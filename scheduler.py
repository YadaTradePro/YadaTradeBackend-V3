import os
import time
import logging
from functools import wraps
from typing import Optional
from main import create_app
from extensions import scheduler
from config import SessionLocal
from sqlalchemy.orm import Session
from sqlalchemy.exc import SQLAlchemyError

from services.fetch_latest_brsapi_eod import update_daily_eod_from_brsapi
from services.data_fetcher import run_full_rebuild
from services.data_processing_and_analysis import run_technical_analysis, run_candlestick_detection

from services.ml_prediction_service import generate_and_save_predictions_for_watchlist, update_ml_prediction_outcomes

from services.weekly_watchlist_service import run_weekly_watchlist_selection
from services.golden_key_service import run_golden_key_analysis_and_save
from services.potential_buy_queues_service import run_potential_buy_queue_analysis_and_save

from services import market_analysis_service
from services.index_data_processor import store_market_indices_data
from services.sector_analysis_service import run_daily_sector_analysis


from services.performance_service import run_weekly_performance_pipeline

from services.data_fetcher import run_full_rebuild

# ----------------- Logging Setup -----------------
LOG_FORMAT = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
logging.basicConfig(
    level=logging.INFO,
    format=LOG_FORMAT,
    handlers=[logging.FileHandler("scheduler.log", encoding="utf-8"), logging.StreamHandler()]
)
logger = logging.getLogger(__name__)

# ----------------- App Context and Error Handling Decorator -----------------
app = create_app()


def with_context_and_error_handling(func):
    """
    Decorator to run a function inside a Flask app context, provide a DB session (if needed),
    and handle potential exceptions (including DB transaction management).
    """
    @wraps(func)
    def wrapper(*args, **kwargs):
        # Ø¨Ø±Ø±Ø³ÛŒ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… Ú©Ù‡ Ø¢ÛŒØ§ ØªØ§Ø¨Ø¹ ÙˆØ±ÙˆØ¯ÛŒ Ø¨Ù‡ db_session Ù†ÛŒØ§Ø² Ø¯Ø§Ø±Ø¯ ÛŒØ§ Ø®ÛŒØ±
        needs_db_session = 'db_session' in func.__code__.co_varnames
        db_session: Optional[Session] = None

        with app.app_context():
            logger.info(f"âœ… Executing job '{func.__name__}' inside Flask app context.")

            # 2. Ø§ÛŒØ¬Ø§Ø¯ Database Session Ø¯Ø± ØµÙˆØ±Øª Ù†ÛŒØ§Ø²
            if needs_db_session:
                try:
                    db_session = SessionLocal()
                    kwargs['db_session'] = db_session  # ğŸ› ï¸ ØªØ²Ø±ÛŒÙ‚ db_session
                except Exception as e:
                    logger.error(
                        f"âŒ Failed to create DB Session for job '{func.__name__}': {e}",
                        exc_info=True
                    )
                    # Ø§Ú¯Ø± Ù†ØªÙˆØ§Ù†Ø¯ Ø³Ø´Ù† Ø§ÛŒØ¬Ø§Ø¯ Ú©Ù†Ø¯ØŒ Job Ù†Ø¨Ø§ÛŒØ¯ Ø§Ø¬Ø±Ø§ Ø´ÙˆØ¯
                    raise

            try:
                # 3. Ø§Ø¬Ø±Ø§ÛŒ ØªØ§Ø¨Ø¹ Ø¨Ø§ Ø¢Ø±Ú¯ÙˆÙ…Ø§Ù†â€ŒÙ‡Ø§ÛŒ Ø¨Ù‡â€ŒØ±ÙˆØ² Ø´Ø¯Ù‡
                result = func(*args, **kwargs)

                # 4. Commit Ú©Ø±Ø¯Ù† ØªØºÛŒÛŒØ±Ø§Øª Ø¯ÛŒØªØ§Ø¨ÛŒØ³
                if db_session:
                    db_session.commit()
                    logger.info(
                        f"âœ… Job '{func.__name__}' completed successfully and changes committed."
                    )
                else:
                    logger.info(f"âœ… Job '{func.__name__}' completed successfully.")
                return result

            except SQLAlchemyError as e:
                # 5. Rollback Ø¯Ø± ØµÙˆØ±Øª Ø¨Ø±ÙˆØ² Ø®Ø·Ø§ÛŒ Ø¯ÛŒØªØ§Ø¨ÛŒØ³
                if db_session:
                    db_session.rollback()
                logger.error(f"âŒ Database Error in job '{func.__name__}': {e}", exc_info=True)
                raise

            except Exception as e:
                # 5. Rollback Ùˆ Ù…Ø¯ÛŒØ±ÛŒØª Ø®Ø·Ø§Ù‡Ø§ÛŒ Ø¹Ù…ÙˆÙ…ÛŒ
                if db_session:
                    db_session.rollback()
                logger.error(f"âŒ An error occurred while running job '{func.__name__}': {e}", exc_info=True)
                raise

            finally:
                # 6. Ø¨Ø³ØªÙ† Ø³Ø´Ù† Ø¯Ø± Ù‡Ø± ØµÙˆØ±Øª
                if db_session:
                    db_session.close()

    return wrapper


# ----------------- Custom Flow Definition -----------------
@with_context_and_error_handling
def run_daily_analysis_flow(db_session: Session = None):
    """
    Ø§Ø¬Ø±Ø§ÛŒ ØªØ±ØªÛŒØ¨ÛŒ ÙØ±Ø¢ÛŒÙ†Ø¯ Ø¢Ù¾Ø¯ÛŒØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ùˆ ØªØ­Ù„ÛŒÙ„ Ø±ÙˆØ²Ø§Ù†Ù‡.
    Ø§ÛŒÙ† ØªØ§Ø¨Ø¹ Ù†ÛŒØ§Ø² Ø¨Ù‡ db_session Ø¯Ø§Ø±Ø¯ ØªØ§ Ø¨ØªÙˆØ§Ù†Ø¯ Ø¢Ù† Ø±Ø§ Ø¨Ù‡ ØªÙˆØ§Ø¨Ø¹ Ù¾Ø§ÛŒÛŒÙ†ÛŒ Ù¾Ø§Ø³ Ø¯Ù‡Ø¯.
    """
    logger.info("ğŸ¬ Ø´Ø±ÙˆØ¹ 'Daily Analysis Flow': EOD Update -> Technical Analysis -> Candlestick Detection")

    # 1. Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø§ÛŒØ§Ù† Ø±ÙˆØ² (EOD)
    logger.info("â¡ï¸ Ù…Ø±Ø­Ù„Ù‡ 1/3: ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ update_daily_eod_from_brsapi")
    update_daily_eod_from_brsapi(db_session=db_session)
    logger.info("âœ… Ù…Ø±Ø­Ù„Ù‡ 1/3: update_daily_eod_from_brsapi Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯.")

    # 2. Ø§Ø¬Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ ØªÚ©Ù†ÛŒÚ©Ø§Ù„
    logger.info("â¡ï¸ Ù…Ø±Ø­Ù„Ù‡ 2/3: ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ run_technical_analysis")
    run_technical_analysis(db_session=db_session)
    logger.info("âœ… Ù…Ø±Ø­Ù„Ù‡ 2/3: run_technical_analysis Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯.")

    # 3. Ø§Ø¬Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ú©Ù†Ø¯Ù„â€ŒØ§Ø³ØªÛŒÚ©
    logger.info("â¡ï¸ Ù…Ø±Ø­Ù„Ù‡ 3/3: ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ run_candlestick_detection")
    run_candlestick_detection(db_session=db_session)
    logger.info("âœ… Ù…Ø±Ø­Ù„Ù‡ 3/3: run_candlestick_detection Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯.")

    logger.info("ğŸ‰ Ù¾Ø§ÛŒØ§Ù† Ù…ÙˆÙÙ‚ÛŒØªâ€ŒØ¢Ù…ÛŒØ² 'Daily Analysis Flow'.")


# ----------------- Job Definitions -----------------
JOBS = [
    # ğŸŸ¢ ÙˆØ¸Ø§ÛŒÙ Ø±ÙˆØ²Ø§Ù†Ù‡ (Ø±ÙˆØ²Ù‡Ø§ÛŒ Ø¨Ø§Ø²Ø§Ø±)

    # 1. Ø¬Ø±ÛŒØ§Ù† Ø§ØµÙ„ÛŒ ØªØ­Ù„ÛŒÙ„
    {
        "id": "daily_analysis_flow_job",
        "func": run_daily_analysis_flow,
        "trigger": "cron",
        "day_of_week": "sat, sun, mon, tue, wed",
        "hour": 16,
        "minute": 30
    },

    # 2. Ø´Ø§Ø®Øµ Ø¨Ø§Ø²Ø§Ø± Ùˆ ØªØ­Ù„ÛŒÙ„ Ø¨Ø®Ø´â€ŒÙ‡Ø§
    {
        "id": "index_data_update_job",
        "func": store_market_indices_data,
        "trigger": "cron",
        "day_of_week": "sat, sun, mon, tue, wed",
        "hour": 17,
        "minute": 30
    },
    {
        "id": "daily_sector_analysis_job",
        "func": run_daily_sector_analysis,
        "trigger": "cron",
        "day_of_week": "sat, sun, mon, tue, wed",
        "hour": 17,
        "minute": 37
    },

    # 3. Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒâ€ŒÙ‡Ø§ÛŒ ML
    {
        "id": "ml_generate_predictions_job",
        "func": generate_and_save_predictions_for_watchlist,
        "trigger": "cron",
        "day_of_week": "sat, sun, mon, tue, wed",
        "hour": 17,
        "minute": 40
    },
    {
        "id": "ml_update_outcomes_job",
        "func": update_ml_prediction_outcomes,
        "trigger": "cron",
        "day_of_week": "sat, sun, mon, tue, wed",
        "hour": 17,
        "minute": 45
    },

    # 4. ØµÙâ€ŒÙ‡Ø§ÛŒ Ø®Ø±ÛŒØ¯ Ø¨Ø§Ù„Ù‚ÙˆÙ‡ Ùˆ ÙÛŒÙ„ØªØ± Ú©Ù„ÛŒØ¯ Ø·Ù„Ø§ÛŒÛŒ
    {
        "id": "potential_buy_queues_job",
        "func": run_potential_buy_queue_analysis_and_save,
        "trigger": "cron",
        "day_of_week": "sat, sun, mon, tue, wed",
        "hour": 19,
        "minute": 10
    },
    {
        "id": "run_golden_key_filters_job",
        "func": run_golden_key_analysis_and_save,
        "trigger": "cron",
        "day_of_week": "sun, tue, wed",
        "hour": 19,
        "minute": 30
    },

    # ğŸŸ¡ ÙˆØ¸Ø§ÛŒÙ Ù‡ÙØªÚ¯ÛŒ
 
    {
        "id": "weekly_watchlist_selection_job",
        "func": run_weekly_watchlist_selection,
        "trigger": "cron",
        "day_of_week": "wed",
        "hour": 22,
        "minute": 30
    },
    {
        "id": "weekly_full_rebuild_job",
        "func": run_full_rebuild,
        "trigger": "cron",
        "day_of_week": "fri",
        "hour": 4,
        "minute": 0,
        "coalesce": True,
        "max_instances": 1,
        "kwargs": {
            "batch_size": 50,
            "commit_batch_size": 100
        }
    },





    {
    "id": "weekly_calculate_aggregated_performance_job",
    "func": run_weekly_performance_pipeline,
    "trigger": "cron",
    "day_of_week": "thu",
    "hour": 21,
    "minute": 45,
    "kwargs": {"period_type": "weekly"}
    },


]

TIMEZONE = "Asia/Tehran"


# ----------------- Scheduler Runner -----------------
def run_scheduler_app():
    """Runs the APScheduler in a standalone process."""
    app.config["SCHEDULER_RUN"] = True

    scheduler.init_app(app)

    for job in JOBS:
        try:
            func_to_schedule = job["func"]

            # Ø§Ú¯Ø± ØªØ§Ø¨Ø¹ Ø¯Ú©ÙˆØ± Ù†Ø´Ø¯Ù‡ØŒ Ø¯Ú©ÙˆØ±ÛŒØªÙˆØ± Ø±Ø§ Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†
            if job["id"] != "daily_analysis_flow_job":
                func_to_schedule = with_context_and_error_handling(job["func"])

            scheduler.add_job(
                id=job["id"],
                func=func_to_schedule,
                trigger=job["trigger"],
                replace_existing=True,
                timezone=TIMEZONE,
                **{k: v for k, v in job.items() if k not in ["id", "func", "trigger"]}
            )
            logger.info(f"âœ… Job registered: {job['id']}")
        except Exception as e:
            logger.error(f"âŒ Failed to add job {job['id']}: {e}", exc_info=True)

    scheduler.start()
    logger.info("ğŸš€ APScheduler started in a separate process.")

    try:
        while True:
            time.sleep(60)
    except (KeyboardInterrupt, SystemExit):
        scheduler.shutdown()
        logger.info("ğŸ›‘ Scheduler has been shut down.")


if __name__ == "__main__":
    run_scheduler_app()
