# -*- coding: utf-8 -*-
# services/market_analysis_service.py

import logging
from datetime import datetime, timedelta
import jdatetime
from sqlalchemy.exc import SQLAlchemyError
import json
from typing import Dict, List, Any, Optional
import pandas as pd
import numpy as np 

from models import (
    HistoricalData,
    ComprehensiveSymbolData,
    AggregatedPerformance,
    WeeklyWatchlistResult,
    DailySectorPerformance,
    DailyIndexData, # ğŸ’¡ Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯
)

# Import Jinja2 for templating
from jinja2 import Environment, FileSystemLoader, Template

# Import necessary modules
from extensions import db
# âŒ Ø­Ø°Ù Ø´Ø¯: Ø¯ÛŒÚ¯Ø± Ù†ÛŒØ§Ø²ÛŒ Ø¨Ù‡ ØªØ§Ø¨Ø¹ Ø®Ø§Ø±Ø¬ÛŒ Ù†ÛŒØ³ØªØŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø§Ø² Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ø®ÙˆØ§Ù†Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯
# from services.iran_market_data import fetch_iran_market_indices 

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù„Ø§Ú¯ÛŒÙ†Ú¯
logger = logging.getLogger(__name__)


daily_template = None
weekly_template = None

try:
    template_loader = FileSystemLoader('services/templates')
    template_env = Environment(loader=template_loader)
    daily_template = template_env.get_template('daily_summary.j2')
    weekly_template = template_env.get_template('weekly_summary.j2')
    logger.info("âœ… Ù‚Ø§Ù„Ø¨â€ŒÙ‡Ø§ÛŒ Jinja2 Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ø² ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯Ù†Ø¯.")
except Exception as e:
    logger.error(f"âŒ Ø®Ø·Ø§ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù‚Ø§Ù„Ø¨â€ŒÙ‡Ø§ÛŒ Jinja2: {e}. Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù‚Ø§Ù„Ø¨â€ŒÙ‡Ø§ÛŒ Ø¯Ø±ÙˆÙ†â€ŒØ­Ø§ÙØ¸Ù‡â€ŒØ§ÛŒ.", exc_info=True)

    # Fallback Ø¨Ù‡ Ù‚Ø§Ù„Ø¨â€ŒÙ‡Ø§ÛŒ Ø¯Ø±ÙˆÙ† Ø­Ø§ÙØ¸Ù‡ - Ù‚Ø§Ù„Ø¨ Ø±ÙˆØ²Ø§Ù†Ù‡ Ø¨Ù‡ Ø·ÙˆØ± Ú©Ø§Ù…Ù„ Ø¨Ø§Ø²Ù†ÙˆÛŒØ³ÛŒ Ø´Ø¯Ù‡ Ø§Ø³Øª
    DAILY_TEMPLATE_STRING = """
ğŸ“Š **ØªØ­Ù„ÛŒÙ„ Ø±ÙˆØ²Ø§Ù†Ù‡ Ø¨Ø§Ø²Ø§Ø± | {{ jdate }}**

**Ù†Ù…Ø§ÛŒ Ú©Ù„ÛŒ Ø¨Ø§Ø²Ø§Ø±:**
- **Ø´Ø§Ø®Øµ Ú©Ù„:** `{{ sentiment.total_index.value }}` ({{ sentiment.total_index.status }})
- **Ø´Ø§Ø®Øµ Ù‡Ù…â€ŒÙˆØ²Ù†:** `{{ sentiment.equal_weighted_index.value }}` ({{ sentiment.equal_weighted_index.status }})
- **Ø§Ø±Ø²Ø´ Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø®Ø±Ø¯:** **{{ '%.1f'|format(sentiment.trade_value.retail / 1e10) }}** Ù‡Ø²Ø§Ø± Ù…ÛŒÙ„ÛŒØ§Ø±Ø¯ ØªÙˆÙ…Ø§Ù† (Ù‡Ù…Øª)

---

**Ù†Ø¨Ø¶ Ø¨Ø§Ø²Ø§Ø± (Ø³Ù†ØªÛŒÙ…Ù†Øª):**
- **Ø¬Ø±ÛŒØ§Ù† Ù¾ÙˆÙ„ Ø­Ù‚ÛŒÙ‚ÛŒ:** {{ sentiment.money_flow.status_text }} Ø¨Ù‡ Ø§Ø±Ø²Ø´ **{{ '%.2f'|format(sentiment.money_flow.net_value_billion_toman) }}** Ù…ÛŒÙ„ÛŒØ§Ø±Ø¯ ØªÙˆÙ…Ø§Ù†
- **Ù‚Ø¯Ø±Øª Ø®Ø±ÛŒØ¯Ø§Ø± Ø­Ù‚ÛŒÙ‚ÛŒ:** Ø³Ø±Ø§Ù†Ù‡ Ø®Ø±ÛŒØ¯ **{{ '{:,.0f}'.format(sentiment.per_capita.buy) }}** Ù….ØªÙˆÙ…Ø§Ù† Ø¯Ø± Ù…Ù‚Ø§Ø¨Ù„ Ø³Ø±Ø§Ù†Ù‡ ÙØ±ÙˆØ´ **{{ '{:,.0f}'.format(sentiment.per_capita.sell) }}** Ù….ØªÙˆÙ…Ø§Ù†. ({{ sentiment.per_capita.status_text }})
- **ÙˆØ¶Ø¹ÛŒØª Ú©Ù„ÛŒ:** **{{ sentiment.market_breadth.positive_symbols }}** Ù†Ù…Ø§Ø¯ Ù…Ø«Ø¨Øª Ø¯Ø± Ø¨Ø±Ø§Ø¨Ø± **{{ sentiment.market_breadth.negative_symbols }}** Ù†Ù…Ø§Ø¯ Ù…Ù†ÙÛŒ.

---

{{ sector_summary }}

---

**Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ù…Ù†ØªØ®Ø¨ Ø±ÙˆØ²:**
{% if all_symbols %}
{{ symbols_text }}
{% else %}
- Ø§Ù…Ø±ÙˆØ² Ù†Ù…Ø§Ø¯ Ø¬Ø¯ÛŒØ¯ÛŒ Ø¯Ø± Ù„ÛŒØ³Øª Ù…Ù†ØªØ®Ø¨ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù†Ø´Ø¯.
{% endif %}
"""
    # Ù‚Ø§Ù„Ø¨ Ù‡ÙØªÚ¯ÛŒ Ø¨Ø±Ø§ÛŒ Ù‡Ù…Ø§Ù‡Ù†Ú¯ÛŒØŒ Ú©Ù…ÛŒ Ø®Ù„Ø§ØµÙ‡â€ŒØªØ± Ù…ÛŒâ€ŒØ´ÙˆØ¯
    WEEKLY_TEMPLATE_STRING = """
ğŸ“… **ØªØ­Ù„ÛŒÙ„ Ù‡ÙØªÚ¯ÛŒ Ø¨Ø§Ø²Ø§Ø± | {{ jdate }}**

**Ø¹Ù…Ù„Ú©Ø±Ø¯ Ú©Ù„ÛŒ Ù‡ÙØªÙ‡:**
- **Ø¬Ø±ÛŒØ§Ù† Ù¾ÙˆÙ„ Ø­Ù‚ÛŒÙ‚ÛŒ:** Ø¯Ø± Ù…Ø¬Ù…ÙˆØ¹ Ù‡ÙØªÙ‡ØŒ {{ smart_money_flow_text }}.
- **Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø³Ø¨Ø¯ Ù…Ù†ØªØ®Ø¨:** Ù†Ø±Ø® Ø¨Ø±Ø¯ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ **{{ '%.1f'|format(indices_data.win_rate|default(0)) }}%** Ø¨ÙˆØ¯Ù‡ Ø§Ø³Øª.

---

{{ sector_summary }}

---

**Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ù‡ÙØªÙ‡:**
{% if all_symbols %}
{{ symbols_text }}
{% else %}
- Ø¯Ø± Ø§ÛŒÙ† Ù‡ÙØªÙ‡ Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø¬Ø¯ÛŒØ¯ÛŒ Ø¯Ø± Ù„ÛŒØ³Øª Ù…Ù†ØªØ®Ø¨ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø´Øª.
{% endif %}
"""
    daily_template = Template(DAILY_TEMPLATE_STRING)
    weekly_template = Template(WEEKLY_TEMPLATE_STRING)
    logger.info("âœ… Ù‚Ø§Ù„Ø¨â€ŒÙ‡Ø§ÛŒ Jinja2 Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ø² Ø±Ø´ØªÙ‡â€ŒÙ‡Ø§ÛŒ Ø¯Ø±ÙˆÙ†â€ŒØ­Ø§ÙØ¸Ù‡â€ŒØ§ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯Ù†Ø¯.")


# -----------------------------------------------------------------------------
# ØªÙˆØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ (Helper Functions) - Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ±Ø§Øª Ø¹Ù…Ø¯Ù‡
# -----------------------------------------------------------------------------

def _safe_dataframe_from_orm(rows: List[Any], cols: List[str]) -> pd.DataFrame:
    if not rows:
        return pd.DataFrame(columns=cols)
    data = [{c: getattr(r, c, None) for c in rows} for r in rows]
    return pd.DataFrame(data)

def _choose_price_col(df: pd.DataFrame) -> str:
    for c in ('close', 'final'):
        if c in df.columns and df[c].notna().any() and df[c].mean() > 0:
            return c
    df['dummy_price'] = 1000 
    return 'dummy_price'

def _get_day_type() -> str:
    j_today = jdatetime.date.today()
    day_name = j_today.strftime('%A') 
    if day_name in ('Saturday', 'Sunday', 'Monday', 'Tuesday', 'Wednesday'):
        return 'daily'
    if day_name == 'Friday':
        return 'weekly'
    return 'no_analysis_day'

def _calculate_pnl(entry_price: float, exit_price: Optional[float]) -> Optional[float]:
    if not entry_price or entry_price == 0 or exit_price is None:
        return None
    return round(((exit_price - entry_price) / entry_price) * 100, 2)

def _get_formatted_symbols_text(symbols: List[Any], is_weekly: bool) -> str:
    if not symbols:
        return ""
    text_parts = []
    for symbol_data in symbols:
        symbol_name = symbol_data.symbol_name
        reasons = getattr(symbol_data, 'reasons', '{}')
        if not isinstance(reasons, str):
            reasons = json.dumps(reasons, ensure_ascii=False)

        if not is_weekly:
            daily_change = getattr(symbol_data, 'daily_change_percent', None)
            status_text = ""
            if daily_change is not None:
                status_text = f" (Ø±Ø´Ø¯ **{daily_change:.2f}%**)" if daily_change > 0 else f" (Ú©Ø§Ù‡Ø´ **{abs(daily_change):.2f}%**)"
            text_parts.append(f"- **{symbol_name}**: {reasons}{status_text}")
        else:
            pnl_percent = getattr(symbol_data, 'profit_loss_percentage', None)
            status_text = "(ÙØ¹Ø§Ù„)"
            if pnl_percent is not None:
                status_text = f"(**{pnl_percent:.2f}%** Ø³ÙˆØ¯)" if pnl_percent > 0 else f"(**{abs(pnl_percent):.2f}%** Ø²ÛŒØ§Ù†)"
            text_parts.append(f"- **{symbol_name}**: {reasons} {status_text}")
    return "\n".join(text_parts)



def _get_top_sectors_summary(db_session: db.session, limit: int = 5) -> List[Dict[str, Any]]:
    """
    Ø§Ø·Ù„Ø§Ø¹Ø§Øª ØµÙ†Ø§ÛŒØ¹ Ø¨Ø±ØªØ± Ø±Ø§ Ø¨Ù‡ ØµÙˆØ±Øª ÛŒÚ© Ù„ÛŒØ³Øª Ø§Ø² Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒâ€ŒÙ‡Ø§ÛŒ JSON-friendly Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯.
    """
    try:
        latest_date_record = db_session.query(DailySectorPerformance.jdate).order_by(DailySectorPerformance.jdate.desc()).first()
        if not latest_date_record:
            # ğŸ’¡ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù† Ù„ÛŒØ³Øª Ø®Ø§Ù„ÛŒ Ø¯Ø± ØµÙˆØ±Øª Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø¯Ù‡ ØªØ§Ø±ÛŒØ®
            return []

        latest_jdate_str = latest_date_record[0]
        top_sectors = DailySectorPerformance.query.filter_by(jdate=latest_jdate_str).order_by(DailySectorPerformance.rank.asc()).limit(limit).all()
        
        if not top_sectors:
            # ğŸ’¡ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù† Ù„ÛŒØ³Øª Ø®Ø§Ù„ÛŒ Ø¯Ø± ØµÙˆØ±Øª Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø¯Ù‡ ØµÙ†Ø¹Øª
            return []
            
        json_sectors_list = []
        for sector in top_sectors:
            # ğŸ’¡ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ float Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ Ù¾Ø§ÛŒØªÙˆÙ† Ø¨Ø±Ø§ÛŒ JSON
            net_flow_billion = float(sector.net_money_flow) / 1e10 if sector.net_money_flow else 0
            
            sector_data = {
                'sector_name': sector.sector_name,
                'net_money_flow_billion': round(net_flow_billion, 2), # Ú¯Ø±Ø¯ Ú©Ø±Ø¯Ù† Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø¨Ù‡ØªØ±
                'flow_status': 'ÙˆØ±ÙˆØ¯' if net_flow_billion > 0 else ('Ø®Ø±ÙˆØ¬' if net_flow_billion < 0 else 'Ø®Ù†Ø«ÛŒ'),
                'flow_value_text': f"{abs(net_flow_billion):.2f} Ù….ØªÙˆÙ…Ø§Ù†",
                # 'rank': sector.rank # Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø±ØªØ¨Ù‡ Ø±Ø§ Ù†ÛŒØ² Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†ÛŒØ¯
            }
            json_sectors_list.append(sector_data)

        # ğŸ’¡ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù† Ù„ÛŒØ³Øª Ø³Ø§Ø®ØªØ§Ø±ÛŒØ§ÙØªÙ‡ Ø¨Ù‡ Ø¬Ø§ÛŒ Ø±Ø´ØªÙ‡
        return json_sectors_list
    
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ Ø®Ù„Ø§ØµÙ‡ ØµÙ†Ø§ÛŒØ¹ Ø¨Ø±ØªØ±: {e}")
        # ğŸ’¡ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù† Ù„ÛŒØ³Øª Ø®Ø§Ù„ÛŒ Ø¯Ø± ØµÙˆØ±Øª Ø®Ø·Ø§ÛŒ ÙÙ†ÛŒ
        return []


#ØªØ§Ø¨Ø¹ Ù†Ú¯Ø§Ø´Øª (Mapping)
def _map_watchlist_result_to_dict(result_obj: 'WeeklyWatchlistResult') -> Dict[str, Any]:
    """
    ÛŒÚ© Ø¢Ø¨Ø¬Ú©Øª ORM WeeklyWatchlistResult Ø±Ø§ Ø¨Ù‡ Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ ØªØ¨Ø¯ÛŒÙ„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    """
    # ØªÙˆØ¬Ù‡: daily_change_percent ÛŒÚ© ÙÛŒÙ„Ø¯ Ù…ÙˆÙ‚ØªÛŒ Ø§Ø³Øª Ú©Ù‡ Ø¨Ø§ setattr Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯Ù‡ Ø§Ø³Øª.
    daily_change = getattr(result_obj, 'daily_change_percent', None)
    
    # ğŸ’¡ ØªÙ…Ø§Ù… Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù„Ø§Ø²Ù… Ø±Ø§ Ø¨Ù‡ ØµÙˆØ±Øª ØµØ±ÛŒØ­ Ø§Ø² Ø¢Ø¨Ø¬Ú©Øª Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
    return {
        'signal_unique_id': result_obj.signal_unique_id,
        'symbol_id': result_obj.symbol_id,
        'symbol_name': result_obj.symbol_name,
        'entry_price': float(result_obj.entry_price) if result_obj.entry_price is not None else None,
        'jentry_date': result_obj.jentry_date,
        'status': result_obj.status,
        'daily_change_percent': float(daily_change) if daily_change is not None else None,
        # Ø§ÙØ²ÙˆØ¯Ù† Ø³Ø§ÛŒØ± ÙÛŒÙ„Ø¯Ù‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø² ÙØ±Ø§Ù†Øªâ€ŒØ§Ù†Ø¯
        'outlook': result_obj.outlook,
        'reason': result_obj.reason,
        'exit_price': float(result_obj.exit_price) if result_obj.exit_price is not None else None,
        'jexit_date': result_obj.jexit_date,
        'profit_loss_percentage': float(result_obj.profit_loss_percentage) if result_obj.profit_loss_percentage is not None else None,
        'probability_percent': float(result_obj.probability_percent) if result_obj.probability_percent is not None else None,
    }


# -----------------------------------------------------------------------------
# ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ Ø¬Ø¯ÛŒØ¯ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø³Ù†ØªÛŒÙ…Ù†Øª Ø¨Ø§Ø²Ø§Ø±
# -----------------------------------------------------------------------------

def _analyze_market_sentiment(df: pd.DataFrame, indices_data_from_db: Dict) -> Dict: # ğŸ’¡ ØªØºÛŒÛŒØ± Ù†Ø§Ù… Ø¢Ø±Ú¯ÙˆÙ…Ø§Ù†
    """
    DataFrame Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø±ÙˆØ²Ø§Ù†Ù‡ Ø±Ø§ ØªØ­Ù„ÛŒÙ„ Ú©Ø±Ø¯Ù‡ Ùˆ ÛŒÚ© Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø¬Ø§Ù…Ø¹ Ø§Ø² Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ø³Ù†ØªÛŒÙ…Ù†Øª Ø¨Ø§Ø²Ø§Ø± Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯.
    Ù…Ø­Ø§Ø³Ø¨Ø§Øª Ø¬Ø±ÛŒØ§Ù† Ù¾ÙˆÙ„ØŒ Ø³Ø±Ø§Ù†Ù‡ Ùˆ Ø§Ø±Ø²Ø´ Ù…Ø¹Ø§Ù…Ù„Ø§Øª ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ø¨ÙˆØ±Ø³ Ùˆ ÙØ±Ø§Ø¨ÙˆØ±Ø³ Ø§Ù†Ø¬Ø§Ù… Ù…ÛŒâ€ŒØ´ÙˆØ¯.
    """
    
    # ğŸ”‘ ØªØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ Ø¯Ø§Ø®Ù„ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ¨Ø¯ÛŒÙ„ Ø§ÛŒÙ…Ù† Ø¯Ø±ØµØ¯ Ø¨Ù‡ Ø¹Ø¯Ø¯ (Ø±ÙØ¹ Ø®Ø·Ø§ÛŒ TypeError)
    def _get_safe_percent(index_data: Dict, key: str = 'percent_change') -> float: # ğŸ’¡ ØªØºÛŒÛŒØ± Ú©Ù„ÛŒØ¯ Ø¨Ù‡ percent_change
        """Ù…Ù‚Ø¯Ø§Ø± Ø¯Ø±ØµØ¯ Ø±Ø§ Ø¨Ù‡ float ØªØ¨Ø¯ÛŒÙ„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ØŒ Ø§Ú¯Ø± None ÛŒØ§ Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø¨ÙˆØ¯ØŒ 0.0 Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯."""
        value = index_data.get(key)
        try:
            # Ø§Ú¯Ø± valueØŒ None Ù†Ø¨Ø§Ø´Ø¯ØŒ Ø¢Ù† Ø±Ø§ Ø¨Ù‡ float ØªØ¨Ø¯ÛŒÙ„ Ú©Ù†
            if value is not None:
                return float(value)
            return 0.0
        except (TypeError, ValueError):
            # Ø§Ú¯Ø± ØªØ¨Ø¯ÛŒÙ„ Ù…ÙˆÙÙ‚ Ù†Ø¨ÙˆØ¯ØŒ 0.0 Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†
            return 0.0

    sentiment_data = {}
    
    # 0. Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ DataFrame Ùˆ ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† Ù†Ù…Ø§Ø¯Ù‡Ø§
    
    # 0.1 ØªØ¨Ø¯ÛŒÙ„ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø¹Ø¯Ø¯ÛŒ
    numeric_cols = [
        'value', 'volume', 'plp',
        'buy_i_volume', 'sell_i_volume', 'buy_count_i', 'sell_count_i',
    ]
    for col in numeric_cols:
        if col in df.columns:
            # Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ù†ÙˆØ¹ Ø¹Ø¯Ø¯ÛŒ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø®Ø·Ø§ÛŒ NumPy Ø¯Ø± Ø§Ø¯Ø§Ù…Ù‡
            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(float) 

    
    # Ø¨Ø§Ø²Ø§Ø±Ù‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø³Ù†ØªÛŒÙ…Ù†Øª (Ø¨Ø§Ø²Ø§Ø±Ù‡Ø§ÛŒ Ø§ØµÙ„ÛŒ)
    bourse_market_types = ['Ø¨ÙˆØ±Ø³', 'ÙØ±Ø§Ø¨ÙˆØ±Ø³'] 
    
    # Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ symbol_id Ù‡Ø§ÛŒ Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ø¨ÙˆØ±Ø³ Ùˆ ÙØ±Ø§Ø¨ÙˆØ±Ø³
    valid_symbol_ids = db.session.query(ComprehensiveSymbolData.symbol_id).filter(
        ComprehensiveSymbolData.market_type.in_(bourse_market_types)
    ).all()
    
    # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ù…Ø¬Ù…ÙˆØ¹Ù‡ Ø¨Ø±Ø§ÛŒ Ø¬Ø³ØªØ¬ÙˆÛŒ Ø³Ø±ÛŒØ¹ØªØ±
    valid_ids_set = {id_[0] for id_ in valid_symbol_ids}

    # ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† DataFrame Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø±ÙˆØ²Ø§Ù†Ù‡
    df_filtered = df[df['symbol_id'].isin(valid_ids_set)].copy() # ğŸ’¡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² .copy() Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² SettingWithCopyWarning
    
    if df_filtered.empty:
        logger.warning("âŒ Ù‡ÛŒÚ† Ù†Ù…Ø§Ø¯ Ø¨ÙˆØ±Ø³/ÙØ±Ø§Ø¨ÙˆØ±Ø³ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø³Ù†ØªÛŒÙ…Ù†Øª ÛŒØ§ÙØª Ù†Ø´Ø¯.")
        # Ø§Ú¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø§ØµÙ„ÛŒ Ù†Ø¯Ø§Ø±ÛŒÙ…ØŒ ÙÙ‚Ø· Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†ÛŒÙ…
        sentiment_data.update({
             'trade_value': {'retail': 0},
             'money_flow': {'net_value_billion_toman': 0, 'status_text': "Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¬Ø±ÛŒØ§Ù† Ù¾ÙˆÙ„ Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø²Ø§Ø±Ù‡Ø§ÛŒ Ø§ØµÙ„ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª."},
             'per_capita': {'buy': 0, 'sell': 0, 'status_text': "Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø³Ø±Ø§Ù†Ù‡ Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø²Ø§Ø±Ù‡Ø§ÛŒ Ø§ØµÙ„ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª."},
             'market_breadth': {'positive_symbols': 0, 'negative_symbols': 0},
        })
        # ğŸ’¡ Û±. ØªØ­Ù„ÛŒÙ„ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§: Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ Ø±Ø§ Ø§Ø² indices_data_from_db Ø§Ø¶Ø§ÙÙ‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… Ø­ØªÛŒ Ø§Ú¯Ø± Ø¨Ù‚ÛŒÙ‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ù†Ø¨Ø§Ø´Ù†Ø¯
        total_index_data = indices_data_from_db.get('Total_Index', {})
        total_percent = _get_safe_percent(total_index_data)

        sentiment_data['total_index'] = {
            'value': total_index_data.get('value', 'N/A'),
            'status': 'ØµØ¹ÙˆØ¯ÛŒ' if total_percent > 0 else ('Ù†Ø²ÙˆÙ„ÛŒ' if total_percent < 0 else 'Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ±')
        }

        equal_weighted_index_data = indices_data_from_db.get('Equal_Weighted_Index', {})
        equal_percent = _get_safe_percent(equal_weighted_index_data)

        sentiment_data['equal_weighted_index'] = {
            'value': equal_weighted_index_data.get('value', 'N/A'),
            'status': 'ØµØ¹ÙˆØ¯ÛŒ' if equal_percent > 0 else ('Ù†Ø²ÙˆÙ„ÛŒ' if equal_percent < 0 else 'Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ±')
        }

        return sentiment_data
    
    # Û±. ØªØ­Ù„ÛŒÙ„ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ (ğŸ’¡ ØªØºÛŒÛŒØ±: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ DB)
    total_index = indices_data_from_db.get('Total_Index', {})
    # ğŸ”‘ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ØªØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ…Ù†â€ŒØ³Ø§Ø²ÛŒ
    total_percent = _get_safe_percent(total_index)
    
    sentiment_data['total_index'] = {
        'value': total_index.get('value', 'N/A'),
        # Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ù‚Ø¯Ø§Ø± Ø§ÛŒÙ…Ù† Ø´Ø¯Ù‡ total_percent
        'status': 'ØµØ¹ÙˆØ¯ÛŒ' if total_percent > 0 else ('Ù†Ø²ÙˆÙ„ÛŒ' if total_percent < 0 else 'Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ±')
    }
    
    equal_weighted_index = indices_data_from_db.get('Equal_Weighted_Index', {})
    # ğŸ”‘ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ØªØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ…Ù†â€ŒØ³Ø§Ø²ÛŒ
    equal_percent = _get_safe_percent(equal_weighted_index)
    
    sentiment_data['equal_weighted_index'] = {
        'value': equal_weighted_index.get('value', 'N/A'),
        # Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ù‚Ø¯Ø§Ø± Ø§ÛŒÙ…Ù† Ø´Ø¯Ù‡ equal_percent
        'status': 'ØµØ¹ÙˆØ¯ÛŒ' if equal_percent > 0 else ('Ù†Ø²ÙˆÙ„ÛŒ' if equal_percent < 0 else 'Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ±')
    }

    # Û². ØªØ­Ù„ÛŒÙ„ Ø§Ø±Ø²Ø´ Ù…Ø¹Ø§Ù…Ù„Ø§Øª (ÙÙ‚Ø· Ø¨ÙˆØ±Ø³ Ùˆ ÙØ±Ø§Ø¨ÙˆØ±Ø³)
    # total_trade_value = df_filtered['value'].sum() # Ø¯ÛŒÚ¯Ø± Ù†ÛŒØ§Ø²ÛŒ Ø¨Ù‡ Ù†Ù…Ø§ÛŒØ´ Ø§Ø±Ø²Ø´ Ú©Ù„ Ù†ÛŒØ³Øª
    retail_trade_value = df_filtered[df_filtered['volume'] > 1]['value'].sum()
    sentiment_data['trade_value'] = {'retail': float(retail_trade_value)} 

    # Û³. ØªØ­Ù„ÛŒÙ„ Ø¬Ø±ÛŒØ§Ù† Ù¾ÙˆÙ„ Ø­Ù‚ÛŒÙ‚ÛŒ (ÙÙ‚Ø· Ø¨ÙˆØ±Ø³ Ùˆ ÙØ±Ø§Ø¨ÙˆØ±Ø³)
    price_col = _choose_price_col(df_filtered) # ğŸ’¡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² df_filtered
    df_filtered['net_real_value'] = (df_filtered['buy_i_volume'] - df_filtered['sell_i_volume']) * df_filtered[price_col]
    net_money_flow_value = df_filtered['net_real_value'].sum()
    
    status_text = "Ø¬Ø±ÛŒØ§Ù† Ù¾ÙˆÙ„ Ø­Ù‚ÛŒÙ‚ÛŒ Ø¯Ø± **Ø¨ÙˆØ±Ø³ Ùˆ ÙØ±Ø§Ø¨ÙˆØ±Ø³** ØªÙ‚Ø±ÛŒØ¨Ø§Ù‹ **Ø®Ù†Ø«ÛŒ** Ø¨ÙˆØ¯"
    if net_money_flow_value > 1e10: # Ø¨ÛŒØ´ Ø§Ø² Û± Ù…ÛŒÙ„ÛŒØ§Ø±Ø¯ ØªÙˆÙ…Ø§Ù†
        status_text = "**ÙˆØ±ÙˆØ¯ Ù¾ÙˆÙ„ Ø­Ù‚ÛŒÙ‚ÛŒ** Ø¯Ø± **Ø¨ÙˆØ±Ø³ Ùˆ ÙØ±Ø§Ø¨ÙˆØ±Ø³** Ø±Ø§ Ø´Ø§Ù‡Ø¯ Ø¨ÙˆØ¯ÛŒÙ…" # ğŸ’¡ ÙˆÛŒØ±Ø§ÛŒØ´ ØªØ§ÛŒØªÙ„
    elif net_money_flow_value < -1e10:
        status_text = "**Ø®Ø±ÙˆØ¬ Ù¾ÙˆÙ„ Ø­Ù‚ÛŒÙ‚ÛŒ** Ø§Ø² **Ø¨ÙˆØ±Ø³ Ùˆ ÙØ±Ø§Ø¨ÙˆØ±Ø³** Ø±Ø§ Ø´Ø§Ù‡Ø¯ Ø¨ÙˆØ¯ÛŒÙ…" # ğŸ’¡ ÙˆÛŒØ±Ø§ÛŒØ´ ØªØ§ÛŒØªÙ„
    
    net_value_billion_toman = float(net_money_flow_value) / 1e10

    sentiment_data['money_flow'] = {
        'net_value_billion_toman': net_value_billion_toman,
        'status_text': status_text,
    }

    # Û´. ØªØ­Ù„ÛŒÙ„ Ø³Ø±Ø§Ù†Ù‡ Ø®Ø±ÛŒØ¯ Ùˆ ÙØ±ÙˆØ´ (ÙÙ‚Ø· Ø¨ÙˆØ±Ø³ Ùˆ ÙØ±Ø§Ø¨ÙˆØ±Ø³)
    total_buy_value_i = (df_filtered['buy_i_volume'] * df_filtered[price_col]).sum()
    total_sell_value_i = (df_filtered['sell_i_volume'] * df_filtered[price_col]).sum()
    total_buyers_i = df_filtered['buy_count_i'].sum()
    total_sellers_i = df_filtered['sell_count_i'].sum()
    
    per_capita_buy = (total_buy_value_i / total_buyers_i / 1e7) if total_buyers_i > 0 else 0
    per_capita_sell = (total_sell_value_i / total_sellers_i / 1e7) if total_sellers_i > 0 else 0

    per_capita_status = "Ù‚Ø¯Ø±Øª Ø®Ø±ÛŒØ¯Ø§Ø±Ø§Ù† Ùˆ ÙØ±ÙˆØ´Ù†Ø¯Ú¯Ø§Ù† Ù…ØªØ¹Ø§Ø¯Ù„ Ø¨ÙˆØ¯"
    if per_capita_buy > per_capita_sell * 1.2:
        per_capita_status = "Ù‚Ø¯Ø±Øª **Ø®Ø±ÛŒØ¯Ø§Ø±Ø§Ù†** Ø¨ÛŒØ´ØªØ± Ø¨ÙˆØ¯"
    elif per_capita_sell > per_capita_buy * 1.2:
        per_capita_status = "Ù‚Ø¯Ø±Øª **ÙØ±ÙˆØ´Ù†Ø¯Ú¯Ø§Ù†** Ø¨ÛŒØ´ØªØ± Ø¨ÙˆØ¯"
        
    sentiment_data['per_capita'] = {
        'buy': float(per_capita_buy), 
        'sell': float(per_capita_sell), 
        'status_text': per_capita_status,
    }

    # Ûµ. ØªØ­Ù„ÛŒÙ„ ÙˆØ¶Ø¹ÛŒØª Ú©Ù„ÛŒ Ø¨Ø§Ø²Ø§Ø± (Ù…Ø«Ø¨Øª/Ù…Ù†ÙÛŒ) (ÙÙ‚Ø· Ø¨ÙˆØ±Ø³ Ùˆ ÙØ±Ø§Ø¨ÙˆØ±Ø³)
    positive_symbols = len(df_filtered[df_filtered['plp'] > 0])
    negative_symbols = len(df_filtered[df_filtered['plp'] < 0])
    sentiment_data['market_breadth'] = {
        'positive_symbols': int(positive_symbols), 
        'negative_symbols': int(negative_symbols), 
    }
    
    return sentiment_data


# -----------------------------------------------------------------------------
# ØªÙˆØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ ØªØ­Ù„ÛŒÙ„ (Ø¨Ø§Ø²Ù†ÙˆÛŒØ³ÛŒ Ø´Ø¯Ù‡)
# -----------------------------------------------------------------------------

def _get_daily_indices(jdate_str: str) -> Dict[str, Any]:
    """
    Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø´Ø§Ø®Øµ Ø±ÙˆØ²Ø§Ù†Ù‡ Ø±Ø§ Ø§Ø² Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ú©Ø±Ø¯Ù‡ Ùˆ Ø¯Ø± ÙØ±Ù…Øª Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø² Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯.
    """
    indices_data = {}
    try:
        # ğŸ’¡ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø§Ø² Ù…Ø¯Ù„ Ø¬Ø¯ÛŒØ¯ DailyIndexData
        index_records = DailyIndexData.query.filter_by(jdate=jdate_str).all()
        
        if not index_records:
            logger.warning(f"âŒ Ù‡ÛŒÚ† Ø¯Ø§Ø¯Ù‡ Ø´Ø§Ø®ØµÛŒ Ø¨Ø±Ø§ÛŒ Ø±ÙˆØ² {jdate_str} Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
            return {
                'Total_Index': {'value': 'N/A', 'percent_change': 0.0},
                'Equal_Weighted_Index': {'value': 'N/A', 'percent_change': 0.0}
            }
            
        for record in index_records:
            indices_data[record.index_type] = {
                # ğŸ’¡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² percent_change Ø¨Ù‡ Ø¬Ø§ÛŒ percent
                'value': float(record.value), 
                'percent_change': float(record.percent_change)
            }
            
        # ğŸ’¡ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² ÙˆØ¬ÙˆØ¯ Ø¯Ùˆ Ø´Ø§Ø®Øµ Ú©Ù„ÛŒØ¯ÛŒ
        if 'Total_Index' not in indices_data:
            indices_data['Total_Index'] = {'value': 'N/A', 'percent_change': 0.0}
        if 'Equal_Weighted_Index' not in indices_data:
            indices_data['Equal_Weighted_Index'] = {'value': 'N/A', 'percent_change': 0.0}
            
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø§ÛŒ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø´Ø§Ø®Øµ Ø±ÙˆØ²Ø§Ù†Ù‡ Ø§Ø² Ø¯ÛŒØªØ§Ø¨ÛŒØ³: {e}", exc_info=True)
        # Ø¯Ø± ØµÙˆØ±Øª Ø®Ø·Ø§ØŒ Ù…Ù‚Ø§Ø¯ÛŒØ± Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯
        return {
            'Total_Index': {'value': 'N/A', 'percent_change': 0.0},
            'Equal_Weighted_Index': {'value': 'N/A', 'percent_change': 0.0}
        }
        
    return indices_data


def _generate_daily_summary() -> Dict[str, Any]: 
    logger.info("Ø´Ø±ÙˆØ¹ ÙØ±Ø¢ÛŒÙ†Ø¯ ØªÙˆÙ„ÛŒØ¯ ØªØ­Ù„ÛŒÙ„ Ø¬Ø§Ù…Ø¹ Ø±ÙˆØ²Ø§Ù†Ù‡ Ø¨Ø§Ø²Ø§Ø±...")
    try:
        # 1. Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ø¢Ø®Ø±ÛŒÙ† Ø±ÙˆØ² Ù…Ø¹Ø§Ù…Ù„Ø§ØªÛŒ (Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø§Ù…Ø±ÙˆØ²)
        last_trading_day = db.session.query(HistoricalData.jdate).distinct().order_by(HistoricalData.jdate.desc()).first()
        if not last_trading_day:
            return {"status": "error", "message": "âŒ Ù‡ÛŒÚ† Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø±ÙˆØ²Ø§Ù†Ù‡ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª."}
        
        analysis_date_jdate_str = last_trading_day[0]
        logger.info(f"ØªØ­Ù„ÛŒÙ„ Ø¨Ø±Ø§ÛŒ Ø¢Ø®Ø±ÛŒÙ† Ø±ÙˆØ² Ù…Ø¹Ø§Ù…Ù„Ø§ØªÛŒ ({analysis_date_jdate_str}) Ø§Ù†Ø¬Ø§Ù… Ù…ÛŒâ€ŒØ´ÙˆØ¯.")

        # 2. Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ§Ø±ÛŒØ®ÛŒ Ø±ÙˆØ² Ø¬Ø§Ø±ÛŒ
        required_cols = [
            # ğŸ’¡ Ø³ØªÙˆÙ† PLP (Ø¯Ø±ØµØ¯ ØªØºÛŒÛŒØ± Ø±ÙˆØ²Ø§Ù†Ù‡) Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯
            'symbol_id', 'value', 'volume', 'close', 'final', 'plp',
            'buy_i_volume', 'sell_i_volume', 'buy_count_i', 'sell_count_i'
        ]
        historical_rows = HistoricalData.query.with_entities(
            *[getattr(HistoricalData, col) for col in required_cols]
        ).filter(HistoricalData.jdate == analysis_date_jdate_str).all()

        if not historical_rows:
            return {"status": "error", "message": f"âŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ§Ø±ÛŒØ®ÛŒ Ø¨Ø±Ø§ÛŒ Ø±ÙˆØ² {analysis_date_jdate_str} ÛŒØ§ÙØª Ù†Ø´Ø¯."}

        df = _safe_dataframe_from_orm(historical_rows, required_cols)

        # 3. Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ùˆ ØªØ­Ù„ÛŒÙ„ Ø³Ù†ØªÛŒÙ…Ù†Øª Ø¨Ø§Ø²Ø§Ø±
        # ğŸ’¡ ØªØºÛŒÛŒØ±: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ØªØ§Ø¨Ø¹ Ø¬Ø¯ÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ Ø§Ø² Ø¯ÛŒØªØ§Ø¨ÛŒØ³
        indices_data = _get_daily_indices(analysis_date_jdate_str) 
        sentiment_analysis_result = _analyze_market_sentiment(df, indices_data)
        
        # 4. Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ø±ÙˆØ² Ù…Ø¹Ø§Ù…Ù„Ø§ØªÛŒ Ù‚Ø¨Ù„ (Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ pnl Ø±ÙˆØ²Ø§Ù†Ù‡)
        # Ø§ÛŒÙ† Ø¨Ø®Ø´ Ø¯ÛŒÚ¯Ø± Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø³ØªÙ‚ÛŒÙ… Ø¯Ø±ØµØ¯ ØªØºÛŒÛŒØ± Ù„Ø§Ø²Ù… Ù†ÛŒØ³Øª Ø§Ù…Ø§ Ø­ÙØ¸ Ù…ÛŒâ€ŒØ´ÙˆØ¯
        prev_trading_day = db.session.query(HistoricalData.jdate).distinct().filter(
            HistoricalData.jdate < analysis_date_jdate_str
        ).order_by(HistoricalData.jdate.desc()).first()
        prev_jdate_str = prev_trading_day[0] if prev_trading_day else None

        # 5. Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ ÙˆØ§Ú†â€ŒÙ„ÛŒØ³Øª ÙØ¹Ø§Ù„ (Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒÛŒ Ú©Ù‡ Ù‡Ù†ÙˆØ² Ø¨Ø³ØªÙ‡ Ù†Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯)
        weekly_watchlist_results = WeeklyWatchlistResult.query.filter(
            WeeklyWatchlistResult.exit_price.is_(None) 
        ).all()
        
        # 6. Ù…Ø­Ø§Ø³Ø¨Ù‡/Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ ØªØºÛŒÛŒØ±Ø§Øª Ø±ÙˆØ²Ø§Ù†Ù‡ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ ÙØ¹Ø§Ù„ (Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡)
        # ğŸ’¡ Ø§Ø² Ø³ØªÙˆÙ† 'plp' Ø¯Ø± HistoricalData Ø±ÙˆØ² Ø¬Ø§Ø±ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ….
        for symbol in weekly_watchlist_results:
            # Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø±ÙˆØ² Ø¬Ø§Ø±ÛŒ (Ø´Ø§Ù…Ù„ Ø³ØªÙˆÙ† 'plp')
            today_data_series = df[df['symbol_id'] == symbol.symbol_id]
            today_data = today_data_series.iloc[0] if not today_data_series.empty else None
            
            daily_change = None 
            
            if today_data is not None and 'plp' in today_data:
                # ğŸ’¡ Ù…Ø³ØªÙ‚ÛŒÙ…Ø§Ù‹ Ù…Ù‚Ø¯Ø§Ø± 'plp' (Ø¯Ø±ØµØ¯ ØªØºÛŒÛŒØ± Ø±ÙˆØ²Ø§Ù†Ù‡) Ø±Ø§ Ø§Ø² Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ù…Ø±ÙˆØ² Ù…ÛŒâ€ŒØ®ÙˆØ§Ù†ÛŒÙ…
                daily_change = today_data['plp']
            
            # Ù…Ù‚Ø¯Ø§Ø± Ù…ÙˆÙ‚ØªÛŒ Ø±Ø§ Ø¨Ù‡ Ø´ÛŒØ¡ ORM Ø§Ø¶Ø§ÙÙ‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
            setattr(symbol, 'daily_change_percent', daily_change)
        
        # 7. Ø®Ù„Ø§ØµÙ‡ ØµÙ†Ø§ÛŒØ¹ Ø¨Ø±ØªØ±
        sector_summary_list = _get_top_sectors_summary(db.session, limit=3)
        
        # 8. ØªØ¨Ø¯ÛŒÙ„ Ù„ÛŒØ³Øª Ø¢Ø¨Ø¬Ú©Øªâ€ŒÙ‡Ø§ÛŒ ORM ÙˆØ§Ú†â€ŒÙ„ÛŒØ³Øª Ø¨Ù‡ Ù„ÛŒØ³Øª Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒâ€ŒÙ‡Ø§ 
        # ğŸš¨ Ø±ÙØ¹ Ø¨Ø§Ú¯ Ø§Ù†ØªÙ‚Ø§Ù„ Ø¯Ø§Ø¯Ù‡: Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² Ø§Ù†ØªÙ‚Ø§Ù„ ÙÛŒÙ„Ø¯ Ù…ÙˆÙ‚ØªÛŒ
        final_symbols_list = []
        for symbol in weekly_watchlist_results:
            # 1. ØªØ¨Ø¯ÛŒÙ„ ÙÛŒÙ„Ø¯Ù‡Ø§ÛŒ Ø§ØµÙ„ÛŒ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ø¨Ù‡ Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ
            symbol_dict = _map_watchlist_result_to_dict(symbol) 
            
            # 2. ğŸ’¡ Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ÙÛŒÙ„Ø¯ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¯Ù‡ Ù…ÙˆÙ‚ØªÛŒ Ú©Ù‡ Ø¯Ø± Ø­Ø§ÙØ¸Ù‡ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù‡ Ø§Ø³Øª
            # Ø§ÛŒÙ† ÙÛŒÙ„Ø¯ Ù…Ø³ØªÙ‚ÛŒÙ…Ø§Ù‹ Ø§Ø² Ø´ÛŒØ¡ ORM Ù‚Ø§Ø¨Ù„ Ø¯Ø³ØªØ±Ø³ÛŒ Ø§Ø³Øª
            calculated_change = getattr(symbol, 'daily_change_percent', None)
            if calculated_change is not None:
                symbol_dict['daily_change_percent'] = calculated_change
            
            final_symbols_list.append(symbol_dict)
        
        # 9. Ø§ÛŒØ¬Ø§Ø¯ Ø®Ø±ÙˆØ¬ÛŒ Ù†Ù‡Ø§ÛŒÛŒ
        data_for_template = {
            'jdate': analysis_date_jdate_str,
            'sentiment': sentiment_analysis_result,
            'sector_summary': sector_summary_list, 
            'all_symbols': final_symbols_list, # ğŸ‘ˆ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù„ÛŒØ³Øª ØªØ¨Ø¯ÛŒÙ„ Ø´Ø¯Ù‡
            'symbols_text': _get_formatted_symbols_text(weekly_watchlist_results, is_weekly=False)
        }
        
        return data_for_template
    
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø§ÛŒ Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ ØªØ­Ù„ÛŒÙ„ Ø±ÙˆØ²Ø§Ù†Ù‡: {e}", exc_info=True)
        return {"status": "error", "message": "âŒ Ù…ØªØ£Ø³ÙØ§Ù†Ù‡ Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ø®Ø·Ø§ÛŒ ÙÙ†ÛŒØŒ Ø§Ù…Ú©Ø§Ù† ØªÙˆÙ„ÛŒØ¯ ØªØ­Ù„ÛŒÙ„ Ø±ÙˆØ²Ø§Ù†Ù‡ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯."}


# -----------------------------------------------------------------------------
# ØªØ§Ø¨Ø¹ ØªØ­Ù„ÛŒÙ„ Ù‡ÙØªÚ¯ÛŒ (Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø®Ø±ÙˆØ¬ÛŒ Dict[str, Any] Ùˆ sector_summary)
# -----------------------------------------------------------------------------

def _generate_weekly_summary() -> Dict[str, Any]: # ğŸ’¡ ØªØºÛŒÛŒØ± Ù†ÙˆØ¹ Ø¨Ø§Ø²Ú¯Ø´ØªÛŒ
    logger.info("Ø´Ø±ÙˆØ¹ ÙØ±Ø¢ÛŒÙ†Ø¯ ØªÙˆÙ„ÛŒØ¯ ØªØ­Ù„ÛŒÙ„ Ù‡ÙØªÚ¯ÛŒ Ø¨Ø§Ø²Ø§Ø±...")
    try:
        # 1. Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ûµ Ø±ÙˆØ² Ù…Ø¹Ø§Ù…Ù„Ø§ØªÛŒ Ø¢Ø®Ø± Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ù‡ÙØªÚ¯ÛŒ
        last_5_days_query = db.session.query(HistoricalData.jdate).distinct().order_by(HistoricalData.jdate.desc()).limit(5)
        last_5_days = [d[0] for d in last_5_days_query.all()]
        if not last_5_days:
            return {"status": "error", "message": "âŒ Ø¯Ø§Ø¯Ù‡ Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ù‡ÙØªÚ¯ÛŒ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯."}

        start_date_j = min(last_5_days)
        
        # 2. Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø¢Ù…Ø§Ø± ØªØ¬Ù…ÛŒØ¹ÛŒ (Ù…Ø«Ù„Ø§Ù‹ Win Rate)
        aggregated_data = AggregatedPerformance.query.filter(
            AggregatedPerformance.period_type == 'weekly'
        ).order_by(AggregatedPerformance.created_at.desc()).first()
        indices_for_template = {'win_rate': float(getattr(aggregated_data, 'win_rate', 0))}
        
        # 3. Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¬Ø±ÛŒØ§Ù† Ù¾ÙˆÙ„ Ù‡ÙØªÚ¯ÛŒ
        historical_rows = HistoricalData.query.filter(HistoricalData.jdate.in_(last_5_days)).all()
        # ğŸ’¡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ØªØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø®Øª DataFrame Ø§Ù…Ù†â€ŒØªØ± Ø§Ø³ØªØŒ Ø§Ù…Ø§ ÙØ±Ø¶ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… DataFrame Ù…ÙˆØ¬ÙˆØ¯ Ø§Ø³Øª
        df = pd.DataFrame([row.__dict__ for row in historical_rows])
        
        total_net_real_money_flow = 0
        if not df.empty:
            price_col = _choose_price_col(df)
            for col in ['buy_i_volume', 'sell_i_volume']:
                if col not in df.columns:
                    df[col] = 0
            df['net_real_value_flow'] = (df['buy_i_volume'].fillna(0) - df['sell_i_volume'].fillna(0)) * df[price_col].fillna(0)
            total_net_real_money_flow = float(df['net_real_value_flow'].sum())
        
        smart_money_text = f"Ø´Ø§Ù‡Ø¯ {'ÙˆØ±ÙˆØ¯' if total_net_real_money_flow > 0 else 'Ø®Ø±ÙˆØ¬'} Ù¾ÙˆÙ„ Ø­Ù‚ÛŒÙ‚ÛŒ Ø¨Ù‡ Ø§Ø±Ø²Ø´ ØªÙ‚Ø±ÛŒØ¨ÛŒ **{abs(total_net_real_money_flow) / 1e10:.2f}** Ù…ÛŒÙ„ÛŒØ§Ø±Ø¯ ØªÙˆÙ…Ø§Ù† Ø¨ÙˆØ¯ÛŒÙ…"

        # 4. Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ù†ØªØ§ÛŒØ¬ ÙˆØ§Ú†â€ŒÙ„ÛŒØ³Øª (Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒÛŒ Ú©Ù‡ ÙˆØ±ÙˆØ¯ Ø¢Ù†Ù‡Ø§ Ø¯Ø± Ûµ Ø±ÙˆØ² Ø§Ø®ÛŒØ± Ø¨ÙˆØ¯Ù‡ Ø§Ø³Øª)
        weekly_watchlist_records = WeeklyWatchlistResult.query.filter(WeeklyWatchlistResult.jentry_date >= start_date_j).all()
        
        # 5. Ø®Ù„Ø§ØµÙ‡ ØµÙ†Ø§ÛŒØ¹ Ø¨Ø±ØªØ± (Ø®Ø±ÙˆØ¬ÛŒ JSON List)
        sector_summary_list = _get_top_sectors_summary(db.session, limit=3) # ğŸ’¡ ØªØºÛŒÛŒØ± Ù†Ø§Ù… Ù…ØªØºÛŒØ±
        
        # 6. Ø§ÛŒØ¬Ø§Ø¯ Ø®Ø±ÙˆØ¬ÛŒ Ù†Ù‡Ø§ÛŒÛŒ
        data_for_template = {
            'jdate': jdatetime.date.today().strftime('%Y-%m-%d'),
            'indices_data': indices_for_template,
            'smart_money_flow_text': smart_money_text,
            'sector_summary': sector_summary_list, # ğŸ’¡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù„ÛŒØ³Øª Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒâ€ŒÙ‡Ø§
            'all_symbols': final_symbols_list,
            'symbols_text': _get_formatted_symbols_text(weekly_watchlist_records, is_weekly=True)
        }
        
        return data_for_template
        
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø§ÛŒ Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ ØªØ­Ù„ÛŒÙ„ Ù‡ÙØªÚ¯ÛŒ: {e}", exc_info=True)
        # ğŸ’¡ Ø¨Ø§Ø²Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù† Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø®Ø·Ø§
        return {"status": "error", "message": "âŒ Ù…ØªØ£Ø³ÙØ§Ù†Ù‡ Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ø®Ø·Ø§ÛŒ ÙÙ†ÛŒØŒ Ø§Ù…Ú©Ø§Ù† ØªÙˆÙ„ÛŒØ¯ ØªØ­Ù„ÛŒÙ„ Ù‡ÙØªÚ¯ÛŒ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯."}

# -----------------------------------------------------------------------------
# ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ Ø³Ø±ÙˆÛŒØ³
# -----------------------------------------------------------------------------

def generate_market_summary() -> str:
    """
    ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ Ø³Ø±ÙˆÛŒØ³ Ú©Ù‡ Ø¨Ø³ØªÙ‡ Ø¨Ù‡ Ø±ÙˆØ² Ù‡ÙØªÙ‡ØŒ ØªØ­Ù„ÛŒÙ„ Ø±ÙˆØ²Ø§Ù†Ù‡ ÛŒØ§ Ù‡ÙØªÚ¯ÛŒ Ø±Ø§ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯.
    """
    logger.info("Ø³Ø±ÙˆÛŒØ³ ØªØ­Ù„ÛŒÙ„ Ø¨Ø§Ø²Ø§Ø± ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ Ø´Ø¯.")
    day_type = _get_day_type()
    
    # ğŸ’¡ Ù†Ú©ØªÙ‡: Ø§ÛŒÙ† ØªØ§Ø¨Ø¹ Ø¯Ø± Ø­Ø§Ù„ Ø­Ø§Ø¶Ø± Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯. 
    # Ø§Ú¯Ø± Ø¯Ø± ØµÙˆØ±Øª Ø®Ø·Ø§ (Ù…Ø«Ù„ Ø®Ø·Ø§ÛŒ Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡) ÛŒÚ© Ø±Ø´ØªÙ‡ Ù…ØªÙ†ÛŒ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†Ø¯ØŒ Ø¯Ø± Ø±ÙˆØª Ø®Ø·Ø§ Ø§ÛŒØ¬Ø§Ø¯ Ù…ÛŒâ€ŒØ´ÙˆØ¯.
    # Ø¨Ø§ÛŒØ¯ Ù…Ø·Ù…Ø¦Ù† Ø´ÙˆÛŒÙ… Ú©Ù‡ Ø¯Ø± ØµÙˆØ±Øª Ø®Ø·Ø§ Ù†ÛŒØ² ÛŒÚ© Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ JSON-friendly Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù‡ Ø´ÙˆØ¯.
    # Ø§Ù…Ø§ Ø¨Ø§ ØªÙˆØ¬Ù‡ Ø¨Ù‡ Ø³Ø§Ø®ØªØ§Ø± ÙØ¹Ù„ÛŒØŒ ÙØ±Ø¶ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… Ø¯Ø± ØµÙˆØ±Øª Ù…ÙˆÙÙ‚ÛŒØªØŒ Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ (Ø¨Ø§ Ø§Ù†ÙˆØ§Ø¹ ØªØ¨Ø¯ÛŒÙ„ Ø´Ø¯Ù‡) Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø¯.
    
    if day_type == 'daily':
        return _generate_daily_summary()
    elif day_type == 'weekly':
        return _generate_weekly_summary()
    elif day_type == 'no_analysis_day':
        logger.info("Ø§Ù…Ø±ÙˆØ² Ù¾Ù†Ø¬Ø´Ù†Ø¨Ù‡ Ø§Ø³ØªØ› ØªØ­Ù„ÛŒÙ„ Ø¨Ø§Ø²Ø§Ø± Ù…Ù†ØªØ´Ø± Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯.")
        # Ø¨Ø§Ø²Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù† ÛŒÚ© Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ JSON Ø¨Ø±Ø§ÛŒ Ø±ÙˆØ²Ù‡Ø§ÛŒ ØºÛŒØ±Ù…Ø¹Ø§Ù…Ù„Ø§ØªÛŒ
        return {"status": "info", "message": "Ø¯Ø± Ø±ÙˆØ² Ù¾Ù†Ø¬Ø´Ù†Ø¨Ù‡ØŒ Ø¨Ø§Ø²Ø§Ø± Ø³Ø±Ù…Ø§ÛŒÙ‡ ÙØ¹Ø§Ù„ Ù†ÛŒØ³Øª Ùˆ ØªØ­Ù„ÛŒÙ„ Ø±ÙˆØ²Ø§Ù†Ù‡ Ù…Ù†ØªØ´Ø± Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯."}
    
    return {"status": "error", "message": "Ù†ÙˆØ¹ ØªØ­Ù„ÛŒÙ„ Ø¨Ø±Ø§ÛŒ Ø±ÙˆØ² Ø¬Ø§Ø±ÛŒ Ù‚Ø§Ø¨Ù„ ØªØ´Ø®ÛŒØµ Ù†ÛŒØ³Øª."}