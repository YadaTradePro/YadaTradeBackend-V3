# -*- coding: utf-8 -*-
# services/data_processing_and_analysis.py
# Ù…Ø³Ø¦ÙˆÙ„ÛŒØª: Ø§Ø¬Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ ØªÚ©Ù†ÛŒÚ©Ø§Ù„ Ùˆ ØªØ´Ø®ÛŒØµ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø´Ù…Ø¹ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³.
# ğŸ’¥ Ù†Ø³Ø®Ù‡ Ù†Ù‡Ø§ÛŒÛŒ: Ø§ØµÙ„Ø§Ø­ Ø®Ø·Ø§ÛŒ 'Working outside of application context' Ø¨Ø§ Lazy Initialization

import logging
import gc
import psutil
import time
import pandas as pd
import numpy as np
from datetime import datetime, date, timedelta
from typing import Dict, List, Optional, Tuple, Any, Union
from contextlib import contextmanager
import threading # ğŸ‘ˆ [Ø¬Ø¯ÛŒØ¯] Ø§ÛŒÙ…Ù¾ÙˆØ±Øª Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø² Ø¨Ø±Ø§ÛŒ Ù‚ÙÙ„

from sqlalchemy import func, distinct, text
from sqlalchemy.orm import sessionmaker, Session
from sqlalchemy.exc import SQLAlchemyError
from sqlalchemy import or_

from flask import current_app

# --- ÙˆØ§Ø¨Ø³ØªÚ¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù¾Ø±ÙˆÚ˜Ù‡ ---
from extensions import db
from models import (
    HistoricalData, 
    TechnicalIndicatorData, 
    CandlestickPatternDetection, 
    ComprehensiveSymbolData
)

from services.technical_analysis_utils import (
        calculate_all_indicators, 
        check_candlestick_patterns
    )

# --- ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù„Ø§Ú¯ÛŒÙ†Ú¯ ---
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

# --- Ø«Ø§Ø¨Øªâ€ŒÙ‡Ø§ÛŒ Ù…Ø¯ÛŒØ±ÛŒØª Ø­Ø§ÙØ¸Ù‡ Ùˆ Ø¨Ú† ---
DEFAULT_BATCH_SIZE = 200  # for DB bulk ops & symbol processing
MEMORY_LIMIT_MB = 1500  # warn threshold

# -----------------------------------------------------------
# ğŸ’¥ [Ø¬Ø¯ÛŒØ¯] Ø¨Ø®Ø´ Û±: Ù…Ø¯ÛŒØ±ÛŒØª ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡ Session (Ù†Ø³Ø®Ù‡ Lazy-Loaded)
# -----------------------------------------------------------

# ğŸ‘ˆ [Ø§ØµÙ„Ø§Ø­] SessionLocal Ø±Ø§ Ø¯Ø± Ø²Ù…Ø§Ù† import Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Ù†Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
SessionLocal: Optional[sessionmaker] = None
# ğŸ‘ˆ [Ø¬Ø¯ÛŒØ¯] ÛŒÚ© Ù‚ÙÙ„ Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø§ÛŒØ¬Ø§Ø¯ Ù‡Ù…Ø²Ù…Ø§Ù† SessionLocal ØªÙˆØ³Ø· Ú†Ù†Ø¯ ØªØ±Ø¯
_session_lock = threading.Lock()

def _get_session_local() -> sessionmaker:
    """
    Ø§ÛŒØ¬Ø§Ø¯ Ùˆ Ø¨Ø§Ø²Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù† SessionMaker Ø¨Ù‡ ØµÙˆØ±Øª Lazy (ØªÙ†Ø¨Ù„) Ùˆ Thread-Safe.
    Ø§ÛŒÙ† ØªØ§Ø¨Ø¹ Ø®Ø·Ø§ÛŒ 'Working outside of application context' Ø±Ø§ Ø¨Ø±Ø·Ø±Ù Ù…ÛŒâ€ŒÚ©Ù†Ø¯
    Ø²ÛŒØ±Ø§ 'db.engine' Ø±Ø§ ØªÙ†Ù‡Ø§ Ø²Ù…Ø§Ù†ÛŒ ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ú©Ù‡ ÙˆØ§Ù‚Ø¹Ø§Ù‹ Ø¨Ù‡ Ø¢Ù† Ù†ÛŒØ§Ø² Ø§Ø³Øª.
    """
    global SessionLocal
    
    # Ø§Ú¯Ø± SessionLocal Ù‚Ø¨Ù„Ø§Ù‹ Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯Ù‡ØŒ Ù‡Ù…Ø§Ù† Ø±Ø§ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†
    if SessionLocal:
        return SessionLocal
    
    # Ø§Ú¯Ø± Ø³Ø§Ø®ØªÙ‡ Ù†Ø´Ø¯Ù‡ØŒ Ù‚ÙÙ„ Ø±Ø§ Ø¨Ú¯ÛŒØ± ØªØ§ ÙÙ‚Ø· ÛŒÚ© ØªØ±Ø¯ Ø¢Ù† Ø±Ø§ Ø¨Ø³Ø§Ø²Ø¯
    with _session_lock:
        # Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ú†Ú© Ú©Ù† Ú©Ù‡ ØªØ±Ø¯ Ø¯ÛŒÚ¯Ø±ÛŒ Ø¢Ù† Ø±Ø§ Ù†Ø³Ø§Ø®ØªÙ‡ Ø¨Ø§Ø´Ø¯
        if SessionLocal is None:
            try:
                # ğŸ’¥ Ø§ÛŒÙ† Ú©Ø¯ Ø§Ú©Ù†ÙˆÙ† Ø¯Ø± Ø²Ù…Ø§Ù† Ø§Ø¬Ø±Ø§ ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ Ù…ÛŒâ€ŒØ´ÙˆØ¯ØŒ Ù†Ù‡ Ø¯Ø± Ø²Ù…Ø§Ù† import
                # Ø¯Ø± Ø§ÛŒÙ† Ù„Ø­Ø¸Ù‡ØŒ Ø§Ù¾Ù„ÛŒÚ©ÛŒØ´Ù† Flask Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø´Ø¯Ù‡ Ùˆ db.engine Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ø§Ø³Øª
                SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=db.engine)
                logger.info("âœ… SessionLocal (sessionmaker) Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Ø´Ø¯.")
            except Exception as e:
                logger.error(f"âŒ Ø§Ù…Ú©Ø§Ù† Ø§ØªØµØ§Ù„ Ø¨Ù‡ db.engine Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø®Øª SessionLocal ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯: {e}", exc_info=True)
                # Ø§Ú¯Ø± engine Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†Ø¨Ø§Ø´Ø¯ØŒ Ø§Ø¬Ø§Ø²Ù‡ Ø§Ø¯Ø§Ù…Ù‡ Ú©Ø§Ø± Ø±Ø§ Ù†Ø¯Ù‡
                raise RuntimeError(f"Ø§Ù…Ú©Ø§Ù† Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ SessionLocal ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯: {e}")
        
        return SessionLocal


@contextmanager
def session_scope(external_session: Optional[Session] = None) -> Session:
    """
    Ù…Ø¯ÛŒØ±ÛŒØª Ù‡ÙˆØ´Ù…Ù†Ø¯ Session Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¯Ø± Flask-context ÛŒØ§ Ø®Ø§Ø±Ø¬ Ø§Ø² Ø¢Ù†.
    """
    session = None
    try:
        if external_session:
            # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Session Ù…ÙˆØ¬ÙˆØ¯ (Ø§Ø² Flask route)
            logger.debug("Using external session (from Flask context).")
            yield external_session
        else:
            # Ø§ÛŒØ¬Ø§Ø¯ Session Ø¬Ø¯ÛŒØ¯ (Ø¨Ø±Ø§ÛŒ Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ù¾Ø³â€ŒØ²Ù…ÛŒÙ†Ù‡)
            
            # ğŸ‘ˆ [Ø§ØµÙ„Ø§Ø­] Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ØªØ§Ø¨Ø¹ lazy-initializer
            factory = _get_session_local()
            if not factory:
                 raise RuntimeError("SessionLocal factory could not be initialized.")
                 
            session = factory()
            logger.debug("Creating new local session for background task.")
            
            yield session
            
            logger.debug("Committing local session.")
            session.commit() # ğŸ‘ˆ Ù…Ø¯ÛŒØ±ÛŒØª Ø®ÙˆØ¯Ú©Ø§Ø± Commit
            
    except Exception as e:
        logger.error(f"Error occurred in session scope: {e}. Rolling back.", exc_info=True)
        if session: # ÙÙ‚Ø· Session Ø§ÛŒ Ú©Ù‡ Ø®ÙˆØ¯Ù…Ø§Ù† Ø³Ø§Ø®ØªÛŒÙ… Ø±Ø§ Rollback Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
            session.rollback() # ğŸ‘ˆ Ù…Ø¯ÛŒØ±ÛŒØª Ø®ÙˆØ¯Ú©Ø§Ø± Rollback
        raise e # Ø§Ù†ØªØ´Ø§Ø± Ù…Ø¬Ø¯Ø¯ Ø®Ø·Ø§
    finally:
        if session: # ÙÙ‚Ø· Session Ø§ÛŒ Ú©Ù‡ Ø®ÙˆØ¯Ù…Ø§Ù† Ø³Ø§Ø®ØªÛŒÙ… Ø±Ø§ Close Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
            logger.debug("Closing local session.")
            session.close() # ğŸ‘ˆ Ù…Ø¯ÛŒØ±ÛŒØª Ø®ÙˆØ¯Ú©Ø§Ø± Close


# -----------------------------------------------------------
# ØªÙˆØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ Ù…Ø¯ÛŒØ±ÛŒØª Ø­Ø§ÙØ¸Ù‡ (Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ±)
# -----------------------------------------------------------

def check_memory_usage_mb() -> float:
    """Return current process memory usage in MB (if psutil available)."""
    try:
        if psutil:
            proc = psutil.Process()
            mem = proc.memory_info().rss / (1024 * 1024)
            return mem
        else:
            return 0.0
    except Exception as e:
        logger.debug("Memory check failed: %s", e)
        return 0.0

def cleanup_memory():
    """Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ø­Ø§ÙØ¸Ù‡"""
    try:
        gc.collect()
        current_memory = check_memory_usage_mb()
        if current_memory > MEMORY_LIMIT_MB:
            logger.warning(f"âš ï¸ Ù…ØµØ±Ù Ø­Ø§ÙØ¸Ù‡ Ø¨Ø§Ù„Ø§: {current_memory:.2f} MB")
    except Exception as e:
        logger.debug(f"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ø­Ø§ÙØ¸Ù‡: {e}")

# -----------------------------------------------------------
# ØªØ§Ø¨Ø¹ Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù†ØªØ§ÛŒØ¬ ØªØ­Ù„ÛŒÙ„ ØªÚ©Ù†ÛŒÚ©Ø§Ù„
# -----------------------------------------------------------

def save_technical_indicators(db_session: Session, symbol_id: Union[int, str], df: pd.DataFrame):
    """
    Ø°Ø®ÛŒØ±Ù‡ (Ø¯Ø±Ø¬ ÛŒØ§ Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ) Ù†ØªØ§ÛŒØ¬ ØªØ­Ù„ÛŒÙ„ ØªÚ©Ù†ÛŒÚ©Ø§Ù„.
    Ø§ÛŒÙ† ØªØ§Ø¨Ø¹ Ø¯ÛŒÚ¯Ø± Commit ÛŒØ§ Rollback Ù†Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    """
    symbol_id_str = str(symbol_id)
    
    logger.debug(f"ğŸ’¾ Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§Ø¯: {symbol_id_str}")

    if 'symbol_id' not in df.columns:
        df['symbol_id'] = symbol_id_str
    else:
        df['symbol_id'] = df['symbol_id'].astype(str)

    df_unique = df.drop_duplicates(subset=['symbol_id', 'jdate'], keep='last').copy()
    df_to_save = df_unique.dropna(subset=['RSI', 'MACD', 'jdate'])

    if df_to_save.empty:
        logger.debug(f"âš ï¸ Ù‡ÛŒÚ† Ø³Ø·Ø± Ù…Ø¹ØªØ¨Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ± {symbol_id_str} ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø´Øª.")
        return
    
    updates_count = 0
    inserts_count = 0
    
    records_dict = df_to_save.to_dict('records')
    
    existing_indicators_query = db_session.query(TechnicalIndicatorData).filter(
        TechnicalIndicatorData.symbol_id == symbol_id_str
    )
    
    existing_map = {
        indicator.jdate: indicator 
        for indicator in existing_indicators_query
    }

    for row in records_dict:
        jdate = row.get('jdate')
        if not jdate:
            continue

        row['symbol_id'] = str(row.get('symbol_id', symbol_id_str))
        existing = existing_map.get(jdate)

        if existing:
            # âœ… Update
            existing.close_price = row.get('close')
            existing.RSI = row.get('RSI')
            existing.MACD = row.get('MACD')
            existing.MACD_Signal = row.get('MACD_Signal')
            existing.MACD_Hist = row.get('MACD_Histogram')
            existing.SMA_20 = row.get('SMA_20')
            existing.SMA_50 = row.get('SMA_50')
            existing.Bollinger_High = row.get('Bollinger_Upper')
            existing.Bollinger_Low = row.get('Bollinger_Lower')
            existing.Bollinger_MA = row.get('Bollinger_Middle')
            existing.Volume_MA_20 = row.get('Volume_MA_20')
            existing.ATR = row.get('ATR')
            existing.Stochastic_K = row.get('Stochastic_K')
            existing.Stochastic_D = row.get('Stochastic_D')
            existing.squeeze_on = bool(row.get('squeeze_on'))
            existing.halftrend_signal = row.get('halftrend_signal')
            existing.resistance_level_50d = row.get('resistance_level_50d')
            existing.resistance_broken = bool(row.get('resistance_broken'))
            updates_count += 1
        else:
            # âœ… Insert
            indicator = TechnicalIndicatorData(
                symbol_id=row['symbol_id'],
                jdate=jdate,
                close_price=row.get('close'),
                RSI=row.get('RSI'),
                MACD=row.get('MACD'),
                MACD_Signal=row.get('MACD_Signal'),
                MACD_Hist=row.get('MACD_Histogram'),
                SMA_20=row.get('SMA_20'),
                SMA_50=row.get('SMA_50'),
                Bollinger_High=row.get('Bollinger_Upper'),
                Bollinger_Low=row.get('Bollinger_Lower'),
                Bollinger_MA=row.get('Bollinger_Middle'),
                Volume_MA_20=row.get('Volume_MA_20'),
                ATR=row.get('ATR'),
                Stochastic_K=row.get('Stochastic_K'),
                Stochastic_D=row.get('Stochastic_D'),
                squeeze_on=bool(row.get('squeeze_on')),
                halftrend_signal=row.get('halftrend_signal'),
                resistance_level_50d=row.get('resistance_level_50d'),
                resistance_broken=bool(row.get('resistance_broken'))
            )
            db_session.add(indicator) # ğŸ‘ˆ ÙÙ‚Ø· Add
            inserts_count += 1

    if inserts_count > 0 or updates_count > 0:
        logger.info(f"âœ… Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§ÛŒ Ù†Ù…Ø§Ø¯ {symbol_id_str} Ø¨Ù‡ Session Ø§Ø¶Ø§ÙÙ‡/Ø¢Ù¾Ø¯ÛŒØª Ø´Ø¯Ù†Ø¯. (Ø¯Ø±Ø¬: {inserts_count}ØŒ Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ: {updates_count})")
    else:
        logger.debug(f"â„¹ï¸ Ù‡ÛŒÚ† Ø¯Ø§Ø¯Ù‡ Ø¬Ø¯ÛŒØ¯ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§Ø¯ {symbol_id_str} ÛŒØ§ÙØª Ù†Ø´Ø¯.")


# -----------------------------------------------------------
# ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ Ø§Ø¬Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ ØªÚ©Ù†ÛŒÚ©Ø§Ù„
# -----------------------------------------------------------

def run_technical_analysis(
    db_session: Optional[Session] = None,
    limit: int = None, 
    symbols_list: list = None, 
    batch_size: int = DEFAULT_BATCH_SIZE
) -> Tuple[int, str]:
    """
    Ø§Ø¬Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ ØªÚ©Ù†ÛŒÚ©Ø§Ù„ Ø¯Ø± Ø¨Ú†â€ŒÙ‡Ø§ÛŒ Ú©ÙˆÚ†Ú©.
    """
    with session_scope(external_session=db_session) as session:
        try:
            logger.info("ğŸ“ˆ Ø´Ø±ÙˆØ¹ ØªØ­Ù„ÛŒÙ„ ØªÚ©Ù†ÛŒÚ©Ø§Ù„...")

            # ğŸ’¥ Ø±Ø§Ù‡ Ø­Ù„: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² session Ù…Ø³ØªÙ‚Ù„ Ø¨Ø±Ø§ÛŒ ÛŒØ§ÙØªÙ† Ù†Ù…Ø§Ø¯Ù‡Ø§
            independent_session = None
            try:
                # Ø§ÛŒØ¬Ø§Ø¯ ÛŒÚ© session Ú©Ø§Ù…Ù„Ø§Ù‹ Ù…Ø³ØªÙ‚Ù„
                factory = _get_session_local()
                independent_session = factory()
                
                # ÛŒØ§ÙØªÙ† Ù†Ù…Ø§Ø¯Ù‡Ø§ Ø¨Ø§ session Ù…Ø³ØªÙ‚Ù„
                symbol_query = independent_session.query(ComprehensiveSymbolData.symbol_id)
                
                if symbols_list:
                    symbols_list_str = [str(sym) for sym in symbols_list]
                    symbol_query = symbol_query.filter(ComprehensiveSymbolData.symbol_id.in_(symbols_list_str))

                all_symbols = [row[0] for row in symbol_query.all()]
                logger.info(f"ğŸ” [SESSION-INDEPENDENT] {len(all_symbols)} Ù†Ù…Ø§Ø¯ ÛŒØ§ÙØª Ø´Ø¯")
                
                # Ø§Ú¯Ø± Ø¨Ø§Ø²Ù‡Ù… ØµÙØ± Ø¨ÙˆØ¯ØŒ Ø§Ø² HistoricalData Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†
                if not all_symbols:
                    logger.warning("âš ï¸ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² HistoricalData Ø¨Ø±Ø§ÛŒ ÛŒØ§ÙØªÙ† Ù†Ù…Ø§Ø¯Ù‡Ø§...")
                    historical_query = independent_session.query(distinct(HistoricalData.symbol_id))
                    all_symbols = [row[0] for row in historical_query.all()]
                    logger.info(f"ğŸ” [HISTORICAL-FALLBACK] {len(all_symbols)} Ù†Ù…Ø§Ø¯ ÛŒØ§ÙØª Ø´Ø¯")
                    
            except Exception as e:
                logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± session Ù…Ø³ØªÙ‚Ù„: {e}")
                # Fallback: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² session Ø§ØµÙ„ÛŒ
                symbol_query = session.query(ComprehensiveSymbolData.symbol_id)
                all_symbols = [row[0] for row in symbol_query.all()] if symbol_query else []
                
            finally:
                if independent_session:
                    independent_session.close()

            total_symbols = len(all_symbols)
            logger.info(f"ğŸ” Ù†Ù‡Ø§ÛŒÛŒ: {total_symbols} Ù†Ù…Ø§Ø¯ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ ØªÚ©Ù†ÛŒÚ©Ø§Ù„")

            if total_symbols == 0:
                logger.error("âŒ Ù‡ÛŒÚ† Ù†Ù…Ø§Ø¯ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ ÛŒØ§ÙØª Ù†Ø´Ø¯!")
                return 0, "Ù‡ÛŒÚ† Ù†Ù…Ø§Ø¯ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ ÛŒØ§ÙØª Ù†Ø´Ø¯"

            if limit is not None:
                all_symbols = all_symbols[:limit]
                total_symbols = len(all_symbols)
                logger.info(f"Ù…Ø­Ø¯ÙˆØ¯ÛŒØª {limit} Ø§Ø¹Ù…Ø§Ù„ Ø´Ø¯. {total_symbols} Ù†Ù…Ø§Ø¯ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ÛŒâ€ŒØ´ÙˆØ¯.")

            processed_count = 0
            success_count = 0
            error_count = 0

            for i in range(0, total_symbols, batch_size):
                batch_symbols = all_symbols[i:i + batch_size]
                logger.info(f"ğŸ“¦ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ú† {i // batch_size + 1}: Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ {i + 1} ØªØ§ {min(i + batch_size, total_symbols)}")

                # ğŸ”§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² batch symbols Ø¨Ø±Ø§ÛŒ Ú©ÙˆØ¦Ø±ÛŒ
                query = session.query(
                    HistoricalData.symbol_id, HistoricalData.symbol_name, HistoricalData.date, HistoricalData.jdate, 
                    HistoricalData.open, HistoricalData.close, HistoricalData.high, HistoricalData.low, 
                    HistoricalData.volume, HistoricalData.final, HistoricalData.yesterday_price, HistoricalData.plc, 
                    HistoricalData.plp, HistoricalData.pcc, HistoricalData.pcp, HistoricalData.mv, 
                    HistoricalData.buy_count_i, HistoricalData.buy_count_n, HistoricalData.sell_count_i, 
                    HistoricalData.sell_count_n, HistoricalData.buy_i_volume, HistoricalData.buy_n_volume, 
                    HistoricalData.sell_i_volume, HistoricalData.sell_n_volume
                ).filter(HistoricalData.symbol_id.in_(batch_symbols))

                query = query.order_by(HistoricalData.symbol_id, HistoricalData.date)
                historical_data = query.all()

                if not historical_data:
                    logger.warning(f"âš ï¸ Ù‡ÛŒÚ† Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø¨Ú† {i // batch_size + 1} ÛŒØ§ÙØª Ù†Ø´Ø¯.")
                    continue
                
                columns = [
                    'symbol_id', 'symbol_name', 'date', 'jdate', 'open', 'close', 'high', 'low', 'volume',
                    'final', 'yesterday_price', 'plc', 'plp', 'pcc', 'pcp', 'mv',
                    'buy_count_i', 'buy_count_n', 'sell_count_i', 'sell_count_n',
                    'buy_i_volume', 'buy_n_volume', 'sell_i_volume', 'sell_n_volume'
                ]
                df = pd.DataFrame(historical_data, columns=columns)
                
                if df.empty:
                    logger.warning(f"âš ï¸ DataFrame Ø®Ø§Ù„ÛŒ Ø¨Ø±Ø§ÛŒ Ø¨Ú† {i // batch_size + 1}")
                    continue
                    
                grouped = df.groupby('symbol_id')

                for symbol_id, group_df in grouped:
                    processed_count += 1
                    try:
                        if len(group_df) < 5:
                            logger.debug(f"âš ï¸ Ø¯Ø§Ø¯Ù‡ Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§Ø¯ {symbol_id} ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯ ({len(group_df)} Ø±Ú©ÙˆØ±Ø¯)")
                            continue
                            
                        df_indicators = calculate_all_indicators(group_df.copy())
                        save_technical_indicators(session, symbol_id, df_indicators)  # âœ… Ø§Ú©Ù†ÙˆÙ† ØªØ¹Ø±ÛŒÙ Ø´Ø¯Ù‡
                        success_count += 1

                        if processed_count % 10 == 0:
                            logger.info(f"ğŸ“Š Ù¾ÛŒØ´Ø±ÙØª ØªØ­Ù„ÛŒÙ„: {processed_count}/{total_symbols} Ù†Ù…Ø§Ø¯")

                    except Exception as e:
                        error_count += 1
                        logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ Ù†Ù…Ø§Ø¯ {symbol_id}: {e}", exc_info=True)

                del df
                del historical_data
                cleanup_memory()

            logger.info(f"âœ… ØªØ­Ù„ÛŒÙ„ ØªÚ©Ù†ÛŒÚ©Ø§Ù„ Ú©Ø§Ù…Ù„ Ø´Ø¯. Ù…ÙˆÙÙ‚: {success_count} | Ø®Ø·Ø§: {error_count}")
            return success_count, f"ØªØ­Ù„ÛŒÙ„ Ú©Ø§Ù…Ù„ Ø´Ø¯. {success_count} Ù…ÙˆÙÙ‚ØŒ {error_count} Ø®Ø·Ø§"

        except Exception as e:
            error_msg = f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø¬Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ ØªÚ©Ù†ÛŒÚ©Ø§Ù„: {e}"
            logger.error(error_msg, exc_info=True)
            return 0, error_msg


# -----------------------------------------------------------
# ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ Ø§Ø¬Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø´Ù…Ø¹ÛŒ
# -----------------------------------------------------------

def run_candlestick_detection(
    db_session: Optional[Session] = None,
    limit: int = None, 
    symbols_list: list = None
) -> int:
    """
    Ø§Ø¬Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø´Ù…Ø¹ÛŒ.
    Ù…Ø¯ÛŒØ±ÛŒØª Session Ø§Ú©Ù†ÙˆÙ† Ø¨Ù‡ ØµÙˆØ±Øª Ø®ÙˆØ¯Ú©Ø§Ø± ØªÙˆØ³Ø· 'session_scope' Ø§Ù†Ø¬Ø§Ù… Ù…ÛŒâ€ŒØ´ÙˆØ¯.
    """
    with session_scope(external_session=db_session) as session:
        try:
            logger.info("ğŸ•¯ï¸ Ø´Ø±ÙˆØ¹ ØªØ´Ø®ÛŒØµ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø´Ù…Ø¹ÛŒ...")
            
            # ğŸ”§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² session Ù…Ø³ØªÙ‚Ù„ Ø¨Ø±Ø§ÛŒ ÛŒØ§ÙØªÙ† Ù†Ù…Ø§Ø¯Ù‡Ø§
            independent_session = None
            try:
                factory = _get_session_local()
                independent_session = factory()
                
                base_query = independent_session.query(ComprehensiveSymbolData.symbol_id)
                
                if symbols_list:
                    symbols_list_str = [str(sym) for sym in symbols_list]
                    base_query = base_query.filter(ComprehensiveSymbolData.symbol_id.in_(symbols_list_str))
                    
                symbol_ids_raw = [s[0] for s in base_query.all()]
                symbol_ids_to_process = [str(symbol_id) for symbol_id in symbol_ids_raw]
                
                # Fallback Ø¨Ù‡ HistoricalData
                if not symbol_ids_to_process:
                    logger.warning("âš ï¸ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² HistoricalData Ø¨Ø±Ø§ÛŒ ÛŒØ§ÙØªÙ† Ù†Ù…Ø§Ø¯Ù‡Ø§...")
                    historical_query = independent_session.query(distinct(HistoricalData.symbol_id))
                    symbol_ids_raw = [s[0] for s in historical_query.all()]
                    symbol_ids_to_process = [str(symbol_id) for symbol_id in symbol_ids_raw]
                    
            except Exception as e:
                logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± session Ù…Ø³ØªÙ‚Ù„: {e}")
                base_query = session.query(ComprehensiveSymbolData.symbol_id)
                symbol_ids_raw = [s[0] for s in base_query.all()] if base_query else []
                symbol_ids_to_process = [str(symbol_id) for symbol_id in symbol_ids_raw]
                
            finally:
                if independent_session:
                    independent_session.close()
            
            if not symbol_ids_to_process:
                logger.warning("âš ï¸ Ù‡ÛŒÚ† Ù†Ù…Ø§Ø¯ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø´Ù…Ø¹ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
                return 0
                
            if limit is not None:
                symbol_ids_to_process = symbol_ids_to_process[:limit]
                
            logger.info(f"ğŸ” ÛŒØ§ÙØª Ø´Ø¯ {len(symbol_ids_to_process)} Ù†Ù…Ø§Ø¯ Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø´Ù…Ø¹ÛŒ")

            success_count = 0
            records_to_insert = []
            processed_count = 0
            today_jdate_str = None

            for symbol_id in symbol_ids_to_process:
                try:
                    historical_data_query = session.query(HistoricalData).filter(
                        HistoricalData.symbol_id == symbol_id
                    ).order_by(HistoricalData.date.desc()).limit(30)
                    
                    historical_data = historical_data_query.all() 
                    
                    if len(historical_data) < 5:
                        logger.debug(f"âš ï¸ Ø¯Ø§Ø¯Ù‡ Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§Ø¯ {symbol_id} ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯ ({len(historical_data)} Ø±Ú©ÙˆØ±Ø¯)")
                        continue 

                    df = pd.DataFrame([row.__dict__ for row in historical_data])
                    if '_sa_instance_state' in df.columns:
                        df = df.drop(columns=['_sa_instance_state']) 
                    
                    df.sort_values(by='date', inplace=True) 

                    today_record_dict = df.iloc[-1].to_dict()
                    yesterday_record_dict = df.iloc[-2].to_dict()
                    
                    patterns = check_candlestick_patterns(
                        today_record_dict, 
                        yesterday_record_dict, 
                        df
                    )
                    
                    if patterns:
                        now = datetime.now()
                        current_jdate = today_record_dict['jdate']
                        if today_jdate_str is None:
                            today_jdate_str = current_jdate

                        for pattern in patterns:
                            records_to_insert.append({
                                'symbol_id': symbol_id,
                                'jdate': current_jdate,
                                'pattern_name': pattern,
                                'created_at': now, 
                                'updated_at': now
                            })
                        success_count += 1
                        logger.debug(f"âœ… Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ ÛŒØ§ÙØª Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§Ø¯ {symbol_id}: {patterns}")
                    
                    processed_count += 1
                    if processed_count % 100 == 0:
                        logger.info(f"ğŸ•¯ï¸ Ù¾ÛŒØ´Ø±ÙØª ØªØ´Ø®ÛŒØµ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø´Ù…Ø¹ÛŒ: {processed_count}/{len(symbol_ids_to_process)} Ù†Ù…Ø§Ø¯")

                except Exception as e:
                    logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ØªØ´Ø®ÛŒØµ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø´Ù…Ø¹ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§Ø¯ {symbol_id}: {e}", exc_info=True)
                    
            logger.info(f"âœ… ØªØ´Ø®ÛŒØµ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø´Ù…Ø¹ÛŒ Ø¨Ø±Ø§ÛŒ {success_count} Ù†Ù…Ø§Ø¯ (Ø¨Ø§ {len(records_to_insert)} Ø§Ù„Ú¯Ùˆ) Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯.")
                    
            # 3. Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬ Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³ (ØªØ±Ø§Ú©Ù†Ø´ ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡)
            if records_to_insert:
                if not today_jdate_str:
                    today_jdate_str = records_to_insert[0]['jdate'] 

                processed_symbol_ids_set = list({record['symbol_id'] for record in records_to_insert})
                
                # Ø¨) Ø­Ø°Ù Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒ
                logger.info(f"ğŸ—‘ï¸ Ø¯Ø± Ø­Ø§Ù„ Ø­Ø°Ù Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø´Ù…Ø¹ÛŒ Ù‚Ø¨Ù„ÛŒ Ø¨Ø±Ø§ÛŒ {len(processed_symbol_ids_set)} Ù†Ù…Ø§Ø¯ Ø¯Ø± ØªØ§Ø±ÛŒØ® {today_jdate_str}...")
                
                session.query(CandlestickPatternDetection).filter(
                    CandlestickPatternDetection.symbol_id.in_(processed_symbol_ids_set),
                    CandlestickPatternDetection.jdate == today_jdate_str
                ).delete(synchronize_session=False) 
                
                # Ø¬) Ø¯Ø±Ø¬ Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯
                session.bulk_insert_mappings(CandlestickPatternDetection, records_to_insert)
                logger.info(f"âœ… {len(records_to_insert)} Ø§Ù„Ú¯ÙˆÛŒ Ø´Ù…Ø¹ÛŒ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¯Ø± Session Ø¯Ø±Ø¬ Ø´Ø¯.")
                
            else:
                logger.info("â„¹ï¸ Ù‡ÛŒÚ† Ø§Ù„Ú¯ÙˆÛŒ Ø´Ù…Ø¹ÛŒ Ø¬Ø¯ÛŒØ¯ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.")

            return success_count

        except Exception as e:
             logger.error(f"âŒ Ø®Ø·Ø§ÛŒ Ú©Ù„ÛŒ Ø¯Ø± Ø§Ø¬Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø´Ù…Ø¹ÛŒ: {e}", exc_info=True)
             return 0

# -----------------------------------------------------------
# ØªÙˆØ§Ø¨Ø¹ Export
# -----------------------------------------------------------

__all__ = [
    # ØªÙˆØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ Ø§Ø¬Ø±Ø§ Ú©Ù†Ù†Ø¯Ù‡ ØªØ­Ù„ÛŒÙ„
    'run_technical_analysis',
    'run_candlestick_detection',
    
    # ØªÙˆØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø²
    # 'get_session_local', (Ø­Ø°Ù Ø´Ø¯)
    'cleanup_memory',
    'save_technical_indicators'
]
