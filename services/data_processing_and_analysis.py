# -*- coding: utf-8 -*-
# services/data_processing_and_analysis.py
# Ù…Ø³Ø¦ÙˆÙ„ÛŒØª: Ø§Ø¬Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ ØªÚ©Ù†ÛŒÚ©Ø§Ù„ Ùˆ ØªØ´Ø®ÛŒØµ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø´Ù…Ø¹ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³.
# Ø§ÛŒÙ† ÙØ§ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø±Ø§ ÙˆØ§Ú©Ø´ÛŒ Ù†Ù…ÛŒâ€ŒÚ©Ù†Ø¯ØŒ Ø¨Ù„Ú©Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡ (HistoricalData) Ø±Ø§ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù†Ø¯ØŒ
# ØªØ­Ù„ÛŒÙ„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ùˆ Ù†ØªØ§ÛŒØ¬ Ø±Ø§ Ø¯Ø± Ø¬Ø¯Ø§ÙˆÙ„ (TechnicalIndicatorData, CandlestickPatternDetection) Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.

import logging
import gc
import psutil
import time
import pandas as pd
import numpy as np
from datetime import datetime, date, timedelta
from typing import Dict, List, Optional, Tuple, Any, Union

from sqlalchemy import func, distinct, text
from sqlalchemy.orm import sessionmaker, Session
from sqlalchemy.exc import SQLAlchemyError
from sqlalchemy import or_

from flask import current_app

# --- ÙˆØ§Ø¨Ø³ØªÚ¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù¾Ø±ÙˆÚ˜Ù‡ ---
from extensions import db
from models import (
    HistoricalData, 
    TechnicalIndicatorData, 
    CandlestickPatternDetection, 
    ComprehensiveSymbolData
)

from services.technical_analysis_utils import (
        calculate_all_indicators, 
        check_candlestick_patterns
    )

# --- ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù„Ø§Ú¯ÛŒÙ†Ú¯ ---
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

# --- Ø«Ø§Ø¨Øªâ€ŒÙ‡Ø§ÛŒ Ù…Ø¯ÛŒØ±ÛŒØª Ø­Ø§ÙØ¸Ù‡ Ùˆ Ø¨Ú† ---
DEFAULT_BATCH_SIZE = 200  # for DB bulk ops & symbol processing
MEMORY_LIMIT_MB = 1500  # warn threshold

# -----------------------------------------------------------
# ØªÙˆØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ (Session Ùˆ Ù…Ø¯ÛŒØ±ÛŒØª Ø­Ø§ÙØ¸Ù‡)
# -----------------------------------------------------------

def get_session_local():
    """Ø§ÛŒØ¬Ø§Ø¯ session local Ø¨Ø§ application context"""
    try:
        from flask import current_app
        with current_app.app_context():
            return sessionmaker(bind=db.engine)()
    except RuntimeError:
        # Ø§Ú¯Ø± Ø®Ø§Ø±Ø¬ Ø§Ø² application context Ù‡Ø³ØªÛŒÙ…
        try:
            # ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ú¯Ø±ÙØªÙ† Ù…ÙˆØªÙˆØ± Ø§Ø² db.get_engine() Ø§Ú¯Ø± Ø¯Ø± ÙØ§ÛŒÙ„ extensions Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ø´Ø¯
            return sessionmaker(bind=db.get_engine())()
        except AttributeError:
            # Fallback Ù†Ù‡Ø§ÛŒÛŒ Ø§Ú¯Ø± db.get_engine() ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯
            logger.error("Could not create session outside of Flask context and db.get_engine() not found.")
            # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² db.session Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¯Ø± Ø³Ù†Ø§Ø±ÛŒÙˆÙ‡Ø§ÛŒ Ø®Ø§ØµÛŒ Ú©Ø§Ø± Ú©Ù†Ø¯ Ø§Ù…Ø§ Ø§Ù…Ù† Ù†ÛŒØ³Øª
            return db.session 


def check_memory_usage_mb() -> float:
    """Return current process memory usage in MB (if psutil available)."""
    try:
        if psutil:
            proc = psutil.Process()
            mem = proc.memory_info().rss / (1024 * 1024)
            return mem
        else:
            return 0.0
    except Exception as e:
        logger.debug("Memory check failed: %s", e)
        return 0.0

def cleanup_memory():
    """Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ø­Ø§ÙØ¸Ù‡"""
    try:
        gc.collect()
        current_memory = check_memory_usage_mb()
        if current_memory > MEMORY_LIMIT_MB:
            logger.warning(f"âš ï¸ Ù…ØµØ±Ù Ø­Ø§ÙØ¸Ù‡ Ø¨Ø§Ù„Ø§: {current_memory:.2f} MB")
    except Exception as e:
        logger.debug(f"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ø­Ø§ÙØ¸Ù‡: {e}")

# -----------------------------------------------------------
# ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ Ø§Ø¬Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ ØªÚ©Ù†ÛŒÚ©Ø§Ù„
# -----------------------------------------------------------

def run_technical_analysis(
    db_session: Session, 
    limit: int = None, 
    symbols_list: list = None, 
    batch_size: int = DEFAULT_BATCH_SIZE
) -> Tuple[int, str]:
    """
    Ø§Ø¬Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ ØªÚ©Ù†ÛŒÚ©Ø§Ù„ Ø¯Ø± Ø¨Ú†â€ŒÙ‡Ø§ÛŒ Ú©ÙˆÚ†Ú© Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ù…ØµØ±Ù Ø²ÛŒØ§Ø¯ Ø­Ø§ÙØ¸Ù‡.
    Ø§ÛŒÙ† ØªØ§Ø¨Ø¹ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø±Ø§ Ø§Ø² HistoricalData Ù…ÛŒâ€ŒØ®ÙˆØ§Ù†Ø¯ØŒ Ø¨Ø§ technical_analysis_utils.calculate_all_indicators
    ØªØ­Ù„ÛŒÙ„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ùˆ Ø¨Ø§ save_technical_indicators Ø¯Ø± TechnicalIndicatorData Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒÙ†Ù…Ø§ÛŒØ¯.
    """
    try:
        logger.info("ğŸ“ˆ Ø´Ø±ÙˆØ¹ ØªØ­Ù„ÛŒÙ„ ØªÚ©Ù†ÛŒÚ©Ø§Ù„...")

        # Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒØ³Øª ÛŒÚ©ØªØ§ Ø§Ø² Ù†Ù…Ø§Ø¯Ù‡Ø§ Ø¯Ø± HistoricalData
        symbol_ids_query = db_session.query(HistoricalData.symbol_id).distinct()
        
        if symbols_list:
            # symbols_list Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø´Ø§Ù…Ù„ symbol_id (str) ÛŒØ§ id (int) Ø¨Ø§Ø´Ø¯
            # Ù…Ø§ Ø¯Ø± Ø§ÛŒÙ†Ø¬Ø§ Ø¨Ù‡ symbol_id (Ú©Ù‡ Ø¯Ø± HistoricalData Ø§Ø³Øª) Ù†ÛŒØ§Ø² Ø¯Ø§Ø±ÛŒÙ…
            symbol_ids_query = symbol_ids_query.filter(HistoricalData.symbol_id.in_(symbols_list))

        all_symbols = [row[0] for row in symbol_ids_query.all()]
        
        total_symbols = len(all_symbols)
        logger.info(f"ğŸ” Ù…Ø¬Ù…ÙˆØ¹ {total_symbols} Ù†Ù…Ø§Ø¯ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ ØªÚ©Ù†ÛŒÚ©Ø§Ù„ ÛŒØ§ÙØª Ø´Ø¯")

        if limit is not None:
            all_symbols = all_symbols[:limit]
            total_symbols = len(all_symbols)
            logger.info(f"Ù…Ø­Ø¯ÙˆØ¯ÛŒØª {limit} Ø§Ø¹Ù…Ø§Ù„ Ø´Ø¯. {total_symbols} Ù†Ù…Ø§Ø¯ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ÛŒâ€ŒØ´ÙˆØ¯.")

        processed_count = 0
        success_count = 0
        error_count = 0

        # Ø§Ø¬Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¯Ø± Ø¨Ú†â€ŒÙ‡Ø§ÛŒ NØªØ§ÛŒÛŒ
        for i in range(0, total_symbols, batch_size):
            batch_symbols = all_symbols[i:i + batch_size]
            logger.info(f"ğŸ“¦ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ú† {i // batch_size + 1}: Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ {i + 1} ØªØ§ {min(i + batch_size, total_symbols)}")

            # ÙˆØ§Ú©Ø´ÛŒ ØªÙ…Ø§Ù… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ§Ø±ÛŒØ®ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø² Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ø¨Ú†
            query = db_session.query(
                HistoricalData.symbol_id, HistoricalData.symbol_name, HistoricalData.date, HistoricalData.jdate, 
                HistoricalData.open, HistoricalData.close, HistoricalData.high, HistoricalData.low, 
                HistoricalData.volume, HistoricalData.final, HistoricalData.yesterday_price, HistoricalData.plc, 
                HistoricalData.plp, HistoricalData.pcc, HistoricalData.pcp, HistoricalData.mv, 
                HistoricalData.buy_count_i, HistoricalData.buy_count_n, HistoricalData.sell_count_i, 
                HistoricalData.sell_count_n, HistoricalData.buy_i_volume, HistoricalData.buy_n_volume, 
                HistoricalData.sell_i_volume, HistoricalData.sell_n_volume
            ).filter(HistoricalData.symbol_id.in_(batch_symbols))

            query = query.order_by(HistoricalData.symbol_id, HistoricalData.date)
            historical_data = query.all()

            if not historical_data:
                logger.warning(f"âš ï¸ Ù‡ÛŒÚ† Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ø¨Ú† ÛŒØ§ÙØª Ù†Ø´Ø¯.")
                continue

            # ØªØ¹Ø±ÛŒÙ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ú©ÙˆØ¦Ø±ÛŒ Ø¨Ø§Ù„Ø§
            columns = [
                'symbol_id', 'symbol_name', 'date', 'jdate', 'open', 'close', 'high', 'low', 'volume',
                'final', 'yesterday_price', 'plc', 'plp', 'pcc', 'pcp', 'mv',
                'buy_count_i', 'buy_count_n', 'sell_count_i', 'sell_count_n',
                'buy_i_volume', 'buy_n_volume', 'sell_i_volume', 'sell_n_volume'
            ]
            df = pd.DataFrame(historical_data, columns=columns)

            grouped = df.groupby('symbol_id')

            for symbol_id, group_df in grouped:
                processed_count += 1
                try:
                    # --- ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ ØªØ§Ø¨Ø¹ ØªØ­Ù„ÛŒÙ„ Ø§Ø² Utils ---
                    # group_df Ø´Ø§Ù…Ù„ ØªÙ…Ø§Ù… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ§Ø±ÛŒØ®ÛŒ Ù…Ø±ØªØ¨ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ ÛŒÚ© Ù†Ù…Ø§Ø¯ Ø§Ø³Øª
                    df_indicators = calculate_all_indicators(group_df.copy())
                    
                    # --- Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬ Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³ ---
                    save_technical_indicators(db_session, symbol_id, df_indicators)
                    success_count += 1

                    if processed_count % 10 == 0:
                         logger.info(f"ğŸ“Š Ù¾ÛŒØ´Ø±ÙØª ØªØ­Ù„ÛŒÙ„: {processed_count}/{total_symbols} Ù†Ù…Ø§Ø¯")

                except Exception as e:
                    error_count += 1
                    logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ Ù†Ù…Ø§Ø¯ {symbol_id}: {e}", exc_info=True)
                    db_session.rollback()

            # ğŸ”¹ Ø¢Ø²Ø§Ø¯Ø³Ø§Ø²ÛŒ Ø­Ø§ÙØ¸Ù‡â€ŒÛŒ DataFrame Ø¨Ø¹Ø¯ Ø§Ø² Ù‡Ø± Ø¨Ú†
            del df
            del historical_data
            cleanup_memory()

        logger.info(f"âœ… ØªØ­Ù„ÛŒÙ„ ØªÚ©Ù†ÛŒÚ©Ø§Ù„ Ú©Ø§Ù…Ù„ Ø´Ø¯. Ù…ÙˆÙÙ‚: {success_count} | Ø®Ø·Ø§: {error_count}")
        return success_count, f"ØªØ­Ù„ÛŒÙ„ Ú©Ø§Ù…Ù„ Ø´Ø¯. {success_count} Ù…ÙˆÙÙ‚ØŒ {error_count} Ø®Ø·Ø§"

    except Exception as e:
        error_msg = f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø¬Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ ØªÚ©Ù†ÛŒÚ©Ø§Ù„: {e}"
        logger.error(error_msg, exc_info=True)
        db_session.rollback()
        return 0, error_msg

# -----------------------------------------------------------
# ØªØ§Ø¨Ø¹ Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù†ØªØ§ÛŒØ¬ ØªØ­Ù„ÛŒÙ„ ØªÚ©Ù†ÛŒÚ©Ø§Ù„
# -----------------------------------------------------------

def save_technical_indicators(db_session: Session, symbol_id: Union[int, str], df: pd.DataFrame):
    """
    Ø°Ø®ÛŒØ±Ù‡ (Ø¯Ø±Ø¬ ÛŒØ§ Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ) Ù†ØªØ§ÛŒØ¬ ØªØ­Ù„ÛŒÙ„ ØªÚ©Ù†ÛŒÚ©Ø§Ù„ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¯Ù‡ Ø¯Ø± Ø¬Ø¯ÙˆÙ„ TechnicalIndicatorData.
    ğŸ”§ Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² Ù‡Ø± Ø¯Ùˆ Ù†ÙˆØ¹ Ø¯Ø§Ø¯Ù‡ symbol_id (int Ùˆ string)
    """
    # ğŸ”§ Ø§ØµÙ„Ø§Ø­: ØªØ¶Ù…ÛŒÙ† string Ø¨ÙˆØ¯Ù† symbol_id Ø¨Ø¯ÙˆÙ† Ø¯Ø± Ù†Ø¸Ø± Ú¯Ø±ÙØªÙ† Ù†ÙˆØ¹ ÙˆØ±ÙˆØ¯ÛŒ
    symbol_id_str = str(symbol_id)
    
    logger.debug(f"ğŸ’¾ Ø°Ø®ÛŒØ±Ù‡ Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§Ø¯: {symbol_id_str} (ÙˆØ±ÙˆØ¯ÛŒ: {symbol_id}, Ù†ÙˆØ¹: {type(symbol_id)})")

    # ğŸ”§ Ø§ØµÙ„Ø§Ø­: ØªØ¶Ù…ÛŒÙ† ÙˆØ¬ÙˆØ¯ Ø³ØªÙˆÙ† symbol_id Ø¨Ù‡ ØµÙˆØ±Øª string
    if 'symbol_id' not in df.columns:
        df['symbol_id'] = symbol_id_str
    else:
        # ØªØ¨Ø¯ÛŒÙ„ ØªÙ…Ø§Ù… symbol_id Ù‡Ø§ Ø¨Ù‡ string Ø¨Ø±Ø§ÛŒ ÛŒÚ©Ù¾Ø§Ø±Ú†Ú¯ÛŒ
        df['symbol_id'] = df['symbol_id'].astype(str)

    # Ø­Ø°Ù ØªÚ©Ø±Ø§Ø±ÛŒâ€ŒÙ‡Ø§ ÙÙ‚Ø· Ø¯Ø§Ø®Ù„ DataFrame
    df_unique = df.drop_duplicates(subset=['symbol_id', 'jdate'], keep='last').copy()
    
    # ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† Ø±Ø¯ÛŒÙâ€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§ÛŒ Ø§ØµÙ„ÛŒ (Ù…Ø§Ù†Ù†Ø¯ RSI) Ø¨Ø±Ø§ÛŒ Ø¢Ù†â€ŒÙ‡Ø§ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù†Ø´Ø¯Ù‡ (Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ø±ÙˆØ²Ù‡Ø§ÛŒ Ø§ÙˆÙ„)
    df_to_save = df_unique.dropna(subset=['RSI', 'MACD', 'jdate'])

    if df_to_save.empty:
        logger.debug(f"âš ï¸ Ù¾Ø³ Ø§Ø² Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒØŒ Ù‡ÛŒÚ† Ø³Ø·Ø± Ù…Ø¹ØªØ¨Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§ÛŒ Ù†Ù…Ø§Ø¯ {symbol_id_str} ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø´Øª.")
        return
    
    updates_count = 0
    inserts_count = 0
    
    try: 
        # ØªØ¨Ø¯ÛŒÙ„ DataFrame Ø¨Ù‡ Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Upsert
        records_dict = df_to_save.to_dict('records')
        
        # ğŸ”§ Ø§ØµÙ„Ø§Ø­: ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† Ø¨Ø§ symbol_id Ø¨Ù‡ ØµÙˆØ±Øª string
        existing_indicators_query = db_session.query(TechnicalIndicatorData).filter(
            TechnicalIndicatorData.symbol_id == symbol_id_str
        )
        
        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² jdate Ø¨Ø±Ø§ÛŒ Ø§ÛŒØ¬Ø§Ø¯ ÛŒÚ© map Ø¬Ù‡Øª Ø¯Ø³ØªØ±Ø³ÛŒ Ø³Ø±ÛŒØ¹
        existing_map = {
            indicator.jdate: indicator 
            for indicator in existing_indicators_query
        }

        for row in records_dict:
            jdate = row.get('jdate')
            if not jdate:
                continue

            # ğŸ”§ Ø§ØµÙ„Ø§Ø­: ØªØ¶Ù…ÛŒÙ† string Ø¨ÙˆØ¯Ù† symbol_id Ø¯Ø± Ù‡Ø± Ø±Ú©ÙˆØ±Ø¯
            row['symbol_id'] = str(row.get('symbol_id', symbol_id_str))

            existing = existing_map.get(jdate)

            # 2. Ù…Ù†Ø·Ù‚ Ø¯Ø±Ø¬ ÛŒØ§ Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ (Upsert)
            if existing:
                # âœ… Update Ø±Ú©ÙˆØ±Ø¯ Ù…ÙˆØ¬ÙˆØ¯
                existing.close_price = row.get('close')
                existing.RSI = row.get('RSI')
                existing.MACD = row.get('MACD')
                existing.MACD_Signal = row.get('MACD_Signal')
                existing.MACD_Hist = row.get('MACD_Histogram')
                existing.SMA_20 = row.get('SMA_20')
                existing.SMA_50 = row.get('SMA_50')
                existing.Bollinger_High = row.get('Bollinger_Upper')
                existing.Bollinger_Low = row.get('Bollinger_Lower')
                existing.Bollinger_MA = row.get('Bollinger_Middle')
                existing.Volume_MA_20 = row.get('Volume_MA_20')
                existing.ATR = row.get('ATR')
                existing.Stochastic_K = row.get('Stochastic_K')
                existing.Stochastic_D = row.get('Stochastic_D')
                existing.squeeze_on = bool(row.get('squeeze_on'))
                existing.halftrend_signal = row.get('halftrend_signal') # Ø¯Ø± utils Ø¬Ø¯ÛŒØ¯ halftrend_trend Ø§Ø³Øª
                existing.resistance_level_50d = row.get('resistance_level_50d')
                existing.resistance_broken = bool(row.get('resistance_broken'))
                
                updates_count += 1
            else:
                # âœ… Insert Ø±Ú©ÙˆØ±Ø¯ Ø¬Ø¯ÛŒØ¯
                indicator = TechnicalIndicatorData(
                    symbol_id=row['symbol_id'],  # ğŸ”§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² symbol_id ØªØ¶Ù…ÛŒÙ† Ø´Ø¯Ù‡ string
                    jdate=jdate,
                    close_price=row.get('close'),
                    RSI=row.get('RSI'),
                    MACD=row.get('MACD'),
                    MACD_Signal=row.get('MACD_Signal'),
                    MACD_Hist=row.get('MACD_Histogram'),
                    SMA_20=row.get('SMA_20'),
                    SMA_50=row.get('SMA_50'),
                    Bollinger_High=row.get('Bollinger_Upper'),
                    Bollinger_Low=row.get('Bollinger_Lower'),
                    Bollinger_MA=row.get('Bollinger_Middle'),
                    Volume_MA_20=row.get('Volume_MA_20'),
                    ATR=row.get('ATR'),
                    Stochastic_K=row.get('Stochastic_K'),
                    Stochastic_D=row.get('Stochastic_D'),
                    squeeze_on=bool(row.get('squeeze_on')),
                    halftrend_signal=row.get('halftrend_signal'), # Ø¯Ø± utils Ø¬Ø¯ÛŒØ¯ halftrend_trend Ø§Ø³Øª
                    resistance_level_50d=row.get('resistance_level_50d'),
                    resistance_broken=bool(row.get('resistance_broken'))
                )
                db_session.add(indicator)
                inserts_count += 1

        # Commit Ú©Ø±Ø¯Ù† ØªØ±Ø§Ú©Ù†Ø´ Ù¾Ø³ Ø§Ø² Ø§ØªÙ…Ø§Ù… Ø­Ù„Ù‚Ù‡
        db_session.commit()
        if inserts_count > 0 or updates_count > 0:
            logger.info(f"âœ… Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§ÛŒ Ù†Ù…Ø§Ø¯ {symbol_id_str} Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø°Ø®ÛŒØ±Ù‡/Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø´Ø¯Ù†Ø¯. (Ø¯Ø±Ø¬: {inserts_count}ØŒ Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ: {updates_count})")
        else:
            logger.debug(f"â„¹ï¸ Ù‡ÛŒÚ† Ø¯Ø§Ø¯Ù‡ Ø¬Ø¯ÛŒØ¯ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§Ø¯ {symbol_id_str} ÛŒØ§ÙØª Ù†Ø´Ø¯.")
        
    except Exception as e:
        db_session.rollback()
        logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§Ø¯ {symbol_id_str}: {e}", exc_info=True)


# -----------------------------------------------------------
# ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ Ø§Ø¬Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø´Ù…Ø¹ÛŒ
# -----------------------------------------------------------

def run_candlestick_detection(
    db_session: Session, 
    limit: int = None, 
    symbols_list: list = None
) -> int:
    """
    Ø§Ø¬Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø´Ù…Ø¹ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§Ø¯Ù‡Ø§ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ§Ø±ÛŒØ®ÛŒ Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬.
    Ø§Ø² Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ø­Ø°Ù Ùˆ Ø¯Ø±Ø¬ (Delete & Insert) Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² ØªÚ©Ø±Ø§Ø± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    ğŸ”§ Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² Ù‡Ø± Ø¯Ùˆ Ù†ÙˆØ¹ Ø¯Ø§Ø¯Ù‡ symbol_id
    """
    try:
        logger.info("ğŸ•¯ï¸ Ø´Ø±ÙˆØ¹ ØªØ´Ø®ÛŒØµ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø´Ù…Ø¹ÛŒ...")
        
        # 1. Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒØ³Øª symbol_id Ù‡Ø§ÛŒ ÙØ¹Ø§Ù„
        # ğŸ”§ Ø§ØµÙ„Ø§Ø­: ØªØ¶Ù…ÛŒÙ† string Ø¨ÙˆØ¯Ù† symbol_id Ù‡Ø§
        base_query = db_session.query(HistoricalData.symbol_id).distinct()
        
        if symbols_list:
            # ğŸ”§ ØªØ¨Ø¯ÛŒÙ„ ØªÙ…Ø§Ù… symbol_id Ù‡Ø§ÛŒ ÙˆØ±ÙˆØ¯ÛŒ Ø¨Ù‡ string Ø¨Ø±Ø§ÛŒ ØªØ·Ø§Ø¨Ù‚
            symbols_list_str = [str(sym) for sym in symbols_list]
            base_query = base_query.filter(HistoricalData.symbol_id.in_(symbols_list_str))
            
        symbol_ids_raw = [s[0] for s in base_query.all()]
        symbol_ids_to_process = [str(symbol_id) for symbol_id in symbol_ids_raw]  # ğŸ”§ ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ string
        
        logger.info(f"ğŸ” Ù†Ù…ÙˆÙ†Ù‡ symbol_id Ù‡Ø§: {symbol_ids_to_process[:3]}")  # ğŸ” Ø¯ÛŒØ¨Ø§Ú¯
        
        if not symbol_ids_to_process:
            logger.warning("âš ï¸ Ù‡ÛŒÚ† Ù†Ù…Ø§Ø¯ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø´Ù…Ø¹ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
            return 0
            
        if limit is not None:
            symbol_ids_to_process = symbol_ids_to_process[:limit]
            
        logger.info(f"ğŸ” ÛŒØ§ÙØª Ø´Ø¯ {len(symbol_ids_to_process)} Ù†Ù…Ø§Ø¯ Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø´Ù…Ø¹ÛŒ")

        success_count = 0
        records_to_insert = []
        
        # 2. Ø­Ù„Ù‚Ù‡ Ø²Ø¯Ù† Ø±ÙˆÛŒ Ù‡Ø± Ù†Ù…Ø§Ø¯ Ùˆ ÙÚ† Ùˆ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡
        processed_count = 0
        today_jdate_str = None

        for symbol_id in symbol_ids_to_process:
            
            try:
                # ğŸ’¡ Ù†Ù‚Ø·Ù‡ Ú©Ù„ÛŒØ¯ÛŒ: ÙÚ† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ§Ø±ÛŒØ®ÛŒ ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ ÛŒÚ© Ù†Ù…Ø§Ø¯
                # ğŸ”§ Ø§ØµÙ„Ø§Ø­: ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† Ø¨Ø§ symbol_id Ø¨Ù‡ ØµÙˆØ±Øª string
                historical_data_query = db_session.query(HistoricalData).filter(
                    HistoricalData.symbol_id == symbol_id
                ).order_by(HistoricalData.date.desc()).limit(30)
                
                historical_data = historical_data_query.all() 
                
                if len(historical_data) < 5:
                    logger.debug(f"âš ï¸ Ø¯Ø§Ø¯Ù‡ Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§Ø¯ {symbol_id} ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯ ({len(historical_data)} Ø±Ú©ÙˆØ±Ø¯)")
                    continue 

                # ğŸ’¡ ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ DataFrame
                df = pd.DataFrame([row.__dict__ for row in historical_data])
                if '_sa_instance_state' in df.columns:
                    df = df.drop(columns=['_sa_instance_state']) 
                
                # Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² Ø§ÛŒÙ†Ú©Ù‡ iloc[-1] Ø±ÙˆØ² Ø¬Ø¯ÛŒØ¯ Ø§Ø³Øª
                df.sort_values(by='date', inplace=True) 

                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù„Ø§Ø²Ù…:
                today_record_dict = df.iloc[-1].to_dict()
                yesterday_record_dict = df.iloc[-2].to_dict()
                
                # --- ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ ØªØ§Ø¨Ø¹ ØªØ´Ø®ÛŒØµ Ø§Ù„Ú¯Ùˆ Ø§Ø² Utils ---
                patterns = check_candlestick_patterns(
                    today_record_dict, 
                    yesterday_record_dict, 
                    df
                )
                
                # Ø°Ø®ÛŒØ±Ù‡ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ ÛŒØ§ÙØªâ€ŒØ´Ø¯Ù‡
                if patterns:
                    now = datetime.now()
                    current_jdate = today_record_dict['jdate']
                    if today_jdate_str is None:
                         today_jdate_str = current_jdate

                    for pattern in patterns:
                        records_to_insert.append({
                            'symbol_id': symbol_id,  # ğŸ”§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² symbol_id Ú©Ù‡ Ø§Ø² Ù‚Ø¨Ù„ string Ø§Ø³Øª
                            'jdate': current_jdate,
                            'pattern_name': pattern,
                            'created_at': now, 
                            'updated_at': now
                        })
                    success_count += 1
                    logger.debug(f"âœ… Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ ÛŒØ§ÙØª Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§Ø¯ {symbol_id}: {patterns}")
                
                processed_count += 1
                if processed_count % 100 == 0:
                    logger.info(f"ğŸ•¯ï¸ Ù¾ÛŒØ´Ø±ÙØª ØªØ´Ø®ÛŒØµ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø´Ù…Ø¹ÛŒ: {processed_count}/{len(symbol_ids_to_process)} Ù†Ù…Ø§Ø¯")

            except Exception as e:
                logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ØªØ´Ø®ÛŒØµ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø´Ù…Ø¹ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§Ø¯ {symbol_id}: {e}", exc_info=True)
                # Ø§Ø¯Ø§Ù…Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡ÛŒÙ… ØªØ§ Ø¨Ù‚ÛŒÙ‡ Ù†Ù…Ø§Ø¯Ù‡Ø§ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´ÙˆÙ†Ø¯
                
        logger.info(f"âœ… ØªØ´Ø®ÛŒØµ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø´Ù…Ø¹ÛŒ Ø¨Ø±Ø§ÛŒ {success_count} Ù†Ù…Ø§Ø¯ (Ø¨Ø§ {len(records_to_insert)} Ø§Ù„Ú¯Ùˆ) Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯.")
                
        # 3. Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬ Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³ (Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Delete & Insert)
        if records_to_insert:
            # Ø§Ù„Ù) Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªØ§Ø±ÛŒØ® Ùˆ Ù„ÛŒØ³Øª Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡
            if not today_jdate_str:
                 today_jdate_str = records_to_insert[0]['jdate'] 

            processed_symbol_ids_set = list({record['symbol_id'] for record in records_to_insert})
            
            # Ø¨) Ø­Ø°Ù Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒ
            try:
                logger.info(f"ğŸ—‘ï¸ Ø¯Ø± Ø­Ø§Ù„ Ø­Ø°Ù Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø´Ù…Ø¹ÛŒ Ù‚Ø¨Ù„ÛŒ Ø¨Ø±Ø§ÛŒ {len(processed_symbol_ids_set)} Ù†Ù…Ø§Ø¯ Ø¯Ø± ØªØ§Ø±ÛŒØ® {today_jdate_str}...")
                
                db_session.query(CandlestickPatternDetection).filter(
                    CandlestickPatternDetection.symbol_id.in_(processed_symbol_ids_set),
                    CandlestickPatternDetection.jdate == today_jdate_str
                ).delete(synchronize_session=False) 
                
                db_session.commit()
                
            except Exception as e:
                db_session.rollback()
                logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø­Ø°Ù Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø´Ù…Ø¹ÛŒ: {e}", exc_info=True)
                return success_count
                
            # Ø¬) Ø¯Ø±Ø¬ Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯
            try:
                db_session.bulk_insert_mappings(CandlestickPatternDetection, records_to_insert)
                db_session.commit()
                logger.info(f"âœ… {len(records_to_insert)} Ø§Ù„Ú¯ÙˆÛŒ Ø´Ù…Ø¹ÛŒ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¯Ø±Ø¬ Ø´Ø¯.")
            except Exception as e:
                 db_session.rollback()
                 logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±Ø¬ Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø´Ù…Ø¹ÛŒ: {e}", exc_info=True)
                 
        else:
            logger.info("â„¹ï¸ Ù‡ÛŒÚ† Ø§Ù„Ú¯ÙˆÛŒ Ø´Ù…Ø¹ÛŒ Ø¬Ø¯ÛŒØ¯ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.")

        return success_count

    except Exception as e:
         logger.error(f"âŒ Ø®Ø·Ø§ÛŒ Ú©Ù„ÛŒ Ø¯Ø± Ø§Ø¬Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø´Ù…Ø¹ÛŒ: {e}", exc_info=True)
         db_session.rollback()
         return 0

# -----------------------------------------------------------
# ØªÙˆØ§Ø¨Ø¹ Export
# -----------------------------------------------------------

__all__ = [
    # ØªÙˆØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ Ø§Ø¬Ø±Ø§ Ú©Ù†Ù†Ø¯Ù‡ ØªØ­Ù„ÛŒÙ„
    'run_technical_analysis',
    'run_candlestick_detection',
    
    # ØªÙˆØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø²
    'get_session_local',
    'cleanup_memory',
    'save_technical_indicators' # (Ø§Ú¯Ø±Ú†Ù‡ Ø¯Ø§Ø®Ù„ÛŒ Ø§Ø³ØªØŒ Ø§Ù…Ø§ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ù…ÙÛŒØ¯ Ø¨Ø§Ø´Ø¯)
]
