# services/potential_buy_queues_service.py
from extensions import db
from models import HistoricalData, ComprehensiveSymbolData, TechnicalIndicatorData, PotentialBuyQueueResult
from flask import current_app
import pandas as pd
from datetime import datetime
import jdatetime
from services.technical_analysis_utils import (
    get_today_jdate_str,
    calculate_z_score,
    calculate_smart_money_flow,
)
import json
import logging
from typing import List, Dict, Optional
from sqlalchemy import desc

logger = logging.getLogger(__name__)


def get_numeric_value(data_row, key, default=0):
    """Safe numeric extraction"""
    value = data_row.get(key, default)
    return value if pd.notna(value) else default


def get_reliable_price(data_row):
    """Use final or close price"""
    final_price = data_row.get("final")
    close_price = data_row.get("close")
    if pd.notna(final_price) and final_price > 0:
        return float(final_price)
    if pd.notna(close_price) and close_price > 0:
        return float(close_price)
    return 0.0


def convert_jalali_to_gregorian_for_pandas(jdate_str):
    if pd.isna(jdate_str) or not isinstance(jdate_str, str):
        return pd.NaT
    try:
        jy, jm, jd = map(int, jdate_str.split("-"))
        return jdatetime.date(jy, jm, jd).togregorian()
    except Exception:
        return pd.NaT


def run_potential_buy_queue_analysis_and_save():
    """
    ØªØ­Ù„ÛŒÙ„ Ø³Ù‡Ø§Ù… Ø¨Ø± Ø§Ø³Ø§Ø³ ÙÛŒÙ„ØªØ± Power_Thrust_Signal Ùˆ Ú†Ù†Ø¯ Ø´Ø§Ø®Øµ Ù…Ú©Ù…Ù„.
    Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ ÙÙ‚Ø· Ø§Ø² HistoricalData Ùˆ TechnicalIndicatorData Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯ Ùˆ Ù†ØªØ§ÛŒØ¬ Ø¯Ø± PotentialBuyQueueResult Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯.
    """
    current_app.logger.info("ğŸš€ Running Power_Thrust_Signal Analysis...")

    symbols = ComprehensiveSymbolData.query.all()
    today_jdate_str = get_today_jdate_str()

    # Ù¾Ø§Ú©â€ŒØ³Ø§Ø²ÛŒ Ù†ØªØ§ÛŒØ¬ Ù‚Ø¨Ù„ÛŒ
    try:
        PotentialBuyQueueResult.query.delete()
        db.session.commit()
    except Exception as e:
        db.session.rollback()
        logger.error(f"Error clearing table: {e}")

    candidates = []

    for symbol in symbols:
        symbol_id = symbol.symbol_id
        symbol_name = symbol.symbol_name

        # Ø­Ø°Ù Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ø­Ù‚ ØªÙ‚Ø¯Ù…
        if "Ø­" in symbol_name or "Ø­Ù‚" in symbol_name:
            continue

        # Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø®ÛŒØ±
        historical = (
            HistoricalData.query.filter_by(symbol_id=symbol_id)
            .order_by(HistoricalData.jdate.desc())
            .limit(60)
            .all()
        )
        technical = (
            TechnicalIndicatorData.query.filter_by(symbol_id=symbol_id)
            .order_by(TechnicalIndicatorData.jdate.desc())
            .limit(60)
            .all()
        )

        if len(historical) < 25 or len(technical) < 25:
            continue

        hist_df = pd.DataFrame([r.__dict__ for r in historical]).drop(
            columns=["_sa_instance_state"], errors="ignore"
        )
        tech_df = pd.DataFrame([r.__dict__ for r in technical]).drop(
            columns=["_sa_instance_state"], errors="ignore"
        )

        hist_df["greg_date"] = hist_df["jdate"].apply(convert_jalali_to_gregorian_for_pandas)
        tech_df["greg_date"] = tech_df["jdate"].apply(convert_jalali_to_gregorian_for_pandas)
        hist_df = hist_df.dropna(subset=["greg_date"]).sort_values(by="greg_date")
        tech_df = tech_df.dropna(subset=["greg_date"]).sort_values(by="greg_date")

        merged_df = pd.merge(hist_df, tech_df, on="jdate", how="left", suffixes=("_hist", "_tech"))
        if merged_df.empty or len(merged_df) < 3:
            continue

        latest = merged_df.iloc[-1]

        close_price = get_reliable_price(latest)
        if close_price <= 0:
            continue

        # ---- Ø´Ø±Ø§ÛŒØ· Ú©Ù„ÛŒØ¯ÛŒ ØªØ­Ù„ÛŒÙ„ ----
        reasons = []
        probability = 0.0

        # --- Ù‚Ø¯Ø±Øª Ø®Ø±ÛŒØ¯Ø§Ø± Ø­Ù‚ÛŒÙ‚ÛŒ ---
        buy_count_i = get_numeric_value(latest, "buy_count_i")
        sell_count_i = get_numeric_value(latest, "sell_count_i")
        real_buy_power_ratio = 0.0

        if buy_count_i > 0 and sell_count_i > 0:
            buy_per_trade = get_numeric_value(latest, "buy_i_volume") / buy_count_i
            sell_per_trade = get_numeric_value(latest, "sell_i_volume") / sell_count_i
            if sell_per_trade > 0:
                real_buy_power_ratio = buy_per_trade / sell_per_trade

        if real_buy_power_ratio > 2.0:
            reasons.append("Ù‚Ø¯Ø±Øª Ø®Ø±ÛŒØ¯Ø§Ø± Ø­Ù‚ÛŒÙ‚ÛŒ Ø¨Ø§Ù„Ø§")
            probability += 20

        # --- Ø§ÙØ²Ø§ÛŒØ´ Ø­Ø¬Ù… Ù…Ø¹Ø§Ù…Ù„Ø§Øª ---
        vol_today = get_numeric_value(latest, "volume")
        volume_z = calculate_z_score(hist_df["volume"])
        if volume_z is not None and volume_z > 2.0:
            reasons.append("Ø§ÙØ²Ø§ÛŒØ´ Ø­Ø¬Ù… ØºÛŒØ±Ø¹Ø§Ø¯ÛŒ (Z-Score > 2)")
            probability += 20

        # --- Ù‚ÛŒÙ…Øª Ù…Ø«Ø¨Øª ---
        plp = get_numeric_value(latest, "plp")
        if plp > 0:
            reasons.append("Ù‚ÛŒÙ…Øª Ù¾Ø§ÛŒØ§Ù†ÛŒ Ù…Ø«Ø¨Øª")
            probability += 10

        # --- RSI ---
        rsi_today = get_numeric_value(latest, "RSI_tech")
        prev_rsi = get_numeric_value(merged_df.iloc[-2], "RSI_tech")
        if rsi_today > prev_rsi and rsi_today < 70:
            reasons.append("RSI Ø¯Ø± Ø­Ø§Ù„ Ø±Ø´Ø¯")
            probability += 10

        # --- MACD ---
        macd_t = get_numeric_value(latest, "MACD_tech")
        macd_s = get_numeric_value(latest, "MACD_Signal_tech")
        prev_macd_t = get_numeric_value(merged_df.iloc[-2], "MACD_tech")
        prev_macd_s = get_numeric_value(merged_df.iloc[-2], "MACD_Signal_tech")
        if macd_t > macd_s and prev_macd_t <= prev_macd_s:
            reasons.append("ØªÙ‚Ø§Ø·Ø¹ ØµØ¹ÙˆØ¯ÛŒ MACD")
            probability += 15

        # --- Power_Thrust_Signal ---
        is_volume_spike = volume_z is not None and volume_z > 2.0
        is_strong_buy_power = real_buy_power_ratio > 2.5
        is_positive_close = plp > 0

        if is_volume_spike and is_strong_buy_power and is_positive_close:
            reasons.append("Power_Thrust_Signal (ÙˆØ±ÙˆØ¯ Ù‚Ø¯Ø±ØªÙ…Ù†Ø¯)")
            probability += 30

        probability = min(probability, 100)

        if probability >= 35 and reasons:
            candidate = {
                "symbol_id": symbol_id,
                "symbol_name": symbol_name,
                "jdate": today_jdate_str,
                "current_price": close_price,
                "real_buyer_power_ratio": real_buy_power_ratio,
                "matched_filters": json.dumps(reasons, ensure_ascii=False),
                "probability_percent": probability,
                "timestamp": datetime.now(),
                "reason": ", ".join(reasons),
                "group_type": "general",
            }
            candidates.append(candidate)

    # Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬
    saved = 0
    for c in sorted(candidates, key=lambda x: x["probability_percent"], reverse=True)[:20]:
        db.session.add(PotentialBuyQueueResult(**c))
        saved += 1

    try:
        db.session.commit()
        current_app.logger.info(f"âœ… Saved {saved} Power_Thrust results for {today_jdate_str}")
        return True, f"Saved {saved} results"
    except Exception as e:
        db.session.rollback()
        current_app.logger.error(f"DB commit failed: {e}", exc_info=True)
        return False, str(e)


# ---------------------------------------------------------------------------------
# ğŸ†• ØªØ§Ø¨Ø¹ Ø¬Ø¯ÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ù†ØªØ§ÛŒØ¬ Ø°Ø®ÛŒØ±Ù‡â€ŒØ´Ø¯Ù‡ (Ø±ÙØ¹ Ø®Ø·Ø§ÛŒ AttributeError)
# ---------------------------------------------------------------------------------
def get_potential_buy_queues_data(filters: Optional[Dict] = None) -> List[Dict]:
    """
    Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ù†ØªØ§ÛŒØ¬ ØªØ­Ù„ÛŒÙ„ Power_Thrust Ø°Ø®ÛŒØ±Ù‡â€ŒØ´Ø¯Ù‡ Ø§Ø² Ø¬Ø¯ÙˆÙ„ PotentialBuyQueueResult.
    """
    if filters is None:
        filters = {}
        
    limit = filters.get('limit', 20)
    
    try:
        query = PotentialBuyQueueResult.query
        
        # Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø±ØµØ¯ Ø§Ø­ØªÙ…Ø§Ù„ (Ø§Ø² Ø¨Ø§Ù„Ø§ Ø¨Ù‡ Ù¾Ø§ÛŒÛŒÙ†)
        query = query.order_by(desc(PotentialBuyQueueResult.probability_percent))
        query = query.limit(limit)
        
        results = query.all()
        
        # ØªØ¨Ø¯ÛŒÙ„ Ù†ØªØ§ÛŒØ¬ Ø¨Ù‡ Ù„ÛŒØ³Øª Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ù¾Ø§Ø³Ø® API
        result_list = []
        for res in results:
            data = {}
            # ØªØ¨Ø¯ÛŒÙ„ Ø¢Ø¨Ø¬Ú©Øª SQLAlchemy Ø¨Ù‡ Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ
            for col in res.__table__.columns:
                data[col.name] = getattr(res, col.name)
            
            # Ù‡Ù†Ø¯Ù„ Ú©Ø±Ø¯Ù† ÙÛŒÙ„Ø¯Ù‡Ø§ÛŒ Ø®Ø§Øµ Ø¨Ø±Ø§ÛŒ ÙØ±Ù…Øª API
            if 'timestamp' in data and data['timestamp']:
                data['timestamp'] = data['timestamp'].isoformat()
            if 'matched_filters' in data and data['matched_filters']:
                # ØªØ¨Ø¯ÛŒÙ„ Ø±Ø´ØªÙ‡ JSON Ø°Ø®ÛŒØ±Ù‡â€ŒØ´Ø¯Ù‡ Ø¨Ù‡ Ø¢Ø¨Ø¬Ú©Øª Python
                try:
                    data['matched_filters'] = json.loads(data['matched_filters'])
                except json.JSONDecodeError:
                    data['matched_filters'] = []
                
            result_list.append(data)
            
        logger.info(f"âœ… Retrieved {len(result_list)} potential buy queue results.")
        return result_list
        
    except Exception as e:
        logger.error(f"âŒ Error retrieving potential buy queues data: {e}", exc_info=True)
        return []


def get_defined_filters():
    """ÙÙ‡Ø±Ø³Øª ÙÛŒÙ„ØªØ±Ù‡Ø§ÛŒ ÙØ¹Ø§Ù„"""
    return [
        {"name": "Ù‚Ø¯Ø±Øª Ø®Ø±ÛŒØ¯Ø§Ø± Ø­Ù‚ÛŒÙ‚ÛŒ Ø¨Ø§Ù„Ø§", "category": "ØªØ§Ø¨Ù„ÙˆÛŒÛŒ"},
        {"name": "Ø§ÙØ²Ø§ÛŒØ´ Ø­Ø¬Ù… ØºÛŒØ±Ø¹Ø§Ø¯ÛŒ (Z-Score > 2)", "category": "Ø­Ø¬Ù…"},
        {"name": "Ù‚ÛŒÙ…Øª Ù¾Ø§ÛŒØ§Ù†ÛŒ Ù…Ø«Ø¨Øª", "category": "Ù‚ÛŒÙ…Øª"},
        {"name": "RSI Ø¯Ø± Ø­Ø§Ù„ Ø±Ø´Ø¯", "category": "Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±"},
        {"name": "ØªÙ‚Ø§Ø·Ø¹ ØµØ¹ÙˆØ¯ÛŒ MACD", "category": "Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±"},
        {"name": "Power_Thrust_Signal (ÙˆØ±ÙˆØ¯ Ù‚Ø¯Ø±ØªÙ…Ù†Ø¯)", "category": "Ø³ÛŒÚ¯Ù†Ø§Ù„ ØªØ±Ú©ÛŒØ¨ÛŒ"},
    ]