# services/potential_buy_queues_service.py
from extensions import db
from models import HistoricalData, ComprehensiveSymbolData, TechnicalIndicatorData, PotentialBuyQueueResult
from flask import current_app
import pandas as pd
from datetime import datetime
import jdatetime
from services.technical_analysis_utils import (
Â  Â  get_today_jdate_str,
Â  Â  calculate_z_score,
Â  Â  calculate_smart_money_flow,
)
import json
import logging
from typing import List, Dict, Optional
from sqlalchemy import desc

logger = logging.getLogger(__name__)


def get_numeric_value(data_row, key, default=0):
Â  Â  """Safe numeric extraction"""
Â  Â  value = data_row.get(key, default)
Â  Â  return value if pd.notna(value) else default


def get_reliable_price(data_row):
Â  Â  """Use final or close price"""
Â  Â  final_price = data_row.get("final")
Â  Â  close_price = data_row.get("close")
Â  Â  if pd.notna(final_price) and final_price > 0:
Â  Â  Â  Â  return float(final_price)
Â  Â  if pd.notna(close_price) and close_price > 0:
Â  Â  Â  Â  return float(close_price)
Â  Â  return 0.0


def convert_jalali_to_gregorian_for_pandas(jdate_str):
Â  Â  if pd.isna(jdate_str) or not isinstance(jdate_str, str):
Â  Â  Â  Â  return pd.NaT
Â  Â  try:
Â  Â  Â  Â  jy, jm, jd = map(int, jdate_str.split("-"))
Â  Â  Â  Â  return jdatetime.date(jy, jm, jd).togregorian()
Â  Â  except Exception:
Â  Â  Â  Â  return pd.NaT


def run_potential_buy_queue_analysis_and_save():
Â  Â  """
Â  Â  ØªØ­Ù„ÛŒÙ„ Ø³Ù‡Ø§Ù… Ø¨Ø± Ø§Ø³Ø§Ø³ ÙÛŒÙ„ØªØ± Power_Thrust_Signal Ùˆ Ú†Ù†Ø¯ Ø´Ø§Ø®Øµ Ù…Ú©Ù…Ù„.
Â  Â  Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ ÙÙ‚Ø· Ø§Ø² HistoricalData Ùˆ TechnicalIndicatorData Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯ Ùˆ Ù†ØªØ§ÛŒØ¬ Ø¯Ø± PotentialBuyQueueResult Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯.
Â  Â  """
Â  Â  current_app.logger.info("ğŸš€ Running Power_Thrust_Signal Analysis...")

Â  Â  symbols = ComprehensiveSymbolData.query.all()
Â  Â  today_jdate_str = get_today_jdate_str()

    # --- Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù…Ù†Ø·Ù‚ ÙÛŒÙ„ØªØ± ØµÙ†Ø¯ÙˆÙ‚â€ŒÙ‡Ø§ ---
    fund_keywords = ["ØµÙ†Ø¯ÙˆÙ‚", "Ø³Ø±Ù…Ø§ÛŒÙ‡", "Ø³Ø±Ù…Ø§ÛŒÙ‡ Ú¯Ø°Ø§Ø±ÛŒ", "Ø§Ø¹ØªØ¨Ø§Ø±", "Ø¢ØªÛŒÙ‡", "ÛŒÚ©ØªØ§", "Ø¯Ø§Ø±Ø§ÛŒÛŒ", "Ø§Ø®ØªØµØ§ØµÛŒ", "Ú©Ù…Ù†Ø¯", "Ù¾Ø§Ø¯Ø§Ø´", "Ø§Ø±Ù…ØºØ§Ù†"]
    fund_symbol_ids_to_ignore = {
        s.symbol_id for s in symbols if any(keyword in s.symbol_name for keyword in fund_keywords)
    }
    # --------------------------------------

Â  Â  # Ù¾Ø§Ú©â€ŒØ³Ø§Ø²ÛŒ Ù†ØªØ§ÛŒØ¬ Ù‚Ø¨Ù„ÛŒ
Â  Â  try:
Â  Â  Â  Â  PotentialBuyQueueResult.query.delete()
Â  Â  Â  Â  db.session.commit()
Â  Â  except Exception as e:
Â  Â  Â  Â  db.session.rollback()
Â  Â  Â  Â  logger.error(f"Error clearing table: {e}")

Â  Â  candidates = []

Â  Â  for symbol in symbols:
Â  Â  Â  Â  symbol_id = symbol.symbol_id
Â  Â  Â  Â  symbol_name = symbol.symbol_name

Â  Â  Â  Â  # Ø­Ø°Ù Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ø­Ù‚ ØªÙ‚Ø¯Ù…
Â  Â  Â  Â  if "Ø­" in symbol_name or "Ø­Ù‚" in symbol_name:
Â  Â  Â  Â  Â  Â  continue
            
        # Ø­Ø°Ù Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ ØµÙ†Ø¯ÙˆÙ‚â€ŒÙ‡Ø§ÛŒ Ø³Ø±Ù…Ø§ÛŒÙ‡â€ŒÚ¯Ø°Ø§Ø±ÛŒ
        if symbol_id in fund_symbol_ids_to_ignore:
            continue

Â  Â  Â  Â  # Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø®ÛŒØ±
Â  Â  Â  Â  historical = (
Â  Â  Â  Â  Â  Â  HistoricalData.query.filter_by(symbol_id=symbol_id)
Â  Â  Â  Â  Â  Â  .order_by(HistoricalData.jdate.desc())
Â  Â  Â  Â  Â  Â  .limit(60)
Â  Â  Â  Â  Â  Â  .all()
Â  Â  Â  Â  )
Â  Â  Â  Â  technical = (
Â  Â  Â  Â  Â  Â  TechnicalIndicatorData.query.filter_by(symbol_id=symbol_id)
Â  Â  Â  Â  Â  Â  .order_by(TechnicalIndicatorData.jdate.desc())
Â  Â  Â  Â  Â  Â  .limit(60)
Â  Â  Â  Â  Â  Â  .all()
Â  Â  Â  Â  )

Â  Â  Â  Â  if len(historical) < 25 or len(technical) < 25:
Â  Â  Â  Â  Â  Â  continue

Â  Â  Â  Â  hist_df = pd.DataFrame([r.__dict__ for r in historical]).drop(
Â  Â  Â  Â  Â  Â  columns=["_sa_instance_state"], errors="ignore"
Â  Â  Â  Â  )
Â  Â  Â  Â  tech_df = pd.DataFrame([r.__dict__ for r in technical]).drop(
Â  Â  Â  Â  Â  Â  columns=["_sa_instance_state"], errors="ignore"
Â  Â  Â  Â  )

Â  Â  Â  Â  hist_df["greg_date"] = hist_df["jdate"].apply(convert_jalali_to_gregorian_for_pandas)
Â  Â  Â  Â  tech_df["greg_date"] = tech_df["jdate"].apply(convert_jalali_to_gregorian_for_pandas)
Â  Â  Â  Â  hist_df = hist_df.dropna(subset=["greg_date"]).sort_values(by="greg_date")
Â  Â  Â  Â  tech_df = tech_df.dropna(subset=["greg_date"]).sort_values(by="greg_date")

Â  Â  Â  Â  merged_df = pd.merge(hist_df, tech_df, on="jdate", how="left", suffixes=("_hist", "_tech"))
Â  Â  Â  Â  if merged_df.empty or len(merged_df) < 3:
Â  Â  Â  Â  Â  Â  continue

Â  Â  Â  Â  latest = merged_df.iloc[-1]

Â  Â  Â  Â  close_price = get_reliable_price(latest)
Â  Â  Â  Â  if close_price <= 0:
Â  Â  Â  Â  Â  Â  continue

Â  Â  Â  Â  # ---- Ø´Ø±Ø§ÛŒØ· Ú©Ù„ÛŒØ¯ÛŒ ØªØ­Ù„ÛŒÙ„ ----
Â  Â  Â  Â  reasons = []
Â  Â  Â  Â  probability = 0.0

Â  Â  Â  Â  # --- Ù‚Ø¯Ø±Øª Ø®Ø±ÛŒØ¯Ø§Ø± Ø­Ù‚ÛŒÙ‚ÛŒ ---
Â  Â  Â  Â  buy_count_i = get_numeric_value(latest, "buy_count_i")
Â  Â  Â  Â  sell_count_i = get_numeric_value(latest, "sell_count_i")
Â  Â  Â  Â  real_buy_power_ratio = 0.0

Â  Â  Â  Â  if buy_count_i > 0 and sell_count_i > 0:
Â  Â  Â  Â  Â  Â  buy_per_trade = get_numeric_value(latest, "buy_i_volume") / buy_count_i
Â  Â  Â  Â  Â  Â  sell_per_trade = get_numeric_value(latest, "sell_i_volume") / sell_count_i
Â  Â  Â  Â  Â  Â  if sell_per_trade > 0:
Â  Â  Â  Â  Â  Â  Â  Â  real_buy_power_ratio = buy_per_trade / sell_per_trade

Â  Â  Â  Â  if real_buy_power_ratio > 2.0:
Â  Â  Â  Â  Â  Â  reasons.append("Ù‚Ø¯Ø±Øª Ø®Ø±ÛŒØ¯Ø§Ø± Ø­Ù‚ÛŒÙ‚ÛŒ Ø¨Ø§Ù„Ø§")
Â  Â  Â  Â  Â  Â  probability += 20

Â  Â  Â  Â  # --- Ø§ÙØ²Ø§ÛŒØ´ Ø­Ø¬Ù… Ù…Ø¹Ø§Ù…Ù„Ø§Øª ---
Â  Â  Â  Â  vol_today = get_numeric_value(latest, "volume")
Â  Â  Â  Â  volume_z = calculate_z_score(hist_df["volume"])
Â  Â  Â  Â  if volume_z is not None and volume_z > 2.0:
Â  Â  Â  Â  Â  Â  reasons.append("Ø§ÙØ²Ø§ÛŒØ´ Ø­Ø¬Ù… ØºÛŒØ±Ø¹Ø§Ø¯ÛŒ (Z-Score > 2)")
Â  Â  Â  Â  Â  Â  probability += 20

Â  Â  Â  Â  # --- Ù‚ÛŒÙ…Øª Ù…Ø«Ø¨Øª ---
Â  Â  Â  Â  plp = get_numeric_value(latest, "plp")
Â  Â  Â  Â  if plp > 0:
Â  Â  Â  Â  Â  Â  reasons.append("Ù‚ÛŒÙ…Øª Ù¾Ø§ÛŒØ§Ù†ÛŒ Ù…Ø«Ø¨Øª")
Â  Â  Â  Â  Â  Â  probability += 10

Â  Â  Â  Â  # --- RSI ---
Â  Â  Â  Â  rsi_today = get_numeric_value(latest, "RSI_tech")
Â  Â  Â  Â  prev_rsi = get_numeric_value(merged_df.iloc[-2], "RSI_tech")
Â  Â  Â  Â  if rsi_today > prev_rsi and rsi_today < 70:
Â  Â  Â  Â  Â  Â  reasons.append("RSI Ø¯Ø± Ø­Ø§Ù„ Ø±Ø´Ø¯")
Â  Â  Â  Â  Â  Â  probability += 10

Â  Â  Â  Â  # --- MACD ---
Â  Â  Â  Â  macd_t = get_numeric_value(latest, "MACD_tech")
Â  Â  Â  Â  macd_s = get_numeric_value(latest, "MACD_Signal_tech")
Â  Â  Â  Â  prev_macd_t = get_numeric_value(merged_df.iloc[-2], "MACD_tech")
Â  Â  Â  Â  prev_macd_s = get_numeric_value(merged_df.iloc[-2], "MACD_Signal_tech")
Â  Â  Â  Â  if macd_t > macd_s and prev_macd_t <= prev_macd_s:
Â  Â  Â  Â  Â  Â  reasons.append("ØªÙ‚Ø§Ø·Ø¹ ØµØ¹ÙˆØ¯ÛŒ MACD")
Â  Â  Â  Â  Â  Â  probability += 15

Â  Â  Â  Â  # --- Power_Thrust_Signal ---
Â  Â  Â  Â  is_volume_spike = volume_z is not None and volume_z > 2.0
Â  Â  Â  Â  is_strong_buy_power = real_buy_power_ratio > 2.5
Â  Â  Â  Â  is_positive_close = plp > 0

Â  Â  Â  Â  if is_volume_spike and is_strong_buy_power and is_positive_close:
Â  Â  Â  Â  Â  Â  reasons.append("Power_Thrust_Signal (ÙˆØ±ÙˆØ¯ Ù‚Ø¯Ø±ØªÙ…Ù†Ø¯)")
Â  Â  Â  Â  Â  Â  probability += 30

Â  Â  Â  Â  probability = min(probability, 100)

Â  Â  Â  Â  if probability >= 35 and reasons:
Â  Â  Â  Â  Â  Â  candidate = {
Â  Â  Â  Â  Â  Â  Â  Â  "symbol_id": symbol_id,
Â  Â  Â  Â  Â  Â  Â  Â  "symbol_name": symbol_name,
Â  Â  Â  Â  Â  Â  Â  Â  "jdate": today_jdate_str,
Â  Â  Â  Â  Â  Â  Â  Â  "current_price": close_price,
Â  Â  Â  Â  Â  Â  Â  Â  "real_buyer_power_ratio": real_buy_power_ratio,
Â  Â  Â  Â  Â  Â  Â  Â  "matched_filters": json.dumps(reasons, ensure_ascii=False),
Â  Â  Â  Â  Â  Â  Â  Â  "probability_percent": probability,
Â  Â  Â  Â  Â  Â  Â  Â  "timestamp": datetime.now(),
Â  Â  Â  Â  Â  Â  Â  Â  "reason": ", ".join(reasons),
Â  Â  Â  Â  Â  Â  Â  Â  "group_type": "general",
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  candidates.append(candidate)

Â  Â  # Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬
Â  Â  saved = 0
Â  Â  for c in sorted(candidates, key=lambda x: x["probability_percent"], reverse=True)[:20]:
Â  Â  Â  Â  db.session.add(PotentialBuyQueueResult(**c))
Â  Â  Â  Â  saved += 1

Â  Â  try:
Â  Â  Â  Â  db.session.commit()
Â  Â  Â  Â  current_app.logger.info(f"âœ… Saved {saved} Power_Thrust results for {today_jdate_str}")
Â  Â  Â  Â  return True, f"Saved {saved} results"
Â  Â  except Exception as e:
Â  Â  Â  Â  db.session.rollback()
Â  Â  Â  Â  current_app.logger.error(f"DB commit failed: {e}", exc_info=True)
Â  Â  Â  Â  return False, str(e)


# ---------------------------------------------------------------------------------
# ğŸ†• ØªØ§Ø¨Ø¹ Ø¬Ø¯ÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ù†ØªØ§ÛŒØ¬ Ø°Ø®ÛŒØ±Ù‡â€ŒØ´Ø¯Ù‡ (Ø±ÙØ¹ Ø®Ø·Ø§ÛŒ AttributeError)
# ---------------------------------------------------------------------------------
def get_potential_buy_queues_data(filters: Optional[Dict] = None) -> List[Dict]:
Â  Â  """
Â  Â  Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ù†ØªØ§ÛŒØ¬ ØªØ­Ù„ÛŒÙ„ Power_Thrust Ø°Ø®ÛŒØ±Ù‡â€ŒØ´Ø¯Ù‡ Ø§Ø² Ø¬Ø¯ÙˆÙ„ PotentialBuyQueueResult.
Â  Â  """
Â  Â  if filters is None:
Â  Â  Â  Â  filters = {}
Â  Â  Â  Â  
Â  Â  limit = filters.get('limit', 20)
Â  Â  
Â  Â  try:
Â  Â  Â  Â  query = PotentialBuyQueueResult.query
Â  Â  Â  Â  
Â  Â  Â  Â  # Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø±ØµØ¯ Ø§Ø­ØªÙ…Ø§Ù„ (Ø§Ø² Ø¨Ø§Ù„Ø§ Ø¨Ù‡ Ù¾Ø§ÛŒÛŒÙ†)
Â  Â  Â  Â  query = query.order_by(desc(PotentialBuyQueueResult.probability_percent))
Â  Â  Â  Â  query = query.limit(limit)
Â  Â  Â  Â  
Â  Â  Â  Â  results = query.all()
Â  Â  Â  Â  
Â  Â  Â  Â  # ØªØ¨Ø¯ÛŒÙ„ Ù†ØªØ§ÛŒØ¬ Ø¨Ù‡ Ù„ÛŒØ³Øª Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ù¾Ø§Ø³Ø® API
Â  Â  Â  Â  result_list = []
Â  Â  Â  Â  for res in results:
Â  Â  Â  Â  Â  Â  data = {}
Â  Â  Â  Â  Â  Â  # ØªØ¨Ø¯ÛŒÙ„ Ø¢Ø¨Ø¬Ú©Øª SQLAlchemy Ø¨Ù‡ Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ
Â  Â  Â  Â  Â  Â  for col in res.__table__.columns:
Â  Â  Â  Â  Â  Â  Â  Â  data[col.name] = getattr(res, col.name)
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  # Ù‡Ù†Ø¯Ù„ Ú©Ø±Ø¯Ù† ÙÛŒÙ„Ø¯Ù‡Ø§ÛŒ Ø®Ø§Øµ Ø¨Ø±Ø§ÛŒ ÙØ±Ù…Øª API
Â  Â  Â  Â  Â  Â  if 'timestamp' in data and data['timestamp']:
Â  Â  Â  Â  Â  Â  Â  Â  data['timestamp'] = data['timestamp'].isoformat()
Â  Â  Â  Â  Â  Â  if 'matched_filters' in data and data['matched_filters']:
Â  Â  Â  Â  Â  Â  Â  Â  # ØªØ¨Ø¯ÛŒÙ„ Ø±Ø´ØªÙ‡ JSON Ø°Ø®ÛŒØ±Ù‡â€ŒØ´Ø¯Ù‡ Ø¨Ù‡ Ø¢Ø¨Ø¬Ú©Øª Python
Â  Â  Â  Â  Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  data['matched_filters'] = json.loads(data['matched_filters'])
Â  Â  Â  Â  Â  Â  Â  Â  except json.JSONDecodeError:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  data['matched_filters'] = []
Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  result_list.append(data)
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  logger.info(f"âœ… Retrieved {len(result_list)} potential buy queue results.")
Â  Â  Â  Â  return result_list
Â  Â  Â  Â  
Â  Â  except Exception as e:
Â  Â  Â  Â  logger.error(f"âŒ Error retrieving potential buy queues data: {e}", exc_info=True)
Â  Â  Â  Â  return []


def get_defined_filters():
Â  Â  """ÙÙ‡Ø±Ø³Øª ÙÛŒÙ„ØªØ±Ù‡Ø§ÛŒ ÙØ¹Ø§Ù„"""
Â  Â  return [
Â  Â  Â  Â  {"name": "Ù‚Ø¯Ø±Øª Ø®Ø±ÛŒØ¯Ø§Ø± Ø­Ù‚ÛŒÙ‚ÛŒ Ø¨Ø§Ù„Ø§", "category": "ØªØ§Ø¨Ù„ÙˆÛŒÛŒ"},
Â  Â  Â  Â  {"name": "Ø§ÙØ²Ø§ÛŒØ´ Ø­Ø¬Ù… ØºÛŒØ±Ø¹Ø§Ø¯ÛŒ (Z-Score > 2)", "category": "Ø­Ø¬Ù…"},
Â  Â  Â  Â  {"name": "Ù‚ÛŒÙ…Øª Ù¾Ø§ÛŒØ§Ù†ÛŒ Ù…Ø«Ø¨Øª", "category": "Ù‚ÛŒÙ…Øª"},
Â  Â  Â  Â  {"name": "RSI Ø¯Ø± Ø­Ø§Ù„ Ø±Ø´Ø¯", "category": "Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±"},
Â  Â  Â  Â  {"name": "ØªÙ‚Ø§Ø·Ø¹ ØµØ¹ÙˆØ¯ÛŒ MACD", "category": "Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±"},
Â  Â  Â  Â  {"name": "Power_Thrust_Signal (ÙˆØ±ÙˆØ¯ Ù‚Ø¯Ø±ØªÙ…Ù†Ø¯)", "category": "Ø³ÛŒÚ¯Ù†Ø§Ù„ ØªØ±Ú©ÛŒØ¨ÛŒ"},
Â  Â  ]
