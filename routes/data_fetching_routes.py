# -*- coding: utf-8 -*-
# routes/data_fetching_routes.py
# Ù…Ø³Ø¦ÙˆÙ„: ØªØ¹Ø±ÛŒÙ Ø§Ù†Ø¯Ù¾ÙˆÛŒÙ†Øªâ€ŒÙ‡Ø§ÛŒ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ ÙˆØ§Ú©Ø´ÛŒ Ø¯Ø§Ø¯Ù‡ØŒ ØªØ­Ù„ÛŒÙ„ ØªÚ©Ù†ÛŒÚ©Ø§Ù„ØŒ Ùˆ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒâ€ŒÙ‡Ø§ÛŒ ML
# Ø§ÛŒÙ† ÙØ§ÛŒÙ„ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø± Ø¨Ø§ Ø³Ø§Ø®ØªØ§Ø± Ø¬Ø¯ÛŒØ¯ Ø³Ø±ÙˆÛŒØ³â€ŒÙ‡Ø§ Ø¨Ø§Ø²Ù†ÙˆÛŒØ³ÛŒ Ø´Ø¯Ù‡ Ø§Ø³Øª.

import logging
import traceback
from datetime import date
import jdatetime

# âœ… Ø§ØµÙ„Ø§Ø­: jsonify Ø§Ø² flask Ø­Ø°Ù Ø´Ø¯ Ø²ÛŒØ±Ø§ Ø¨Ø§ Flask-RESTX Ù†ÛŒØ§Ø²ÛŒ Ø¨Ù‡ Ø¢Ù† Ù†ÛŒØ³Øª Ùˆ Ø¨Ø§Ø¹Ø« Ø®Ø·Ø§ÛŒ TypeError Ù…ÛŒâ€ŒØ´ÙˆØ¯.
from flask_restx import Namespace, Resource, fields, reqparse

from extensions import db
from sqlalchemy.orm import sessionmaker, Session

# =========================
# Namespace Ø¨Ø±Ø§ÛŒ Flask-RESTX
# =========================
data_ns = Namespace('data', description='Ø¹Ù…Ù„ÛŒØ§Øª ÙˆØ§Ú©Ø´ÛŒ Ø¯Ø§Ø¯Ù‡ØŒ ØªØ­Ù„ÛŒÙ„ Ùˆ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ')

# =========================
# ØªÙˆØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ
# =========================
def get_session_local() -> Session:
    """ÛŒÚ© Session Ù…Ø­Ù„ÛŒ Ø¨Ø±Ø§ÛŒ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ø§ÛŒØ¬Ø§Ø¯ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ ØªØ§ Ø§Ø² Ú©Ø§Ù†ØªÚ©Ø³Øª Flask Ù…Ø³ØªÙ‚Ù„ Ø¨Ø§Ø´Ø¯."""
    SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=db.engine)
    return SessionLocal()

def parse_date(value: str) -> date | None:
    """ØªØ§Ø±ÛŒØ® Ø±Ø§ Ø§Ø² ÙØ±Ù…Øª Ø±Ø´ØªÙ‡ (YYYY-MM-DD) Ø´Ù…Ø³ÛŒ ÛŒØ§ Ù…ÛŒÙ„Ø§Ø¯ÛŒ Ø¨Ù‡ Ø´ÛŒØ¡ date Ù…ÛŒÙ„Ø§Ø¯ÛŒ ØªØ¨Ø¯ÛŒÙ„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    if not isinstance(value, str) or not value:
        return None
    try:
        # 1. ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ù¾Ø§Ø±Ø³ Ú©Ø±Ø¯Ù† Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† ØªØ§Ø±ÛŒØ® Ù…ÛŒÙ„Ø§Ø¯ÛŒ
        return date.fromisoformat(value)
    except ValueError:
        # 2. ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ù¾Ø§Ø±Ø³ Ú©Ø±Ø¯Ù† Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† ØªØ§Ø±ÛŒØ® Ø´Ù…Ø³ÛŒ
        try:
            j_year, j_month, j_day = map(int, value.split('-'))
            return jdatetime.date(j_year, j_month, j_day).togregorian()
        except Exception:
            return None

# =========================
# --- API Models for Swagger/RESTX Documentation ---
# =========================
# Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ù…Ø³ØªÙ†Ø¯Ø³Ø§Ø²ÛŒ Ø®ÙˆØ¯Ú©Ø§Ø± API (Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ±)
historical_data_model = data_ns.model('HistoricalData', {
    'date': fields.String(description='Gregorian date (YYYY-MM-DD)'),
    'jdate': fields.String(description='Persian date (YYYY-MM-DD)'),
    'open': fields.Float,
    'high': fields.Float,
    'low': fields.Float,
    'close': fields.Float,
    'last_price': fields.Float,
    'volume': fields.Integer,
    # ... Ø³Ø§ÛŒØ± ÙÛŒÙ„Ø¯Ù‡Ø§ Ø¯Ø± Ø§ÛŒÙ†Ø¬Ø§ Ù‚Ø±Ø§Ø± Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ù†Ø¯ ...
    'buyers_count': fields.Integer
})

ml_prediction_model = data_ns.model('MLPredictionModel', {
    'id': fields.Integer(readOnly=True, description='The unique identifier of the prediction'),
    'symbol_id': fields.String(required=True, description='The ID of the stock symbol'),
    'symbol_name': fields.String(required=True, description='The name of the stock symbol'),
    'prediction_date': fields.String(required=True, description='Gregorian date when the prediction was made'),
    'jprediction_date': fields.String(required=True, description='Jalali date when the prediction was made'),
    'prediction_period_days': fields.Integer(description='Number of days for the prediction horizon'),
    'predicted_trend': fields.String(required=True, description='Predicted trend: Uptrend, Downtrend, or Sideways'),
    'prediction_probability': fields.Float(required=True, description='Probability/confidence of the predicted trend'),
    'actual_trend_outcome': fields.String(description='Actual trend outcome after the period'),
    'is_prediction_accurate': fields.Boolean(description='True if prediction was accurate'),
    'model_version': fields.String(description='Version of the ML model used'),
})


# =================================================================================
# --- Parsers for API Endpoints ---
# =================================================================================
# Ù¾Ø§Ø±Ø³Ø± Ø¨Ø±Ø§ÛŒ Ø§Ù†Ø¯Ù¾ÙˆÛŒÙ†Øª Ø¨Ø§Ø²Ø³Ø§Ø²ÛŒ Ú©Ø§Ù…Ù„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
rebuild_parser = reqparse.RequestParser()
rebuild_parser.add_argument('batch_size', type=int, default=50, help='ØªØ¹Ø¯Ø§Ø¯ Ù†Ù…Ø§Ø¯Ù‡Ø§ Ø¯Ø± Ù‡Ø± Ø¨Ú† Ù¾Ø±Ø¯Ø§Ø²Ø´ÛŒ')
rebuild_parser.add_argument('commit_batch_size', type=int, default=100, help='ØªØ¹Ø¯Ø§Ø¯ Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´â€ŒØ´Ø¯Ù‡ Ù‚Ø¨Ù„ Ø§Ø² Ù‡Ø± commit')

# Ù¾Ø§Ø±Ø³Ø± Ø¨Ø±Ø§ÛŒ Ø§Ù†Ø¯Ù¾ÙˆÛŒÙ†Øªâ€ŒÙ‡Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ú©Ù‡ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ù†Ø¯ Ù„ÛŒØ³Øª Ù†Ù…Ø§Ø¯Ù‡Ø§ Ø±Ø§ Ø¯Ø±ÛŒØ§ÙØª Ú©Ù†Ù†Ø¯
analysis_parser = reqparse.RequestParser()
analysis_parser.add_argument('limit', type=int, required=False, help='Ù…Ø­Ø¯ÙˆØ¯ÛŒØª ØªØ¹Ø¯Ø§Ø¯ Ù†Ù…Ø§Ø¯Ù‡Ø§ Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´')
analysis_parser.add_argument('days_limit', type=int, required=False, help='Ù…Ø­Ø¯ÙˆØ¯ÛŒØª ØªØ¹Ø¯Ø§Ø¯ Ø±ÙˆØ²Ù‡Ø§ÛŒ ØªØ§Ø±ÛŒØ®ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ù‡Ø± Ù†Ù…Ø§Ø¯')
analysis_parser.add_argument(
    'specific_symbols',
    type=list,
    location='json',
    required=False,
    help='Ù„ÛŒØ³ØªÛŒ Ø§Ø² Ù†Ø§Ù… ÛŒØ§ Ú©Ø¯ Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ø®Ø§Øµ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ (Ù…Ø«Ø§Ù„: ["Ø®ÙˆØ¯Ø±Ùˆ", "Ø®Ø³Ø§Ù¾Ø§"])'
)

# Ù¾Ø§Ø±Ø³Ø± Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ§Ø±ÛŒØ®ÛŒ ÛŒÚ© Ù†Ù…Ø§Ø¯
historical_data_parser = reqparse.RequestParser()
historical_data_parser.add_argument('days', type=int, default=61, help='ØªØ¹Ø¯Ø§Ø¯ Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù…Ø¹Ø§Ù…Ù„Ø§ØªÛŒ Ø§Ø®ÛŒØ± Ø¨Ø±Ø§ÛŒ ÙˆØ§Ú©Ø´ÛŒ')
historical_data_parser.add_argument('start_date', type=str, help='ØªØ§Ø±ÛŒØ® Ø´Ø±ÙˆØ¹ Ø¨Ø§Ø²Ù‡ ( Ø´Ù…Ø³ÛŒ ÛŒØ§ Ù…ÛŒÙ„Ø§Ø¯ÛŒ YYYY-MM-DD)')
historical_data_parser.add_argument('end_date', type=str, help='ØªØ§Ø±ÛŒØ® Ù¾Ø§ÛŒØ§Ù† Ø¨Ø§Ø²Ù‡ ( Ø´Ù…Ø³ÛŒ ÛŒØ§ Ù…ÛŒÙ„Ø§Ø¯ÛŒ YYYY-MM-DD)')

# Ù¾Ø§Ø±Ø³Ø± Ø¨Ø±Ø§ÛŒ Ø§Ù†Ø¯Ù¾ÙˆÛŒÙ†Øª ØªÙˆÙ„ÛŒØ¯ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ ML
ml_generate_parser = reqparse.RequestParser()
ml_generate_parser.add_argument('prediction_date', type=str, required=False, help='ØªØ§Ø±ÛŒØ® Ù…ÛŒÙ„Ø§Ø¯ÛŒ Ø¨Ø±Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ (YYYY-MM-DD)')
ml_generate_parser.add_argument('prediction_period_days', type=int, default=7, help='Ø¯ÙˆØ±Ù‡ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø¨Ù‡ Ø±ÙˆØ²')


# =================================================================================
# --- Import Ø³Ø±ÙˆÛŒØ³â€ŒÙ‡Ø§ (Ø¨Ø± Ø§Ø³Ø§Ø³ Ø³Ø§Ø®ØªØ§Ø± Ø¬Ø¯ÛŒØ¯) ---
# =================================================================================
from services.data_fetcher import run_full_rebuild
from services.fetch_latest_brsapi_eod import update_daily_eod_from_brsapi
from services.historical_data_service import get_historical_data_for_symbol
from services.data_processing_and_analysis import run_technical_analysis
from services.data_analysis_service import run_fundamental_analysis
from services.ml_prediction_service import (
    generate_and_save_predictions_for_watchlist,
    update_ml_prediction_outcomes,
    get_all_ml_predictions,
    get_ml_predictions_for_symbol,
)

# =================================================================================
# --- Endpoints ---
# =================================================================================

# -----------------------------------------------
# Û±. Ø§Ù†Ø¯Ù¾ÙˆÛŒÙ†Øªâ€ŒÙ‡Ø§ÛŒ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ ÙˆØ§Ú©Ø´ÛŒ Ùˆ Ø¨Ø§Ø²Ø³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡
# -----------------------------------------------
@data_ns.route('/fetch/full-rebuild')
class FullRebuildResource(Resource):
    @data_ns.doc('run_full_rebuild')
    @data_ns.expect(rebuild_parser)
    def post(self):
        """
        Ø§Ø¬Ø±Ø§ÛŒ Ú†Ø±Ø®Ù‡ Ú©Ø§Ù…Ù„ Ø¨Ø§Ø²Ø³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø§Ø² TSETMC.
        Ø§ÛŒÙ† Ø¹Ù…Ù„ÛŒØ§Øª Ø³Ù†Ú¯ÛŒÙ†ØŒ ØªÙ…Ø§Ù… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø§ÛŒÙ‡ Ø±Ø§ Ù¾Ø§Ú© Ú©Ø±Ø¯Ù‡ Ùˆ Ø§Ø² Ù†Ùˆ ÙˆØ§Ú©Ø´ÛŒ Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
        """
        logger = logging.getLogger(__name__)
        logger.info("ğŸŒ€ [API] Starting full data rebuild process...")
        try:
            args = rebuild_parser.parse_args()
            result = run_full_rebuild(
                batch_size=args['batch_size'],
                commit_batch_size=args['commit_batch_size']
            )
            # âœ… Ø§ØµÙ„Ø§Ø­: Ø­Ø°Ù jsonify
            return result, 200
        except Exception as e:
            logger.error(f"âŒ Fatal error in full-rebuild endpoint: {e}\n{traceback.format_exc()}")
            # âœ… Ø§ØµÙ„Ø§Ø­: Ø­Ø°Ù jsonify
            return {"status": "error", "message": f"An unexpected error occurred: {e}"}, 500

@data_ns.route('/fetch/daily-eod-update')
class DailyEODUpdateResource(Resource):
    @data_ns.doc('run_daily_eod_update')
    def post(self):
        """
        ÙˆØ§Ú©Ø´ÛŒ Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ø¢Ø®Ø±ÛŒÙ† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø±ÙˆØ²Ø§Ù†Ù‡ (EOD) Ùˆ Ø§Ø·Ù„Ø§Ø¹Ø§Øª ØµÙ Ø³ÙØ§Ø±Ø´ Ø§Ø² BRSAPI.
        Ø§ÛŒÙ† Ø¹Ù…Ù„ÛŒØ§Øª Ø¨Ø§ÛŒØ¯ Ø±ÙˆØ²Ø§Ù†Ù‡ Ù¾Ø³ Ø§Ø² Ù¾Ø§ÛŒØ§Ù† Ø¨Ø§Ø²Ø§Ø± Ø§Ø¬Ø±Ø§ Ø´ÙˆØ¯.
        """
        logger = logging.getLogger(__name__)
        logger.info("âš¡ï¸ [API] Starting daily EOD update from BRSAPI...")
        session = get_session_local()
        try:
            count, message = update_daily_eod_from_brsapi(session)
            # âœ… Ø§ØµÙ„Ø§Ø­: Ø­Ø°Ù jsonify
            return {"status": "success", "updated_symbols": count, "message": message}, 200
        except Exception as e:
            logger.error(f"âŒ Error in daily-eod-update endpoint: {e}\n{traceback.format_exc()}")
            # âœ… Ø§ØµÙ„Ø§Ø­: Ø­Ø°Ù jsonify
            return {"status": "error", "message": str(e)}, 500
        finally:
            session.close()

# -----------------------------------
# Û². Ø§Ù†Ø¯Ù¾ÙˆÛŒÙ†Øªâ€ŒÙ‡Ø§ÛŒ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡
# -----------------------------------
@data_ns.route('/analysis/technical')
class RunTechnicalAnalysisResource(Resource):
    @data_ns.doc('run_technical_analysis')
    @data_ns.expect(analysis_parser)
    def post(self):
        """
        Ø§Ø¬Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ ØªÚ©Ù†ÛŒÚ©Ø§Ù„ Ùˆ ØªØ´Ø®ÛŒØµ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ú©Ù†Ø¯Ù„ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§Ø¯Ù‡Ø§.
        Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø¨Ø±Ø§ÛŒ ØªÙ…Ø§Ù… Ù†Ù…Ø§Ø¯Ù‡Ø§ ÛŒØ§ Ù„ÛŒØ³Øª Ù…Ø´Ø®ØµÛŒ Ø§Ø¬Ø±Ø§ Ø´ÙˆØ¯.
        """
        logger = logging.getLogger(__name__)
        logger.info("ğŸ“Š [API] Running comprehensive technical analysis...")
        session = get_session_local()
        try:
            args = analysis_parser.parse_args()
            processed_count, message = run_technical_analysis(
                db_session=session,
                limit=args.get('limit'),
                specific_symbols_list=args.get('specific_symbols'),
                days_limit=args.get('days_limit')
            )
            # âœ… Ø§ØµÙ„Ø§Ø­: Ø­Ø°Ù jsonify
            return {"status": "success", "processed_symbols": processed_count, "message": message}, 200
        except Exception as e:
            logger.error(f"âŒ Error in technical analysis endpoint: {e}\n{traceback.format_exc()}")
            # âœ… Ø§ØµÙ„Ø§Ø­: Ø­Ø°Ù jsonify
            return {"status": "error", "message": str(e)}, 500
        finally:
            session.close()

@data_ns.route('/analysis/fundamental')
class RunFundamentalAnalysisResource(Resource):
    @data_ns.doc('run_fundamental_analysis')
    @data_ns.expect(analysis_parser)
    def post(self):
        """
        Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ ÙØ§Ù†Ø¯Ø§Ù…Ù†ØªØ§Ù„ (Ù…Ø§Ù†Ù†Ø¯ Ù‚Ø¯Ø±Øª Ø®Ø±ÛŒØ¯Ø§Ø± Ø­Ù‚ÛŒÙ‚ÛŒ) Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ§Ø±ÛŒØ®ÛŒ.
        """
        logger = logging.getLogger(__name__)
        logger.info("ğŸ’° [API] Running fundamental metrics analysis...")
        session = get_session_local()
        try:
            args = analysis_parser.parse_args()
            success_count, message = run_fundamental_analysis(
                db_session=session,
                symbols_list=args.get('specific_symbols')
            )
            # âœ… Ø§ØµÙ„Ø§Ø­: Ø­Ø°Ù jsonify
            return {"status": "success", "processed_symbols": success_count, "message": message}, 200
        except Exception as e:
            logger.error(f"âŒ Error in fundamental analysis endpoint: {e}\n{traceback.format_exc()}")
            # âœ… Ø§ØµÙ„Ø§Ø­: Ø­Ø°Ù jsonify
            return {"status": "error", "message": str(e)}, 500
        finally:
            session.close()

# ------------------------------------------
# Û³. Ø§Ù†Ø¯Ù¾ÙˆÛŒÙ†Øªâ€ŒÙ‡Ø§ÛŒ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ ML
# ------------------------------------------
@data_ns.route('/ml-predictions/generate')
class GenerateMLPredictionsResource(Resource):
    @data_ns.doc('generate_ml_predictions')
    @data_ns.expect(ml_generate_parser)
    def post(self):
        """
        ØªÙˆÙ„ÛŒØ¯ Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒâ€ŒÙ‡Ø§ÛŒ Ø±ÙˆÙ†Ø¯ Ø¢ÛŒÙ†Ø¯Ù‡ Ù†Ù…Ø§Ø¯Ù‡Ø§ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„ ML.
        """
        logger = logging.getLogger(__name__)
        logger.info("ğŸ¤– [API] Generating ML trend predictions...")
        try:
            args = ml_generate_parser.parse_args()
            prediction_date = parse_date(args['prediction_date']) if args['prediction_date'] else date.today()

            success, message = generate_and_save_predictions_for_watchlist(
                prediction_date_greg=prediction_date,
                prediction_period_days=args['prediction_period_days']
            )
            if success:
                # âœ… Ø§ØµÙ„Ø§Ø­: Ø­Ø°Ù jsonify
                return {"status": "success", "message": message}, 200
            else:
                # âœ… Ø§ØµÙ„Ø§Ø­: Ø­Ø°Ù jsonify
                return {"status": "error", "message": message}, 400
        except Exception as e:
            logger.error(f"âŒ Error in generate-ml-predictions endpoint: {e}\n{traceback.format_exc()}")
            # âœ… Ø§ØµÙ„Ø§Ø­: Ø­Ø°Ù jsonify
            return {"status": "error", "message": str(e)}, 500

@data_ns.route('/ml-predictions/update-outcomes')
class UpdateMLOutcomesResource(Resource):
    @data_ns.doc('update_ml_outcomes')
    def post(self):
        """
        Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù†ØªØ§ÛŒØ¬ ÙˆØ§Ù‚Ø¹ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒâ€ŒÙ‡Ø§ÛŒ Ú¯Ø°Ø´ØªÙ‡ Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø¯Ù‚Øª Ù…Ø¯Ù„.
        Ø§ÛŒÙ† Ø§Ù†Ø¯Ù¾ÙˆÛŒÙ†Øª Ø¨Ø§ÛŒØ¯ Ø¨Ù‡ ØµÙˆØ±Øª Ø¯ÙˆØ±Ù‡â€ŒØ§ÛŒ (Ø±ÙˆØ²Ø§Ù†Ù‡) ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ Ø´ÙˆØ¯.
        """
        logger = logging.getLogger(__name__)
        logger.info("ğŸ¯ [API] Updating ML prediction outcomes...")
        try:
            success, message = update_ml_prediction_outcomes()
            if success:
                # âœ… Ø§ØµÙ„Ø§Ø­: Ø­Ø°Ù jsonify
                return {"status": "success", "message": message}, 200
            else:
                # âœ… Ø§ØµÙ„Ø§Ø­: Ø­Ø°Ù jsonify
                return {"status": "error", "message": message}, 400
        except Exception as e:
            logger.error(f"âŒ Error in update-ml-outcomes endpoint: {e}\n{traceback.format_exc()}")
            # âœ… Ø§ØµÙ„Ø§Ø­: Ø­Ø°Ù jsonify
            return {"status": "error", "message": str(e)}, 500

@data_ns.route('/ml-predictions/all')
class GetAllMLPredictionsResource(Resource):
    @data_ns.doc('get_all_ml_predictions')
    @data_ns.marshal_list_with(ml_prediction_model)
    def get(self):
        """Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒØ³Øª ØªÙ…Ø§Ù… Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒâ€ŒÙ‡Ø§ÛŒ ML Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù‡ Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³."""
        logger = logging.getLogger(__name__)
        logger.info("ğŸ“š [API] Fetching all ML predictions...")
        try:
            predictions = get_all_ml_predictions()
            return predictions, 200
        except Exception as e:
            logger.error(f"âŒ Error getting all ML predictions: {e}\n{traceback.format_exc()}")
            # âœ… Ø§ØµÙ„Ø§Ø­: Ø­Ø°Ù jsonify
            return {"status": "error", "message": str(e)}, 500

@data_ns.route('/ml-predictions/<string:symbol_id>')
class GetSymbolMLPredictionResource(Resource):
    @data_ns.doc('get_symbol_ml_prediction')
    @data_ns.marshal_with(ml_prediction_model)
    def get(self, symbol_id: str):
        """Ø¯Ø±ÛŒØ§ÙØª Ø¢Ø®Ø±ÛŒÙ† Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ ML Ø¨Ø±Ø§ÛŒ ÛŒÚ© Ù†Ù…Ø§Ø¯ Ù…Ø´Ø®Øµ."""
        logger = logging.getLogger(__name__)
        logger.info(f"ğŸ” [API] Fetching latest ML prediction for symbol: {symbol_id}")
        try:
            prediction = get_ml_predictions_for_symbol(symbol_id)
            if prediction:
                return prediction, 200
            return {"message": f"No prediction found for symbol {symbol_id}"}, 404
        except Exception as e:
            logger.error(f"âŒ Error getting ML prediction for {symbol_id}: {e}\n{traceback.format_exc()}")
            # âœ… Ø§ØµÙ„Ø§Ø­: Ø­Ø°Ù jsonify
            return {"status": "error", "message": str(e)}, 500

# ------------------------------------
# Û´. Ø§Ù†Ø¯Ù¾ÙˆÛŒÙ†Øªâ€ŒÙ‡Ø§ÛŒ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡
# ------------------------------------
@data_ns.route('/historical/<string:symbol_identifier>')
class GetHistoricalDataResource(Resource):
    @data_ns.doc('get_historical_data')
    @data_ns.expect(historical_data_parser)
    @data_ns.marshal_list_with(historical_data_model)
    def get(self, symbol_identifier: str):
        """
        Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ§Ø±ÛŒØ®ÛŒ ØªØ¬Ù…ÛŒØ¹â€ŒØ´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ ÛŒÚ© Ù†Ù…Ø§Ø¯ Ù…Ø´Ø®Øµ.
        Ù†Ù…Ø§Ø¯ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ù†Ø§Ù… (Ø®ÙˆØ¯Ø±Ùˆ) ÛŒØ§ Ú©Ø¯ TSETMC Ø¨Ø§Ø´Ø¯.
        """
        logger = logging.getLogger(__name__)
        logger.info(f"ğŸ“ˆ [API] Request for historical data for symbol: {symbol_identifier}")
        try:
            args = historical_data_parser.parse_args()
            start_date_obj = parse_date(args.get('start_date'))
            end_date_obj = parse_date(args.get('end_date'))

            data = get_historical_data_for_symbol(
                symbol_identifier=symbol_identifier,
                start_date=start_date_obj,
                end_date=end_date_obj,
                days=args['days']
            )

            if data is None:
                # âœ… Ø§ØµÙ„Ø§Ø­: Ø­Ø°Ù jsonify
                return {"status": "error", "message": "Failed to retrieve data due to an internal error."}, 500
            if not data:
                # âœ… Ø§ØµÙ„Ø§Ø­: Ø­Ø°Ù jsonify
                return {"status": "not_found", "message": "No data found for the specified symbol or date range."}, 404

            return data, 200
        except Exception as e:
            logger.error(f"âŒ Error in get_historical_data endpoint for {symbol_identifier}: {e}\n{traceback.format_exc()}")
            # âœ… Ø§ØµÙ„Ø§Ø­: Ø­Ø°Ù jsonify
            return {"status": "error", "message": str(e)}, 500

# ---------------------------
# Health Check
# ---------------------------
@data_ns.route('/health')
class HealthResource(Resource):
    def get(self):
        """Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¶Ø¹ÛŒØª Ø³Ù„Ø§Ù…Øª Ø³Ø±ÙˆÛŒØ³ Ùˆ Ø§ØªØµØ§Ù„ Ø¨Ù‡ Ø¯ÛŒØªØ§Ø¨ÛŒØ³."""
        db_ok = False
        try:
            db.session.execute('SELECT 1')
            db_ok = True
        except Exception as e:
            logging.getLogger(__name__).error(f"Health check DB connection failed: {e}")

        # âœ… Ø§ØµÙ„Ø§Ø­: Ø­Ø°Ù jsonify
        return {
            "status": "ok",
            "message": "API is running.",
            "db_connection": "successful" if db_ok else "failed"
        }, 200