# routes/combined_analysis_route.py
import logging
from flask_restx import Namespace, Resource, fields, reqparse
from extensions import db
import traceback
import time
from sqlalchemy import and_

# Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† import Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„ CandlestickPatternDetection
from models import CandlestickPatternDetection, ComprehensiveSymbolData, HistoricalData

from services.combined_analysis_service import get_analysis_profile_for_symbols
from services.market_analysis_orchestrator import run_comprehensive_market_analysis

logger = logging.getLogger(__name__)

# =========================
# Namespace Ø¨Ø±Ø§ÛŒ Flask-RESTX
# =========================
SymbolAnalysis_ns = Namespace('SymbolAnalysis', description='Demand Analysis Engine')

# =================================================================================
# ØªØ¹Ø±ÛŒÙ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ DTO (Data Transfer Object) Ø¨Ø±Ø§ÛŒ Swagger
# =================================================================================
raw_historical_model = SymbolAnalysis_ns.model('RawHistorical', {
    'jdate': fields.String,
    'close': fields.Float,
    'volume': fields.Float,
    'plp': fields.Float,
    'buy_i_volume': fields.Float,
    'sell_i_volume': fields.Float
})

raw_fundamental_model = SymbolAnalysis_ns.model('RawFundamental', {
    'jdate': fields.String,
    'eps': fields.Float,
    'pe': fields.Float,
    'group_pe_ratio': fields.Float,
    'real_power_ratio': fields.Float
})

raw_technical_model = SymbolAnalysis_ns.model('RawTechnical', {
    'jdate': fields.String,
    'RSI': fields.Float,
    'SMA_50': fields.Float,
    'MACD': fields.Float,
    'MACD_Signal': fields.Float,
    'ATR': fields.Float
})

raw_candlestick_model = SymbolAnalysis_ns.model('RawCandlestick', {
    'jdate': fields.String,
    'pattern_name': fields.String
})

processed_model = SymbolAnalysis_ns.model('ProcessedMetrics', {
    'trend_score': fields.Float(description="Ø§Ù…ØªÛŒØ§Ø² Ø±ÙˆÙ†Ø¯ (ØªÚ©Ù†ÛŒÚ©Ø§Ù„)"),
    'value_score': fields.Float(description="Ø§Ù…ØªÛŒØ§Ø² Ø§Ø±Ø²Ø´ (Ø¨Ù†ÛŒØ§Ø¯ÛŒ)"),
    'flow_signal': fields.String(description="Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø¬Ø±ÛŒØ§Ù† Ù¾ÙˆÙ„ (Bullish/Neutral/Bearish)"),
    'flow_score': fields.Float(description="Ø§Ù…ØªÛŒØ§Ø² Ø¬Ø±ÛŒØ§Ù† Ù¾ÙˆÙ„ (Ø­Ù‚ÛŒÙ‚ÛŒ Ùˆ Ø­Ø¬Ù…)"),
    'risk_penalty': fields.Float(description="Ø§Ù…ØªÛŒØ§Ø² Ù…Ù†ÙÛŒ Ø±ÛŒØ³Ú© (Ø§Ø´Ø¨Ø§Ø¹ Ø®Ø±ÛŒØ¯ØŒ Ú©Ø´ÛŒØ¯Ú¯ÛŒ)"),
    'total_score': fields.Float(description="Ø§Ù…ØªÛŒØ§Ø² Ù†Ù‡Ø§ÛŒÛŒ (Ø¬Ù…Ø¹ Ú©Ù„)"),
    'overall_signal': fields.String(description="Ø³ÛŒÚ¯Ù†Ø§Ù„ Ú©Ù„ÛŒ (Buy/Hold/Sell)"),
    'target_upside_percent': fields.Float(description="Ø¯Ø±ØµØ¯ Ø³ÙˆØ¯ ØªØ§ Ù…Ù‚Ø§ÙˆÙ…Øª Ø§Ø³ØªØ§ØªÛŒÚ© Ø¨Ø¹Ø¯ÛŒ"),
    'reasons_summary': fields.List(fields.String, description="Ø®Ù„Ø§ØµÙ‡â€ŒØ§ÛŒ Ø§Ø² Ø¯Ù„Ø§ÛŒÙ„ Ø³ÛŒÚ¯Ù†Ø§Ù„"),
    'error': fields.String(description="Ø¯Ø± ØµÙˆØ±Øª Ø¨Ø±ÙˆØ² Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ Ø§ÛŒÙ† Ù†Ù…Ø§Ø¯ØŒ Ø§ÛŒÙ† ÙÛŒÙ„Ø¯ Ù¾Ø± Ù…ÛŒâ€ŒØ´ÙˆØ¯")
})

symbol_analysis_profile_model = SymbolAnalysis_ns.model('SymbolAnalysisProfile', {
    'symbol_id': fields.String,
    'symbol_name': fields.String(required=True),
    'company_name': fields.String,
    'sector_name': fields.String,
    'raw_historical': fields.Nested(raw_historical_model),
    'raw_fundamental': fields.Nested(raw_fundamental_model),
    'raw_technical': fields.Nested(raw_technical_model),
    'raw_candlestick': fields.Nested(raw_candlestick_model),
    'processed': fields.Nested(processed_model)
})

# ðŸ”¥ Ù…Ø¯Ù„ Ø¬Ø¯ÛŒØ¯ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¬Ø§Ù…Ø¹ Ø¨Ø§Ø²Ø§Ø±
comprehensive_analysis_response_model = SymbolAnalysis_ns.model('ComprehensiveAnalysisResponse', {
    'status': fields.String(example="success"),
    'analysis_type': fields.String(description="Ù†ÙˆØ¹ ØªØ­Ù„ÛŒÙ„ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯Ù‡"),
    'technical_analysis': fields.Raw(description="Ù†ØªØ§ÛŒØ¬ ØªØ­Ù„ÛŒÙ„ ØªÚ©Ù†ÛŒÚ©Ø§Ù„"),
    'fundamental_analysis': fields.Raw(description="Ù†ØªØ§ÛŒØ¬ ØªØ­Ù„ÛŒÙ„ ÙØ§Ù†Ø¯Ø§Ù…Ù†ØªØ§Ù„"),
    'sentiment_analysis': fields.Raw(description="Ù†ØªØ§ÛŒØ¬ ØªØ­Ù„ÛŒÙ„ Ø³Ù†ØªÛŒÙ…Ù†Øª"),
    'market_overview': fields.Raw(description="Ù†Ù…Ø§ÛŒ Ú©Ù„ÛŒ Ø¨Ø§Ø²Ø§Ø±"),
    'anomalies_detected': fields.Raw(description="Ø¢Ù†ÙˆÙ…Ø§Ù„ÛŒâ€ŒÙ‡Ø§ÛŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯Ù‡"),
    'execution_time': fields.Float(description="Ø²Ù…Ø§Ù† Ø§Ø¬Ø±Ø§ Ø¨Ù‡ Ø«Ø§Ù†ÛŒÙ‡"),
    'timestamp': fields.String(description="Ø²Ù…Ø§Ù† ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´")
})

combined_analysis_response_model = SymbolAnalysis_ns.model('CombinedAnalysisResponse', {
    'status': fields.String(example="success"),
    'SymbolAnalysis': fields.List(fields.Nested(symbol_analysis_profile_model)),
    'message': fields.String(description="Ù¾ÛŒØ§Ù… Ø®Ø·Ø§ Ø¯Ø± ØµÙˆØ±Øª Ø´Ú©Ø³Øª Ú©Ù„ÛŒ")
})

# ðŸ”¥ Ù…Ø¯Ù„ Ø¬Ø¯ÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ú©Ù†Ø¯Ù„ Ø§Ø³ØªÛŒÚ©
candlestick_pattern_model = SymbolAnalysis_ns.model('CandlestickPattern', {
    'symbol_id': fields.String(description="Ø´Ù†Ø§Ø³Ù‡ Ù†Ù…Ø§Ø¯"),
    'symbol_name': fields.String(description="Ù†Ø§Ù… Ù†Ù…Ø§Ø¯"),
    'company_name': fields.String(description="Ù†Ø§Ù… Ø´Ø±Ú©Øª"),
    'sector_name': fields.String(description="Ù†Ø§Ù… ØµÙ†Ø¹Øª"),
    'jdate': fields.String(description="ØªØ§Ø±ÛŒØ® Ø´Ù…Ø³ÛŒ"),
    'pattern_name': fields.String(description="Ù†Ø§Ù… Ø§Ù„Ú¯ÙˆÛŒ Ú©Ù†Ø¯Ù„ Ø§Ø³ØªÛŒÚ©"),
    'pattern_name_english': fields.String(description="Ù†Ø§Ù… Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ø§Ù„Ú¯Ùˆ"),
    'pattern_name_persian': fields.String(description="Ù†Ø§Ù… ÙØ§Ø±Ø³ÛŒ Ø§Ù„Ú¯Ùˆ"),
    'pattern_type': fields.String(description="Ù†ÙˆØ¹ Ø§Ù„Ú¯Ùˆ (Bullish/Bearish/Neutral)"),
    'created_at': fields.String(description="Ø²Ù…Ø§Ù† Ø§ÛŒØ¬Ø§Ø¯ Ø±Ú©ÙˆØ±Ø¯")
})

candlestick_response_model = SymbolAnalysis_ns.model('CandlestickResponse', {
    'status': fields.String(example="success"),
    'count': fields.Integer(description="ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ ÛŒØ§ÙØª Ø´Ø¯Ù‡"),
    'symbols_count': fields.Integer(description="ØªØ¹Ø¯Ø§Ø¯ Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ø¯Ø§Ø±Ø§ÛŒ Ø§Ù„Ú¯Ùˆ"),
    'patterns': fields.List(fields.Nested(candlestick_pattern_model)),
    'timestamp': fields.String(description="Ø²Ù…Ø§Ù† ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø®")
})

# =================================================================================
# ØªØ¹Ø±ÛŒÙ Parser ÙˆØ±ÙˆØ¯ÛŒ
# =================================================================================
combined_analysis_parser = reqparse.RequestParser()
combined_analysis_parser.add_argument(
    'symbols', type=str, required=True,
    help='Comma-separated list of symbol names (e.g., "Ø®ÙˆØ¯Ø±Ùˆ,Ø®Ø³Ø§Ù¾Ø§")', 
    location='args', # Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² Ø§ÛŒÙ†Ú©Ù‡ Ø§Ø² query string Ø®ÙˆØ§Ù†Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯
    action='split'
)

# ðŸ”¥ Parser Ø¬Ø¯ÛŒØ¯ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¬Ø§Ù…Ø¹
comprehensive_analysis_parser = reqparse.RequestParser()
comprehensive_analysis_parser.add_argument(
    'symbols', type=list, location='json', required=False,
    help='Ù„ÛŒØ³Øª Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ø®Ø§Øµ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ (Ø¯Ø± ØµÙˆØ±Øª Ø¹Ø¯Ù… Ø§Ø±Ø³Ø§Ù„ØŒ Ù‡Ù…Ù‡ Ù†Ù…Ø§Ø¯Ù‡Ø§ ØªØ­Ù„ÛŒÙ„ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯)'
)
comprehensive_analysis_parser.add_argument(
    'limit', type=int, location='json', required=False,
    help='Ù…Ø­Ø¯ÙˆØ¯ÛŒØª ØªØ¹Ø¯Ø§Ø¯ Ù†Ù…Ø§Ø¯Ù‡Ø§ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„'
)
comprehensive_analysis_parser.add_argument(
    'analysis_types', type=list, location='json', required=False, default=['technical', 'fundamental', 'sentiment'],
    help='Ø§Ù†ÙˆØ§Ø¹ ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø² (technical, fundamental, sentiment)'
)

# ðŸ”¥ Parser Ø¬Ø¯ÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ú©Ù†Ø¯Ù„ Ø§Ø³ØªÛŒÚ©
candlestick_parser = reqparse.RequestParser()
candlestick_parser.add_argument(
    'symbol_id', type=str, required=False,
    help='Ø´Ù†Ø§Ø³Ù‡ Ù†Ù…Ø§Ø¯ Ø®Ø§Øµ (Ø¯Ø± ØµÙˆØ±Øª Ø¹Ø¯Ù… Ø§Ø±Ø³Ø§Ù„ØŒ Ù‡Ù…Ù‡ Ù†Ù…Ø§Ø¯Ù‡Ø§ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯)',
    location='args'
)
candlestick_parser.add_argument(
    'pattern_type', type=str, required=False,
    choices=['bullish', 'bearish', 'neutral', 'all'],
    default='all',
    help='ÙÛŒÙ„ØªØ± Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹ Ø§Ù„Ú¯Ùˆ',
    location='args'
)
candlestick_parser.add_argument(
    'limit', type=int, required=False,
    help='Ù…Ø­Ø¯ÙˆØ¯ÛŒØª ØªØ¹Ø¯Ø§Ø¯ Ù†ØªØ§ÛŒØ¬',
    location='args'
)


# ðŸ”¥ Parser Ø¬Ø¯ÛŒØ¯ Ø¨Ø±Ø§ÛŒ ÙÛŒÙ„ØªØ±Ù‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡
advanced_candlestick_parser = reqparse.RequestParser()
advanced_candlestick_parser.add_argument(
    'symbol_id', type=str, required=False,
    help='Ø´Ù†Ø§Ø³Ù‡ Ù†Ù…Ø§Ø¯ Ø®Ø§Øµ',
    location='args'
)
advanced_candlestick_parser.add_argument(
    'pattern_type', type=str, required=False,
    choices=['bullish', 'bearish', 'neutral', 'all'],
    default='all',
    help='ÙÛŒÙ„ØªØ± Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹ Ø§Ù„Ú¯Ùˆ',
    location='args'
)
advanced_candlestick_parser.add_argument(
    'min_volume_ratio', type=float, required=False, default=1.0,
    help='Ø­Ø¯Ø§Ù‚Ù„ Ù†Ø³Ø¨Øª Ø­Ø¬Ù… Ø¨Ù‡ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø­Ø¬Ù… (Ù…Ø«Ù„Ø§Ù‹ 1.5 ÛŒØ¹Ù†ÛŒ Ø­Ø¬Ù… 50% Ø¨ÛŒØ´ØªØ± Ø§Ø² Ù…ÛŒØ§Ù†Ú¯ÛŒÙ†)',
    location='args'
)
advanced_candlestick_parser.add_argument(
    'min_trade_value', type=float, required=False, default=5.0,
    help='Ø­Ø¯Ø§Ù‚Ù„ Ø§Ø±Ø²Ø´ Ù…Ø¹Ø§Ù…Ù„Ø§Øª (Ù…ÛŒÙ„ÛŒØ§Ø±Ø¯ ØªÙˆÙ…Ø§Ù†)',
    location='args'
)
advanced_candlestick_parser.add_argument(
    'trend_direction', type=str, required=False,
    choices=['bullish', 'bearish', 'any'],
    default='any',
    help='ÙÛŒÙ„ØªØ± Ø¨Ø± Ø§Ø³Ø§Ø³ Ø±ÙˆÙ†Ø¯',
    location='args'
)
advanced_candlestick_parser.add_argument(
    'institutional_power', type=str, required=False,
    choices=['buying', 'selling', 'any'],
    default='any',
    help='ÙÛŒÙ„ØªØ± Ø¨Ø± Ø§Ø³Ø§Ø³ Ù‚Ø¯Ø±Øª Ø­Ù‚ÙˆÙ‚ÛŒ',
    location='args'
)
advanced_candlestick_parser.add_argument(
    'limit', type=int, required=False,
    help='Ù…Ø­Ø¯ÙˆØ¯ÛŒØª ØªØ¹Ø¯Ø§Ø¯ Ù†ØªØ§ÛŒØ¬',
    location='args'
)


# =================================================================================
# ØªØ¹Ø±ÛŒÙ Ø§Ù†Ø¯Ù¾ÙˆÛŒÙ†Øªâ€ŒÙ‡Ø§ (Controller)
# =================================================================================

@SymbolAnalysis_ns.route('/combined-analysis')
class CombinedAnalysisResource(Resource):

    @SymbolAnalysis_ns.doc('get_combined_analysis_profile')
    @SymbolAnalysis_ns.expect(combined_analysis_parser)
    @SymbolAnalysis_ns.marshal_with(combined_analysis_response_model)
    def get(self):
        """
        ÙˆØ§Ú©Ø´ÛŒ Ù¾Ø±ÙˆÙØ§ÛŒÙ„ ØªØ­Ù„ÛŒÙ„ÛŒ Ú©Ø§Ù…Ù„ (Ø®Ø§Ù… + Ù¾Ø±Ø¯Ø§Ø²Ø´â€ŒØ´Ø¯Ù‡) Ø¨Ø± Ø§Ø³Ø§Ø³ *Ù†Ø§Ù… Ù†Ù…Ø§Ø¯*.
        """
        logger.info("ðŸ” [API] Received request for combined analysis profile...")

        try:
            args = combined_analysis_parser.parse_args()
            symbol_names = args['symbols']

            if not symbol_names:
                logger.warning("No symbol names provided.")
                return {"status": "error", "SymbolAnalysis": []}, 400

            # --- ØªÙ…Ø§Ù… Ù…Ù†Ø·Ù‚ Ù¾ÛŒÚ†ÛŒØ¯Ù‡ Ø¨Ù‡ Ø³Ø±ÙˆÛŒØ³ Ø³Ù¾Ø±Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯ ---
            results_data = get_analysis_profile_for_symbols(symbol_names)
            
            logger.info(f"âœ… [API] Returning {len(results_data)} analysis profiles.")
            return {"status": "success", "SymbolAnalysis": results_data}, 200

        except Exception as e_outer:
            logger.error(f"âŒ Critical error in combined-analysis endpoint: {e_outer}", exc_info=True)
            return {"status": "error", "message": str(e_outer), "SymbolAnalysis": []}, 500



# =================================================================================
# Ø§Ù†Ø¯Ù¾ÙˆÛŒÙ†Øª Ø¢Ù†Ø§Ù„ÛŒØ² Ù‡Ù…Ú¯Ø§Ù†ÛŒ ÛŒÚ© Ø³Ù‡Ù…
# =================================================================================

@SymbolAnalysis_ns.route('/comprehensive-analysis')
class ComprehensiveAnalysisResource(Resource):
    
    @SymbolAnalysis_ns.doc('run_comprehensive_market_analysis')
    @SymbolAnalysis_ns.expect(comprehensive_analysis_parser)
    @SymbolAnalysis_ns.marshal_with(comprehensive_analysis_response_model)
    def post(self):
        """
        Ø§Ø¬Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¬Ø§Ù…Ø¹ ØªÚ©Ù†ÛŒÚ©Ø§Ù„-ÙØ§Ù†Ø¯Ø§Ù…Ù†ØªØ§Ù„-Ø³Ù†ØªÛŒÙ…Ù†Øª Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§Ø¯Ù‡Ø§
        """
        import time
        start_time = time.time()
        
        logger.info("ðŸŽ¯ [API] Starting comprehensive market analysis...")
        
        try:
            args = comprehensive_analysis_parser.parse_args()
            symbol_ids = args.get('symbols')
            limit = args.get('limit')
            analysis_types = args.get('analysis_types', ['technical', 'fundamental', 'sentiment'])
            
            logger.info(f"ðŸ“Š ØªØ­Ù„ÛŒÙ„ Ø¬Ø§Ù…Ø¹ Ø¨Ø±Ø§ÛŒ: {len(symbol_ids) if symbol_ids else 'Ù‡Ù…Ù‡'} Ù†Ù…Ø§Ø¯ | Ù…Ø­Ø¯ÙˆØ¯ÛŒØª: {limit} | Ø§Ù†ÙˆØ§Ø¹ ØªØ­Ù„ÛŒÙ„: {analysis_types}")
            
            # Ø§Ø¬Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¬Ø§Ù…Ø¹
            analysis_results = run_comprehensive_market_analysis(
                db_session=db.session,
                symbol_ids=symbol_ids,
                limit=limit
            )
            
            execution_time = time.time() - start_time
            
            # Ø³Ø§Ø®Øª Ù¾Ø§Ø³Ø®
            response = {
                'status': 'success',
                'analysis_type': 'comprehensive_technical_fundamental_sentiment',
                'technical_analysis': analysis_results.get('technical_analysis', {}),
                'fundamental_analysis': analysis_results.get('fundamental_analysis', {}),
                'sentiment_analysis': analysis_results.get('sentiment_analysis', {}),
                'market_overview': analysis_results.get('market_overview', {}),
                'anomalies_detected': analysis_results.get('anomalies_detected', []),
                'execution_time': round(execution_time, 2),
                'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
            }
            
            logger.info(f"âœ… ØªØ­Ù„ÛŒÙ„ Ø¬Ø§Ù…Ø¹ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯. Ø²Ù…Ø§Ù† Ø§Ø¬Ø±Ø§: {execution_time:.2f} Ø«Ø§Ù†ÛŒÙ‡")
            return response, 200
            
        except Exception as e:
            execution_time = time.time() - start_time
            logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ Ø¬Ø§Ù…Ø¹ Ø¨Ø§Ø²Ø§Ø±: {e}\n{traceback.format_exc()}")
            
            return {
                'status': 'error',
                'analysis_type': 'comprehensive_technical_fundamental_sentiment',
                'technical_analysis': {},
                'fundamental_analysis': {},
                'sentiment_analysis': {},
                'market_overview': {},
                'anomalies_detected': [],
                'execution_time': round(execution_time, 2),
                'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
                'error_message': str(e)
            }, 500

# ðŸ”¥ Ø§Ù†Ø¯Ù¾ÙˆÛŒÙ†Øª GET Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¬Ø§Ù…Ø¹ (Ø§Ø®ØªÛŒØ§Ø±ÛŒ)
@SymbolAnalysis_ns.route('/comprehensive-analysis/status')
class ComprehensiveAnalysisStatusResource(Resource):
    
    @SymbolAnalysis_ns.doc('get_comprehensive_analysis_status')
    def get(self):
        """
        Ø¯Ø±ÛŒØ§ÙØª ÙˆØ¶Ø¹ÛŒØª Ø³Ø±ÙˆÛŒØ³ ØªØ­Ù„ÛŒÙ„ Ø¬Ø§Ù…Ø¹
        """
        return {
            'status': 'active',
            'service': 'Comprehensive Market Analysis',
            'capabilities': [
                'Technical Analysis (RSI, MACD, Bollinger Bands, etc.)',
                'Fundamental Analysis (Valuation, Financial Health, Growth)',
                'Market Sentiment Analysis',
                'Anomaly Detection',
                'Market Overview'
            ],
            'version': '1.0',
            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
        }, 200




# =================================================================================
# Ø§Ù†Ø¯Ù¾ÙˆÛŒÙ†Øª Ú©Ù†Ø¯Ù„ Ù‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡
# =================================================================================        

# ðŸ”¥ Ø§Ù†Ø¯Ù¾ÙˆÛŒÙ†Øª Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø¨Ø±Ø§ÛŒ Ú©Ù†Ø¯Ù„ Ø§Ø³ØªÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ø§Ø±Ø²Ø´
@SymbolAnalysis_ns.route('/candlestick-patterns/advanced')
class AdvancedCandlestickPatternsResource(Resource):
    
    @SymbolAnalysis_ns.doc('get_valuable_candlestick_patterns')
    @SymbolAnalysis_ns.expect(advanced_candlestick_parser)
    @SymbolAnalysis_ns.marshal_with(candlestick_response_model)
    def get(self):
        """
        Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒØ³Øª Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ø¨Ø§Ø§Ø±Ø²Ø´ Ø¯Ø§Ø±Ø§ÛŒ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ú©Ù†Ø¯Ù„ Ø§Ø³ØªÛŒÚ©
        
        Ø§ÛŒÙ† Ø§Ù†Ø¯Ù¾ÙˆÛŒÙ†Øª ÙÙ‚Ø· Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒÛŒ Ø±Ø§ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯ Ú©Ù‡:
        - Ø­Ø¬Ù… Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ù‚Ø§Ø¨Ù„ ØªÙˆØ¬Ù‡ÛŒ Ø¯Ø§Ø±Ù†Ø¯
        - Ù†Ù‚Ø¯Ø´ÙˆÙ†Ø¯Ú¯ÛŒ Ø®ÙˆØ¨ÛŒ Ø¯Ø§Ø±Ù†Ø¯  
        - Ø¯Ø± Ø±ÙˆÙ†Ø¯ Ù…Ù†Ø§Ø³Ø¨ÛŒ Ù‚Ø±Ø§Ø± Ø¯Ø§Ø±Ù†Ø¯
        - Ù‚Ø¯Ø±Øª Ø®Ø±ÛŒØ¯ Ø³Ø§Ù„Ù…ÛŒ Ø¯Ø§Ø±Ù†Ø¯
        """
        logger.info("ðŸŽ¯ [API] Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¨Ø±Ø§ÛŒ Ú©Ù†Ø¯Ù„ Ø§Ø³ØªÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ø§Ø±Ø²Ø´...")
        
        try:
            args = advanced_candlestick_parser.parse_args()
            symbol_id = args.get('symbol_id')
            pattern_type = args.get('pattern_type', 'all')
            min_volume_ratio = args.get('min_volume_ratio', 1.0)
            min_trade_value = args.get('min_trade_value', 5.0)  # Ù…ÛŒÙ„ÛŒØ§Ø±Ø¯ ØªÙˆÙ…Ø§Ù†
            trend_direction = args.get('trend_direction', 'any')
            institutional_power = args.get('institutional_power', 'any')
            limit = args.get('limit')
            
            # Ú©ÙˆØ¦Ø±ÛŒ Ù¾Ø§ÛŒÙ‡ Ø¨Ø§ join Ø¬Ø¯ÙˆÙ„â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ø¨Ø±Ø§ÛŒ Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªÚ©Ù†ÛŒÚ©Ø§Ù„
            base_query = db.session.query(
                CandlestickPatternDetection,
                ComprehensiveSymbolData.symbol_name,
                ComprehensiveSymbolData.company_name,
                ComprehensiveSymbolData.group_name,
                HistoricalData.close,
                HistoricalData.volume,
                HistoricalData.value,
                HistoricalData.buy_i_volume,
                HistoricalData.sell_i_volume,
                HistoricalData.plp
            ).join(
                ComprehensiveSymbolData,
                CandlestickPatternDetection.symbol_id == ComprehensiveSymbolData.symbol_id
            ).join(
                HistoricalData,
                and_(
                    CandlestickPatternDetection.symbol_id == HistoricalData.symbol_id,
                    CandlestickPatternDetection.jdate == HistoricalData.jdate
                )
            )
            
            # ðŸ”§ Ø§Ø¹Ù…Ø§Ù„ ÙÛŒÙ„ØªØ±Ù‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡
            
            # ÙÛŒÙ„ØªØ± Ø­Ø°Ù ØµÙ†Ø¯ÙˆÙ‚â€ŒÙ‡Ø§ÛŒ Ø³Ø±Ù…Ø§ÛŒÙ‡ Ú¯Ø°Ø§Ø±ÛŒ - Ø§ÛŒÙ† Ø±Ùˆ Ø§ÙˆÙ„ Ø§Ø² Ù‡Ù…Ù‡ Ø§Ø¹Ù…Ø§Ù„ Ú©Ù†ÛŒØ¯
            excluded_sectors = ['ØµÙ†Ø¯ÙˆÙ‚', 'Ø§Ù‡Ø±Ù…ÛŒ', 'Ø³Ø±Ù…Ø§ÛŒÙ‡â€ŒÚ¯Ø°Ø§Ø±ÛŒâ€Œ', 'Ø³Ø±Ù…Ø§ÛŒÙ‡ Ú¯Ø°Ø§Ø±ÛŒ', 'Ø³Ø±Ù…Ø§ÙŠÙ‡ Ú¯Ø°Ø§Ø±ÙŠÙ‡Ø§']
            for excluded_sector in excluded_sectors:
                base_query = base_query.filter(
                    ~ComprehensiveSymbolData.group_name.ilike(f'%{excluded_sector}%')
                )
            logger.info("âœ… ÙÛŒÙ„ØªØ± Ø­Ø°Ù ØµÙ†Ø¯ÙˆÙ‚â€ŒÙ‡Ø§ Ø§Ø¹Ù…Ø§Ù„ Ø´Ø¯")

            # ÙÛŒÙ„ØªØ± Ø­Ø¬Ù… Ù…Ø¹Ø§Ù…Ù„Ø§Øª
            if min_volume_ratio > 1.0:
                # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø­Ø¬Ù… 20 Ø±ÙˆØ²Ù‡ (Ù†ÛŒØ§Ø² Ø¨Ù‡ subquery Ø¯Ø§Ø±Ø¯)
                from sqlalchemy import func
                avg_volume_subquery = db.session.query(
                    HistoricalData.symbol_id,
                    func.avg(HistoricalData.volume).label('avg_volume_20d')
                ).group_by(HistoricalData.symbol_id).subquery()
                
                base_query = base_query.join(
                    avg_volume_subquery,
                    CandlestickPatternDetection.symbol_id == avg_volume_subquery.c.symbol_id
                ).filter(
                    HistoricalData.volume >= avg_volume_subquery.c.avg_volume_20d * min_volume_ratio
                )
            
            # ÙÛŒÙ„ØªØ± Ø§Ø±Ø²Ø´ Ù…Ø¹Ø§Ù…Ù„Ø§Øª
            if min_trade_value > 0:
                base_query = base_query.filter(
                    HistoricalData.value >= min_trade_value * 1e9  # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ø±ÛŒØ§Ù„
                )
            
            # ÙÛŒÙ„ØªØ± Ø±ÙˆÙ†Ø¯
            if trend_direction != 'any':
                # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªÚ©Ù†ÛŒÚ©Ø§Ù„ Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ø±ÙˆÙ†Ø¯
                if trend_direction == 'bullish':
                    base_query = base_query.filter(
                        HistoricalData.close > func.coalesce(HistoricalData.sma_20, HistoricalData.close)
                    )
                elif trend_direction == 'bearish':
                    base_query = base_query.filter(
                        HistoricalData.close < func.coalesce(HistoricalData.sma_20, HistoricalData.close)
                    )
            
            # ÙÛŒÙ„ØªØ± Ù‚Ø¯Ø±Øª Ø­Ù‚ÙˆÙ‚ÛŒ
            if institutional_power != 'any':
                if institutional_power == 'buying':
                    base_query = base_query.filter(
                        HistoricalData.buy_i_volume > HistoricalData.sell_i_volume
                    )
                elif institutional_power == 'selling':
                    base_query = base_query.filter(
                        HistoricalData.buy_i_volume < HistoricalData.sell_i_volume
                    )
            
            # ÙÛŒÙ„ØªØ±Ù‡Ø§ÛŒ Ù¾Ø§ÛŒÙ‡
            if symbol_id:
                base_query = base_query.filter(CandlestickPatternDetection.symbol_id == symbol_id)
            
            if pattern_type != 'all':
                base_query = self._apply_pattern_type_filter(base_query, pattern_type)
            
            # Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ø±Ø²Ø´ Ù…Ø¹Ø§Ù…Ù„Ø§Øª (Ø¨Ø§Ø§Ø±Ø²Ø´â€ŒØªØ±ÛŒÙ† Ø§ÙˆÙ„)
            base_query = base_query.order_by(HistoricalData.value.desc())
            
            if limit:
                base_query = base_query.limit(limit)
            
            # Ø§Ø¬Ø±Ø§ÛŒ Ú©ÙˆØ¦Ø±ÛŒ
            results = base_query.all()
            
            logger.info(f"âœ… ÛŒØ§ÙØª Ø´Ø¯ {len(results)} Ú©Ù†Ø¯Ù„ Ø§Ø³ØªÛŒÚ© Ø¨Ø§Ø§Ø±Ø²Ø´")

            # ðŸ”¥ Ø­Ø°Ù Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§ÛŒ ØªÚ©Ø±Ø§Ø±ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ±Ú©ÛŒØ¨ symbol_id + pattern_name + jdate
            unique_patterns = {}
            for row in results:
                # Unpack ØªÙ…Ø§Ù… 10 ÙÛŒÙ„Ø¯ Ø§Ø² Ú©ÙˆØ¦Ø±ÛŒ
                candlestick, symbol_name, company_name, group_name, close, volume, value, buy_i_volume, sell_i_volume, plp = row
                
                key = (candlestick.symbol_id, candlestick.pattern_name, candlestick.jdate)
                if key not in unique_patterns:
                    unique_patterns[key] = row
            
            unique_results = list(unique_patterns.values())
            logger.info(f"ðŸ”¥ Ù¾Ø³ Ø§Ø² Ø­Ø°Ù ØªÚ©Ø±Ø§Ø±ÛŒâ€ŒÙ‡Ø§: {len(unique_results)} Ø§Ù„Ú¯ÙˆÛŒ Ù…Ù†Ø­ØµØ±Ø¨ÙØ±Ø¯")
            
            # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù†ØªØ§ÛŒØ¬
            patterns_list = []
            for row in unique_results:
                # Unpack ØªÙ…Ø§Ù… 10 ÙÛŒÙ„Ø¯ Ø§Ø² unique_results
                candlestick, symbol_name, company_name, group_name, close, volume, value_traded, buy_i_volume, sell_i_volume, plp = row
                
                pattern_name = candlestick.pattern_name
                pattern_name_english, pattern_name_persian = self._extract_pattern_names(pattern_name)
                pattern_type_detected = self._detect_pattern_type(pattern_name_english)
                
                patterns_list.append({
                    'symbol_id': candlestick.symbol_id,
                    'symbol_name': symbol_name,
                    'company_name': company_name,
                    'sector_name': group_name,  # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² group_name Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† sector_name
                    'jdate': candlestick.jdate,
                    'pattern_name': pattern_name,
                    'pattern_name_english': pattern_name_english,
                    'pattern_name_persian': pattern_name_persian,
                    'pattern_type': pattern_type_detected,
                    'created_at': candlestick.created_at.isoformat() if candlestick.created_at else None,
                    # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªÚ©Ù†ÛŒÚ©Ø§Ù„ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´
                    'technical_data': {
                        'close_price': close,
                        'volume': volume,
                        'trade_value_billion': round(value_traded / 1e9, 2) if value_traded else 0,
                        'institutional_net': buy_i_volume - sell_i_volume if buy_i_volume and sell_i_volume else 0,
                        'plp': plp
                    }
                })
            
            unique_symbols = len(set([p['symbol_id'] for p in patterns_list]))
            
            # ðŸ” Ù„Ø§Ú¯ Ø¢Ù…Ø§Ø± Ø§Ù„Ú¯ÙˆÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ø¯ÛŒØ¨Ø§Ú¯
            doji_count = len([p for p in patterns_list if 'Doji' in p['pattern_name']])
            engulfing_count = len([p for p in patterns_list if 'Engulfing' in p['pattern_name']])
            other_count = len(patterns_list) - doji_count - engulfing_count
            
            logger.info(f"ðŸ“Š Ø¢Ù…Ø§Ø± Ø§Ù„Ú¯ÙˆÙ‡Ø§: Ø¯ÙˆØ¬ÛŒ: {doji_count}, Ù¾ÙˆØ´Ø§: {engulfing_count}, Ø³Ø§ÛŒØ±: {other_count}")
            
            response = {
                'status': 'success',
                'count': len(patterns_list),
                'symbols_count': unique_symbols,
                'patterns': patterns_list,
                'filters_applied': {
                    'min_volume_ratio': min_volume_ratio,
                    'min_trade_value_billion': min_trade_value,
                    'trend_direction': trend_direction,
                    'institutional_power': institutional_power
                },
                'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
            }
            
            return response, 200
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ú©Ù†Ø¯Ù„ Ø§Ø³ØªÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ø§Ø±Ø²Ø´: {e}\n{traceback.format_exc()}")
            return {
                'status': 'error',
                'count': 0,
                'symbols_count': 0,
                'patterns': [],
                'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
                'error_message': str(e)
            }, 500
    
    def _apply_pattern_type_filter(self, query, pattern_type):
        """Ø§Ø¹Ù…Ø§Ù„ ÙÛŒÙ„ØªØ± Ù†ÙˆØ¹ Ø§Ù„Ú¯Ùˆ"""
        bullish_patterns = ['Hammer', 'Inverted_Hammer', 'Bullish_Engulfing', 'Piercing_Line', 
                          'Morning_Star', 'Three_White_Soldiers', 'Bullish_Harami', 'Dragonfly_Doji']
        bearish_patterns = ['Shooting_Star', 'Bearish_Engulfing', 'Evening_Star', 'Dark_Cloud_Cover',
                          'Three_Black_Crows', 'Bearish_Harami', 'Gravestone_Doji']
        neutral_patterns = ['Doji', 'Spinning_Top']
        
        if pattern_type == 'bullish':
            return query.filter(
                CandlestickPatternDetection.pattern_name.contains('Bullish') |
                CandlestickPatternDetection.pattern_name.in_(bullish_patterns)
            )
        elif pattern_type == 'bearish':
            return query.filter(
                CandlestickPatternDetection.pattern_name.contains('Bearish') |
                CandlestickPatternDetection.pattern_name.in_(bearish_patterns)
            )
        elif pattern_type == 'neutral':
            return query.filter(CandlestickPatternDetection.pattern_name.in_(neutral_patterns))
        
        return query
    
    def _extract_pattern_names(self, pattern_name):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†Ø§Ù… Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ùˆ ÙØ§Ø±Ø³ÛŒ Ø§Ø² Ø§Ù„Ú¯Ùˆ"""
        if ' (' in pattern_name and ')' in pattern_name:
            pattern_name_english = pattern_name.split(' (')[0]
            pattern_name_persian = pattern_name.split(' (')[1].replace(')', '')
        else:
            pattern_name_english = pattern_name
            pattern_name_persian = pattern_name
        return pattern_name_english, pattern_name_persian
    
    def _detect_pattern_type(self, pattern_name):
        """ØªØ´Ø®ÛŒØµ Ù†ÙˆØ¹ Ø§Ù„Ú¯Ùˆ"""
        bullish_keywords = ['Hammer', 'Inverted_Hammer', 'Bullish', 'Piercing', 'Morning', 'Dragonfly']
        bearish_keywords = ['Shooting', 'Bearish', 'Evening', 'Dark_Cloud', 'Gravestone']
        
        pattern_lower = pattern_name.lower()
        
        for keyword in bullish_keywords:
            if keyword.lower() in pattern_lower:
                return 'bullish'
        
        for keyword in bearish_keywords:
            if keyword.lower() in pattern_lower:
                return 'bearish'
        
        return 'neutral'





# ðŸ”¥ Ø§Ù†Ø¯Ù¾ÙˆÛŒÙ†Øª Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ø¢Ù…Ø§Ø± Ú©Ù†Ø¯Ù„ Ø§Ø³ØªÛŒÚ©â€ŒÙ‡Ø§
@SymbolAnalysis_ns.route('/candlestick-patterns/stats')
class CandlestickPatternsStatsResource(Resource):
    
    @SymbolAnalysis_ns.doc('get_candlestick_patterns_statistics')
    def get(self):
        """
        Ø¯Ø±ÛŒØ§ÙØª Ø¢Ù…Ø§Ø± Ùˆ Ú¯Ø²Ø§Ø±Ø´ Ø§Ø² Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ú©Ù†Ø¯Ù„ Ø§Ø³ØªÛŒÚ© Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯Ù‡
        """
        logger.info("ðŸ“Š [API] Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¨Ø±Ø§ÛŒ Ø¢Ù…Ø§Ø± Ú©Ù†Ø¯Ù„ Ø§Ø³ØªÛŒÚ©â€ŒÙ‡Ø§...")
        
        try:
            # Ø¢Ù…Ø§Ø± Ú©Ù„ÛŒ
            total_patterns = db.session.query(CandlestickPatternDetection).count()
            unique_symbols = db.session.query(CandlestickPatternDetection.symbol_id).distinct().count()
            
            # Ø¢Ù…Ø§Ø± Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹ Ø§Ù„Ú¯Ùˆ
            patterns_by_type = db.session.query(
                CandlestickPatternDetection.pattern_name
            ).all()
            
            bullish_count = 0
            bearish_count = 0
            neutral_count = 0
            
            for pattern in patterns_by_type:
                pattern_type = CandlestickPatternsResource()._detect_pattern_type(pattern[0])
                if pattern_type == 'bullish':
                    bullish_count += 1
                elif pattern_type == 'bearish':
                    bearish_count += 1
                else:
                    neutral_count += 1
            
            # Ù…Ø­Ø¨ÙˆØ¨â€ŒØªØ±ÛŒÙ† Ø§Ù„Ú¯ÙˆÙ‡Ø§
            from sqlalchemy import func
            popular_patterns = db.session.query(
                CandlestickPatternDetection.pattern_name,
                func.count(CandlestickPatternDetection.pattern_name).label('count')
            ).group_by(
                CandlestickPatternDetection.pattern_name
            ).order_by(
                func.count(CandlestickPatternDetection.pattern_name).desc()
            ).limit(10).all()
            
            stats = {
                'status': 'success',
                'total_patterns': total_patterns,
                'unique_symbols': unique_symbols,
                'pattern_type_distribution': {
                    'bullish': bullish_count,
                    'bearish': bearish_count,
                    'neutral': neutral_count
                },
                'popular_patterns': [
                    {'pattern_name': pattern[0], 'count': pattern[1]} 
                    for pattern in popular_patterns
                ],
                'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
            }
            
            return stats, 200
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¢Ù…Ø§Ø± Ú©Ù†Ø¯Ù„ Ø§Ø³ØªÛŒÚ©â€ŒÙ‡Ø§: {e}")
            return {
                'status': 'error',
                'error_message': str(e),
                'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
            }, 500
